<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Métodos y Simulación Estadística" />


<title> Pruebas sobre dos muestras</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="site_libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>
<link href="site_libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="site_libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"> </a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Inicio
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Probabilidad
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso101.html">Introducción</a>
    </li>
    <li>
      <a href="recurso102.html">Conceptos básicos</a>
    </li>
    <li>
      <a href="recurso103.html">Enfoques y postulados</a>
    </li>
    <li>
      <a href="recurso104.html">Tipos de probabilidad</a>
    </li>
    <li>
      <a href="recurso104b.html">Independencia</a>
    </li>
    <li>
      <a href="recurso104c.html">Teorema de Bayes</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Variable aleatoria
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso201.html">Variable aleatoria: Univariado</a>
    </li>
    <li>
      <a href="recurso202.html">Valor esperado</a>
    </li>
    <li>
      <a href="recurso203.html">Variables conjuntas</a>
    </li>
    <li>
      <a href="recurso204.html">Modelos discretos: Univariado</a>
    </li>
    <li>
      <a href="recurso205.html">Modelos continuos: Univariado</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Inferencia estadística
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso301.html">Conceptos básicos</a>
    </li>
    <li>
      <a href="recurso302.html">Distribución muestral</a>
    </li>
    <li>
      <a href="recurso305.html">Teorema del límite central</a>
    </li>
    <li>
      <a href="recurso303.html">Propiedades de los estimadores</a>
    </li>
    <li>
      <a href="recurso304.html">Métodos de estimación</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Intervalos de confianza
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso401.html">Paramétrico: Una población</a>
    </li>
    <li>
      <a href="recurso402.html">Paramétrico: Dos poblaciones</a>
    </li>
    <li>
      <a href="recurso403.html">Estimación no paramétrica</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pruebas de hipótesis
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso501.html">Introducción</a>
    </li>
    <li>
      <a href="recurso502.html">Paramétrico: Una población</a>
    </li>
    <li>
      <a href="recurso503.html">Paramétrico: Dos poblaciones</a>
    </li>
    <li>
      <a href="recurso504.html">Pruebas no paramétricas</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Casos y simulaciones
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso404.html">Casos 1 y 2</a>
    </li>
    <li>
      <a href="recurso406.html">Simulación y problema</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Referencias
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso1000.html">Referencias</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore"><span style="color:#686868">
<strong>Pruebas sobre dos muestras</strong></span></h1>
<h4 class="author">Métodos y Simulación Estadística</h4>

</div>


</br></br>
<h2>
Introducción
</h2>
<p>En este análisis, se busca evaluar la <strong>eventual diferencia
entre dos grupos</strong> y la <strong>correlación entre dos
variables</strong>. Para ello, se aplicarán pruebas estadísticas que
permitan determinar si:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Dos poblaciones</strong> presentan la <strong>misma
media</strong> o la <strong>misma varianza</strong> en una
<strong>variable cuantitativa</strong>.</p></li>
<li><p><strong>Dos poblaciones</strong> tienen la <strong>misma
proporción</strong> en una <strong>categoría de una variable
cualitativa</strong>.</p></li>
<li><p>Existe una <strong>relación significativa lineal</strong> entre
<strong>dos variables cuantitativas</strong> mediante el análisis de
correlación.</p></li>
</ol>
<hr />
</br></br>
<h2>
Muestras independientes
</h2>
</br></br>
<h3>
Prueba de diferencia de medias
</h3>
<p>En numerosos estudios estadísticos, es común preguntarse si dos
poblaciones presentan diferencias en una característica cuantitativa de
interés.</p>
<p>Por ejemplo, en un estudio clínico, se desea comparar la
<strong>presión arterial promedio</strong> en dos grupos de pacientes:
uno que recibió un <strong>tratamiento experimental</strong> y otro que
recibió un <strong>placebo</strong>. En este caso, la pregunta central
es: <strong>¿Existe una diferencia significativa en la presión arterial
media entre ambos grupos?</strong></p>
<p>Para responder a esta cuestión, se comparan las <strong>medias de las
dos poblaciones independientes</strong> (unidades muestrales diferentes
en cada grupo), evaluando si la diferencia observada entre los grupos es
suficientemente grande como para descartar que se deba únicamente al
azar.</p>
<p>La comparación de las <strong>medias de dos poblaciones
independientes</strong> se realiza mediante la evaluación de sus
<strong>estimadores muestrales</strong>. De manera similar a la relación
entre la <strong>media muestral</strong> y la <strong>media
poblacional</strong>, el <strong>parámetro de interés</strong> en este
caso es la <strong>diferencia de medias poblacionales</strong>,
representada como:</p>
<p><span class="math display">\[
\mu_1 - \mu_2
\]</span></p>
<p>Dado que el valor de los parámetros poblacionales es desconocido, se
utiliza la <strong>diferencia de medias muestrales</strong> como
<strong>estimador</strong>:</p>
<p><span class="math display">\[
\bar{x}_1 - \bar{x}_2
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(\bar{x}_1\)</span> y <span
class="math inline">\(\bar{x}_2\)</span> representan las <strong>medias
muestrales</strong> de los dos grupos,</p></li>
<li><p><span class="math inline">\(\mu_1\)</span> y <span
class="math inline">\(\mu_2\)</span> son las <strong>medias
poblacionales desconocidas</strong>.</p></li>
</ul>
<p>Sea <span class="math inline">\(\mu_1\)</span> la media poblacional
del <strong>primer grupo</strong> y <span
class="math inline">\(\mu_2\)</span> la media poblacional del
<strong>segundo grupo</strong>, una hipótesis de interés se puede
formular como:</p>
<p><span class="math display">\[
H_0: \mu_1 = \mu_2
\]</span></p>
<p><span class="math display">\[
H_1: \mu_1 \neq \mu_2
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span> establece que <strong>no
hay diferencia significativa</strong> entre las medias
poblacionales.</p></li>
<li><p><span class="math inline">\(H_1\)</span> plantea que
<strong>existe una diferencia significativa</strong> entre los dos
grupos.</p></li>
</ul>
<hr />
</br></br>
<h3>
Prueba de cociente de varianzas
</h3>
<p>En numerosos estudios estadísticos, es fundamental determinar si dos
poblaciones presentan <strong>variabilidad similar</strong> en una
característica de interés.</p>
<p>Por ejemplo, en un estudio sobre el rendimiento académico, un
investigador podría querer comparar la <strong>dispersión de
calificaciones</strong> en dos universidades diferentes para evaluar si
una de ellas presenta una mayor <strong>variabilidad</strong> en el
desempeño de los estudiantes. En este caso, la pregunta central es:
<strong>¿Existen diferencias significativas en la variabilidad de las
calificaciones entre ambas universidades?</strong></p>
<p>Para responder a esta pregunta, se comparan las <strong>varianzas de
las dos poblaciones independientes</strong>, evaluando si la diferencia
observada en la dispersión de los datos es <strong>estadísticamente
significativa</strong>.</p>
<p>La comparación de las <strong>varianzas de dos poblaciones
independientes</strong> se lleva a cabo mediante la evaluación de sus
<strong>estimadores muestrales</strong>. De manera similar a la relación
entre la <strong>varianza muestral</strong> y la <strong>varianza
poblacional</strong>, el <strong>parámetro de interés</strong> en este
caso es el <strong>cociente de varianzas poblacionales</strong>,
representado como:</p>
<p><span class="math display">\[
\frac{\sigma_1^2}{\sigma_2^2}
\]</span></p>
<p>Dado que los valores de las varianzas poblacionales son desconocidos,
se utiliza el <strong>cociente de varianzas muestrales</strong> como
<strong>estimador</strong>:</p>
<p><span class="math display">\[
\frac{S_1^2}{S_2^2}
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(S_1^2\)</span> y <span
class="math inline">\(S_2^2\)</span> representan las <strong>varianzas
muestrales</strong> de los dos grupos,</p></li>
<li><p><span class="math inline">\(\sigma_1^2\)</span> y <span
class="math inline">\(\sigma_2^2\)</span> son las <strong>varianzas
poblacionales desconocidas</strong>.</p></li>
</ul>
<p>Sea <span class="math inline">\(\sigma_1^2\)</span> la varianza
poblacional del <strong>primer grupo</strong> y <span
class="math inline">\(\sigma_2^2\)</span> la varianza poblacional del
<strong>segundo grupo</strong>. La hipótesis de interés podría ser la
siguiente:</p>
<p><span class="math display">\[
H_0: \sigma_1^2 = \sigma_2^2
\]</span></p>
<p><span class="math display">\[
H_1: \sigma_1^2 \neq \sigma_2^2
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span> indica que <strong>no
hay diferencia significativa</strong> entre las varianzas
poblacionales.</p></li>
<li><p><span class="math inline">\(H_1\)</span> plantea que <strong>las
varianzas son diferentes</strong>, lo que implica una dispersión
desigual en los datos.</p></li>
</ul>
<hr />
</br></br>
<h3>
Prueba de resta de proporciones
</h3>
<p>En diversas investigaciones, surge la necesidad de comparar
<strong>proporciones entre dos poblaciones independientes</strong> para
determinar si existe una diferencia significativa en la ocurrencia de
una característica específica.</p>
<p>Por ejemplo, en un estudio médico, se busca evaluar si la
<strong>tasa de recuperación</strong> de pacientes tratados con un
<strong>nuevo medicamento</strong> es mayor que la de aquellos que
recibieron un <strong>tratamiento convencional</strong>. La pregunta
central es: <strong>¿Existe una diferencia estadísticamente
significativa en la proporción de pacientes recuperados entre ambos
tratamientos?</strong></p>
<p>Para responder a esta interrogante, se comparan las
<strong>proporciones de éxito en las dos poblaciones
independientes</strong>, evaluando si la diferencia observada en la
muestra es suficientemente grande como para descartar que se deba
únicamente al azar.</p>
<p>La comparación de las <strong>proporciones de dos poblaciones
independientes</strong> se lleva a cabo mediante la evaluación de sus
<strong>estimadores muestrales</strong>. De manera similar a la relación
entre la <strong>proporción muestral</strong> y la <strong>proporción
poblacional</strong>, el <strong>parámetro de interés</strong> en este
caso es la <strong>diferencia de proporciones poblacionales</strong>,
representada como:</p>
<p><span class="math display">\[
P_1 - P_2
\]</span></p>
<p>Dado que los valores de las proporciones poblacionales son
desconocidos, se utiliza la <strong>diferencia de proporciones
muestrales</strong> como <strong>estimador</strong>:</p>
<p><span class="math display">\[
\hat{P}_1 - \hat{P}_2
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(\hat{P}_1\)</span> y <span
class="math inline">\(\hat{P}_2\)</span> representan las
<strong>proporciones muestrales</strong> de los dos grupos,</p></li>
<li><p><span class="math inline">\(P_1\)</span> y <span
class="math inline">\(P_2\)</span> son las <strong>proporciones
poblacionales desconocidas</strong>.</p></li>
</ul>
<p>Sea <span class="math inline">\(P_1\)</span> la proporción
poblacional de <strong>éxito en el primer grupo</strong> y <span
class="math inline">\(P_2\)</span> la proporción poblacional de
<strong>éxito en el segundo grupo</strong>. La hipótesis de interés se
puede formular como:</p>
<p><span class="math display">\[
H_0: P_1 = P_2
\]</span></p>
<p><span class="math display">\[
H_1: P_1 \neq P_2
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span> indica que <strong>no
hay diferencia significativa</strong> entre las proporciones
poblacionales.</p></li>
<li><p><span class="math inline">\(H_1\)</span> plantea que
<strong>existe una diferencia significativa</strong> entre los dos
grupos.</p></li>
</ul>
</br></br>
<h2>
Muestras pareadas (dependientes)
</h2>
<p>Esta prueba es útil cuando se busca evaluar <strong>diferencias
individuales</strong> en sujetos observados en <strong>dos momentos
distintos</strong>. Se denomina <strong>prueba para muestras
pareadas</strong> porque las diferencias se analizan en <strong>pares o
parejas</strong>, es decir, cada unidad de análisis se compara consigo
misma en dos instancias temporales.</p>
<p>A diferencia de las pruebas para muestras independientes, donde se
contrastan datos de <strong>dos poblaciones distintas</strong>, aquí el
interés radica en evaluar <strong>cambios individuales dentro del mismo
grupo</strong>.</p>
<p><strong>Aplicaciones de la prueba pareada</strong></p>
<p><strong>1. Comparaciones antes y después</strong></p>
<p>Un uso común de esta prueba ocurre en estudios donde se mide una
variable en dos momentos diferentes, como en los diseños experimentales
que incluyen:</p>
<ul>
<li><p><strong>Evaluaciones pretest y postest</strong> en intervenciones
educativas o médicas.</p></li>
<li><p><strong>Efectos de un tratamiento</strong> sobre la presión
arterial, el rendimiento académico o la condición física.</p></li>
<li><p><strong>Estudios longitudinales</strong>, donde los mismos
sujetos son observados en distintos periodos de tiempo.</p></li>
</ul>
<p>En estos casos, interesa analizar en qué medida cada individuo
<strong>ha cambiado</strong> después de la intervención, en lugar de
centrarse en las diferencias entre los sujetos.</p>
<p><strong>2. Comparaciones de condiciones diferentes en el mismo
individuo</strong></p>
<ul>
<li><p><strong>Evaluaciones de presión arterial</strong> por la mañana y
en la tarde en los mismos pacientes.</p></li>
<li><p><strong>Comparación del desempeño en tareas cognitivas</strong>
en entornos con y sin distracción.</p></li>
</ul>
</br></br>
<h3>
Prueba de diferencia
</h3>
<p>Para analizar la diferencia entre las dos mediciones en la misma
unidad de observación, se define la variable <span
class="math inline">\(D\)</span>, que representa la diferencia entre los
valores de cada par:</p>
<p><span class="math display">\[
D_i = X_{i,1} - X_{i,2}
\]</span></p>
<p>Las hipótesis se plantean en función de la <strong>media de las
diferencias</strong> <span class="math inline">\(\mu_D\)</span>, por
ejemplo:</p>
<p><span class="math display">\[
H_0: \mu_D = 0
\]</span></p>
<p><span class="math display">\[
H_1: \mu_D \neq 0
\]</span></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span> establece que <strong>no
hay cambios significativos</strong> entre las mediciones.</p></li>
<li><p><span class="math inline">\(H_1\)</span> sugiere que
<strong>existe una diferencia significativa</strong> entre los dos
momentos.</p></li>
</ul>
<p>La <strong>Tabla 2.21</strong> presenta un resumen de los
estimadores, parámetros, test paramétricos y supuestos para realizar
comparaciones cuando se tienen muestras independientes o pareadas.</p>
<br/><br/>
<center>
<strong>Tabla 2.21</strong> Resumen de pruebas de hipótesis para
muestras independientes y pareadas.
</center>
<table>
<colgroup>
<col width="15%" />
<col width="21%" />
<col width="28%" />
<col width="34%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Parámetro</strong></th>
<th align="center"><strong>Supuestos</strong></th>
<th align="center"><strong>Hipótesis nula <span
class="math inline">\(H_0\)</span></strong></th>
<th align="center"><strong>Estadístico de prueba y
distribución</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Diferencia de medias <span
class="math inline">\(\mu_1 - \mu_2\)</span></strong></td>
<td align="center">Muestras independientes, poblaciones normales o <span
class="math inline">\(n_1, n_2 \geq 30\)</span>, varianzas <span
class="math inline">\(\sigma_1^2, \sigma_2^2\)</span> conocidas</td>
<td align="center"><span class="math inline">\(\mu_1 - \mu_2 =
d_0\)</span></td>
<td align="center"><span class="math inline">\(Z = \frac{(\bar{x}_1 -
\bar{x}_2) - d_0}{\sqrt{\frac{\sigma_1^2}{n_1} +
\frac{\sigma_2^2}{n_2}}} \sim N(0,1)\)</span></td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">Muestras independientes, poblaciones normales,
varianzas <span class="math inline">\(\sigma_1^2 = \sigma_2^2\)</span>
desconocidas</td>
<td align="center"><span class="math inline">\(\mu_1 - \mu_2 =
d_0\)</span></td>
<td align="center"><span class="math inline">\(T = \frac{(\bar{x}_1 -
\bar{x}_2) - d_0}{S_p \cdot \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \sim
t_{(v=n_1+n_2-2)}\)</span>, donde <span class="math inline">\(S_p^2 =
\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}\)</span></td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center">Muestras independientes, poblaciones normales,
varianzas <span class="math inline">\(\sigma_1^2 \neq
\sigma_2^2\)</span> desconocidas</td>
<td align="center"><span class="math inline">\(\mu_1 - \mu_2 =
d_0\)</span></td>
<td align="center"><span class="math inline">\(T = \frac{(\bar{x}_1 -
\bar{x}_2) - d_0}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} \sim
t_{(v)}\)</span>, donde <span class="math inline">\(v = \frac{\left(
\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}
\right)^2}{\frac{(s_1^2/n_1)^2}{n_1 - 1} + \frac{(s_2^2/n_2)^2}{n_2 -
1}}\)</span></td>
</tr>
<tr class="even">
<td align="center"><strong>Diferencia de medias <span
class="math inline">\(\mu_D\)</span></strong></td>
<td align="center">Muestras pareadas, diferencias distribuidas
normalmente</td>
<td align="center"><span class="math inline">\(\mu_D = d_0\)</span></td>
<td align="center"><span class="math inline">\(T = \frac{\bar{d} -
d_0}{\frac{s_d}{\sqrt{n}}} \sim t_{(v=n-1)}\)</span>, donde <span
class="math inline">\(\bar{d} = \frac{1}{n} \sum_{i=1}^{n} d_i\)</span>
y <span class="math inline">\(d_i = x_{1i} - x_{2i}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><strong>Diferencia de proporciones <span
class="math inline">\(P_1 - P_2\)</span></strong></td>
<td align="center"><span class="math inline">\(n_1 p_1 \geq 5\)</span>,
<span class="math inline">\(n_1 (1 - p_1) \geq 5\)</span>, <span
class="math inline">\(n_2 p_2 \geq 5\)</span>, <span
class="math inline">\(n_2 (1 - p_2) \geq 5\)</span></td>
<td align="center"><span class="math inline">\(P_1 - P_2 =
p_0\)</span></td>
<td align="center"><span class="math inline">\(Z = \frac{p_1 -
p_2}{\sqrt{p(1 - p) \left( \frac{1}{n_1} + \frac{1}{n_2} \right)}} \sim
N(0,1)\)</span>, donde <span class="math inline">\(p_1 =
\frac{x_1}{n_1}\)</span>, <span class="math inline">\(p_2 =
\frac{x_2}{n_2}\)</span>, y <span class="math inline">\(p = \frac{x_1 +
x_2}{n_1 + n_2}\)</span></td>
</tr>
<tr class="even">
<td align="center"><strong>Cociente de varianzas <span
class="math inline">\(\sigma_1^2 / \sigma_2^2\)</span></strong></td>
<td align="center">Muestras independientes, poblaciones normales</td>
<td align="center"><span class="math inline">\(\sigma_1^2 =
\sigma_2^2\)</span></td>
<td align="center"><span class="math inline">\(F = \frac{s_1^2}{s_2^2}
\sim F_{(v_1=n_1-1, v_2=n_2-1)}\)</span></td>
</tr>
</tbody>
</table>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p>El director de un gimnasio busca determinar si la contratación de un
instructor para su programa de reducción de peso resulta efectiva. Para
tomar esta decisión, se selecciona un grupo de <strong>16
personas</strong> que asisten regularmente al gimnasio y se les somete a
una prueba piloto con un aspirante al cargo.</p>
<p>A fin de evaluar la eficacia del programa, se registran los
<strong>pesos iniciales (antes del programa)</strong> y los
<strong>pesos finales (después de un mes de participación)</strong> en
la iniciativa. El objetivo es determinar si existe una reducción
significativa en el peso de los participantes, lo que permitiría
justificar la contratación del instructor.</p>
<p>Se establece un <strong>nivel de significancia de <span
class="math inline">\(\alpha = 0.10\)</span></strong> para realizar la
prueba estadística.</p>
<!-- |     |     |     |     |     |     |     |     |     |     |     |     |     |     |     |     |     | -->
<!-- |:----|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|      -->
<!-- |Antes  |104.5|89   |84.5 |106  |90   |96   |79   |90   |85   |76.5 |91.5 |82.5 |100.5| 89.5|121.5| 72  | -->
<!-- |Después | 98  |85.5 |85   |103.5|88.5 |95   |79.5 |90   |82   |76   |89.5 |81   | 99.5| 86.5|115.5| 70  | -->
<table>
<thead>
<tr class="header">
<th align="left">observación</th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Antes</td>
<td align="right">104.5</td>
<td align="right">89.0</td>
<td align="right">84.5</td>
<td align="right">106.0</td>
<td align="right">90.0</td>
<td align="right">96</td>
<td align="right">79.0</td>
<td align="right">90</td>
</tr>
<tr class="even">
<td align="left">Después</td>
<td align="right">98.0</td>
<td align="right">85.5</td>
<td align="right">85.0</td>
<td align="right">103.5</td>
<td align="right">88.5</td>
<td align="right">95</td>
<td align="right">79.5</td>
<td align="right">90</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="left">observación</th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Antes</td>
<td align="right">85</td>
<td align="right">76.5</td>
<td align="right">91.5</td>
<td align="right">82.5</td>
<td align="right">100.5</td>
<td align="right">89.5</td>
<td align="right">121.5</td>
<td align="right">72</td>
</tr>
<tr class="even">
<td align="left">Después</td>
<td align="right">82</td>
<td align="right">76.0</td>
<td align="right">89.5</td>
<td align="right">81.0</td>
<td align="right">99.5</td>
<td align="right">86.5</td>
<td align="right">115.5</td>
<td align="right">70</td>
</tr>
</tbody>
</table>
<p>En este análisis se evalúa la eficacia de un <strong>programa de
reducción de peso</strong>, implementado en un gimnasio bajo la
supervisión de un aspirante a instructor. Se dispone de los pesos de un
grupo de <strong>16 participantes</strong>, registrados <strong>antes y
después</strong> de un mes de entrenamiento.</p>
<p>Dado que cada individuo tiene <strong>dos mediciones</strong> (una
antes y otra después del programa), este estudio corresponde a un
<strong>análisis de diferencias con muestras pareadas</strong>. En este
contexto, se busca determinar si el programa ha generado <strong>una
reducción significativa en el peso de los participantes</strong>.</p>
<p>En términos estadísticos, el interés radica en evaluar si la
<strong>diferencia promedio entre los pesos antes y después es
negativa</strong>, lo que indicaría una reducción efectiva del peso tras
la implementación del programa.</p>
<p>Sea <span class="math inline">\(D_i = \text{peso antes}_i -
\text{peso después}_i\)</span> la diferencia en el peso de cada
individuo. Definiendo <span class="math inline">\(\mu_D\)</span> como la
<strong>media poblacional de las diferencias</strong>, se establecen las
siguientes hipótesis:</p>
<p><span class="math display">\[
H_0: \mu_D \geq 0
\]</span></p>
<p><span class="math display">\[
H_1: \mu_D &lt; 0
\]</span></p>
<p>donde:</p>
<ul>
<li><p><strong><span class="math inline">\(H_0\)</span></strong> indica
que <strong>no hay reducción significativa en el peso</strong> o que, en
promedio, el peso no ha disminuido después del programa.</p></li>
<li><p><strong><span class="math inline">\(H_1\)</span></strong>
establece que <strong>el peso promedio después del programa es
menor</strong>, lo que sugiere que la intervención ha sido
efectiva.</p></li>
</ul>
<p>Para la aplicación de una <strong>prueba t para muestras
pareadas</strong>, es necesario verificar que las <strong>diferencias
muestrales</strong> (<span class="math inline">\(D_i\)</span>) siguen
una distribución <strong>aproximadamente normal</strong>.</p>
<p>Para ello, se utiliza la <strong>prueba de normalidad de
Shapiro-Wilk</strong>, cuyos resultados son los siguientes:</p>
<pre>
    Shapiro-Wilk normality test

data:  dif
W = 0.32897, p-value = 1.088e-07
</pre>
<p>El <span class="math inline">\(valor-p\)</span> obtenido es <span
class="math inline">\(1.088 \times 10^{-7}\)</span>, lo que, con un
nivel de significancia de menos del 1%, permite inferir que las
<strong>diferencias no siguen una distribución normal</strong>.</p>
<p>A pesar de que <strong>la normalidad no se cumple</strong>, se
realiza la <strong>prueba t para muestras pareadas</strong> bajo el
supuesto de normalidad. Los resultados obtenidos son:</p>
<pre>
    Paired t-test

data:  pant and pdes
t = 1.2736, df = 15, p-value = 0.8889
alternative hypothesis: true mean difference is less than 0
95 percent confidence interval:
     -Inf 19.75467
sample estimates:
mean difference 
         8.3125 
</pre>
<p>El <strong><span class="math inline">\(valor-p\)</span></strong>
obtenido es 0.8889, lo que indica que <strong>no hay suficiente
evidencia para rechazar la hipótesis nula</strong> con una significancia
del 5%. Sin embargo, dado que no se cumple el supuesto de normalidad,
estos resultados no son confiables, por lo que se requiere aplicar una
prueba no paramétrica.</p>
<p>Dado que las <strong>diferencias no siguen una distribución
normal</strong>, se emplea la <strong>prueba de rangos con signo de
Wilcoxon</strong>, la cual no asume normalidad de las diferencias. En la
siguiente sección de describe este test.</p>
<p>Los resultados obtenidos son:</p>
<pre>
Wilcoxon signed rank test with continuity correction

data:  pant and pdes
V = 116, p-value = 0.9993
alternative hypothesis: true location shift is less than 0
</pre>
<p>El <strong><span class="math inline">\(valor-p\)</span></strong>
obtenido es 0.9993, lo que indica que, con una significancia del 5%,
<strong>no hay suficiente evidencia para rechazar la hipótesis
nula</strong>, es decir, que no existe diferencia significativa en la
mediana de las diferencias entre ambos grupos.</p>
<p>Los códigos implementados son los siguientes:</p>
<pre>
# Datos de las mediciones
pant <- c(104.5, 89, 84.5, 106, 90, 96, 79, 90, 85, 76.5, 91.5, 82.5, 100.5, 89.5, 121.5, 72)
pdes <- c(98, 85.5, 85, 103.5, 88.5, 95, 79.5, 90, 82, 76, 89.5, 81, 99.5, 86.5, 15.5, 70)

# Calcular las diferencias entre pares
dif <- pant - pdes

# Prueba de normalidad de Shapiro-Wilk sobre las diferencias
shapiro_test <- shapiro.test(dif)
print(shapiro_test)

# Prueba t para muestras pareadas (cola inferior)
t_test <- t.test(pant, pdes, 
                 alternative = "less", 
                 mu = 0, 
                 paired = TRUE, 
                 conf.level = 0.95)
print(t_test)

wilcoxon_test <- wilcox.test(pant, pdes, 
                               alternative = "less", 
                               paired = TRUE, 
                               conf.level = 0.95,
                               exact = FALSE,   # Usa aproximación normal cuando hay empates (ties)
                               correct = TRUE)  # Aplica corrección de continuidad
print(wilcoxon_test)
</pre>
<pre class="r"><code># Datos de las mediciones
pant &lt;- c(104.5, 89, 84.5, 106, 90, 96, 79, 90, 85, 76.5, 91.5, 82.5, 100.5, 89.5, 121.5, 72)
pdes &lt;- c(98, 85.5, 85, 103.5, 88.5, 95, 79.5, 90, 82, 76, 89.5, 81, 99.5, 86.5, 15.5, 70)

# Calcular las diferencias entre pares
dif &lt;- pant - pdes

# Prueba de normalidad de Shapiro-Wilk sobre las diferencias
shapiro_test &lt;- shapiro.test(dif)
print(shapiro_test)</code></pre>
<pre><code>
    Shapiro-Wilk normality test

data:  dif
W = 0.32897, p-value = 1.088e-07</code></pre>
<pre class="r"><code># Prueba t para muestras pareadas (cola inferior)
t_test &lt;- t.test(pant, pdes, 
                 alternative = &quot;less&quot;, 
                 mu = 0, 
                 paired = TRUE, 
                 conf.level = 0.95)
print(t_test)</code></pre>
<pre><code>
    Paired t-test

data:  pant and pdes
t = 1.2736, df = 15, p-value = 0.8889
alternative hypothesis: true mean difference is less than 0
95 percent confidence interval:
     -Inf 19.75467
sample estimates:
mean difference 
         8.3125 </code></pre>
<pre class="r"><code>wilcoxon_test &lt;- wilcox.test(pant, pdes, 
                               alternative = &quot;less&quot;, 
                               paired = TRUE, 
                               conf.level = 0.95,
                               exact = FALSE,   # Usa aproximación normal cuando hay empates (ties)
                               correct = TRUE)  # Aplica corrección de continuidad
print(wilcoxon_test)</code></pre>
<pre><code>
    Wilcoxon signed rank test with continuity correction

data:  pant and pdes
V = 116, p-value = 0.9993
alternative hypothesis: true location shift is less than 0</code></pre>
<p>Aunque se aplicó la <strong>prueba t pareada</strong>, su
<strong>resultado no es confiable</strong>, ya que el supuesto de
normalidad no se cumple.</p>
<p>La <strong>prueba no paramétrica de Wilcoxon</strong> tampoco
proporciona evidencia suficiente para afirmar que el programa ha
generado una reducción significativa de peso, con una significancia del
5%.</p>
</p>
</div>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p>Una empresa implementa un <strong>programa de entrenamiento</strong>
con el objetivo de mejorar las habilidades de sus empleados. Para
evaluar la efectividad de las metodologías utilizadas, se forman
<strong>dos grupos</strong> de empleados, cada uno sometido a un método
diferente de capacitación:</p>
<ul>
<li><p><strong>Grupo 1 (G1)</strong>: Compuesto por <strong>36
empleados</strong>.</p></li>
<li><p><strong>Grupo 2 (G2)</strong>: Compuesto por <strong>40
empleados</strong>.</p></li>
</ul>
<p>El interés principal es determinar si <strong>el método aplicado al
segundo grupo (G2) produce mejores resultados que el aplicado al primer
grupo (G1)</strong>.</p>
<p>Sea <span class="math inline">\(\mu_1\)</span> la media poblacional
del desempeño de los empleados entrenados con el <strong>Método
1</strong>, y <span class="math inline">\(\mu_2\)</span> la media
poblacional del desempeño de los empleados entrenados con el
<strong>Método 2</strong>. Se plantea la siguiente prueba de hipótesis
unilateral:</p>
<p><span class="math display">\[
H_0: \mu_1 \geq \mu_2
\]</span></p>
<p><span class="math display">\[
H_1: \mu_1 &lt; \mu_2
\]</span></p>
<p>donde:</p>
<ul>
<li><p><strong><span class="math inline">\(H_0\)</span></strong>
establece que <strong>no hay evidencia suficiente para afirmar que el
método 2 es mejor que el método 1</strong>.</p></li>
<li><p><strong><span class="math inline">\(H_1\)</span></strong> plantea
que <strong>el desempeño promedio del Grupo 2 es significativamente
mayor que el del Grupo 1</strong>, lo que sugiere que el <strong>Método
2 es superior</strong>.</p></li>
</ul>
<p>Los datos de ambos grupos corresponden a los índices de desempeño por
cada método y son los siguientes:</p>
<table>
<colgroup>
<col width="6%" />
<col width="93%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left">Grupo 1</td>
<td align="left">6.8, 6.1, 5.8, 5.9, 5.8, 6.4, 5.7, 6.0, 5.9, 6.4, 6.0,
5.7, 6.5, 6.5, 6.0, 5.9, 5.7, 5.8, 5.9, 5.8, 6.0, 6.0, 5.8, 5.7, 6.1,
5.9, 5.2, 6.3, 5.4, 6.5, 5.5, 5.9, 7.0, 6.4, 5.1, 6.3</td>
</tr>
<tr class="even">
<td align="left">Grupo 2</td>
<td align="left">8.8, 8.5, 8.4, 8.5, 7.6, 8.7, 8.0, 7.9, 8.2, 8.0, 7.8,
8.6, 8.5, 7.9, 8.5, 8.3, 8.4, 8.2, 8.3, 7.9, 8.2, 7.7, 7.8, 7.7, 8.1,
8.0, 8.3, 8.2, 8.1, 8.3, 8.1, 8.8, 7.7, 9.1, 7.6, 8.4, 8.2, 8.3, 8.1,
8.7</td>
</tr>
</tbody>
</table>
<p>Para evaluar si existen diferencias en la distribución de los índices
de desempeño según el método de capacitación aplicado, se generan
gráficos de densidad y boxplots que permiten una visualización
comparativa entre ambos grupos.</p>
<pre>
# Cargar librerías necesarias
library(ggplot2)
library(dplyr)
library(tidyr)

# Definir los datos
grupo1 <- c(6.8, 6.1, 5.8, 5.9, 5.8, 6.4, 5.7, 6.0, 5.9, 6.4, 6.0, 5.7, 
            6.5, 6.5, 6.0, 5.9, 5.7, 5.8, 5.9, 5.8, 6.0, 6.0, 5.8, 5.7, 
            6.1, 5.9, 5.2, 6.3, 5.4, 6.5, 5.5, 5.9, 7.0, 6.4, 5.1, 6.3)

grupo2 <- c(8.8, 8.5, 8.4, 8.5, 7.6, 8.7, 8.0, 7.9, 8.2, 8.0, 7.8, 8.6, 
            8.5, 7.9, 8.5, 8.3, 8.4, 8.2, 8.3, 7.9, 8.2, 7.7, 7.8, 7.7, 
            8.1, 8.0, 8.3, 8.2, 8.1, 8.3, 8.1, 8.8, 7.7, 9.1, 7.6, 8.4, 
            8.2, 8.3, 8.1, 8.7)

# Crear un data frame en formato largo para facilitar los gráficos
datos <- data.frame(
  valor = c(grupo1, grupo2),
  grupo = c(rep("Grupo 1", length(grupo1)), rep("Grupo 2", length(grupo2)))
)

# Gráfico de densidad comparativo
ggplot(datos, aes(x = valor, fill = grupo, color = grupo)) +
  geom_density(alpha = 0.3) +
  labs(title = "Comparación de Densidades entre los Grupos",
       x = "Valor",
       y = "Densidad") +
  theme_minimal()

# Gráfico de boxplot comparativo
ggplot(datos, aes(x = grupo, y = valor, fill = grupo)) +
  geom_boxplot() +
  labs(title = "Comparación de Boxplots entre los Grupos",
       x = "Grupo",
       y = "Valor") +
  theme_minimal()

# Prueba de normalidad de Shapiro-Wilk para cada grupo
shapiro_test_grupo1 <- shapiro.test(grupo1)
shapiro_test_grupo2 <- shapiro.test(grupo2)

# Mostrar resultados de la prueba de normalidad
print("Prueba de normalidad de Shapiro-Wilk para Grupo 1:")
print(shapiro_test_grupo1)

print("Prueba de normalidad de Shapiro-Wilk para Grupo 2:")
print(shapiro_test_grupo2)
</pre>
<pre class="r"><code># Cargar librerías necesarias
library(ggplot2)
library(dplyr)
library(tidyr)

# Definir los datos
grupo1 &lt;- c(6.8, 6.1, 5.8, 5.9, 5.8, 6.4, 5.7, 6.0, 5.9, 6.4, 6.0, 5.7, 
            6.5, 6.5, 6.0, 5.9, 5.7, 5.8, 5.9, 5.8, 6.0, 6.0, 5.8, 5.7, 
            6.1, 5.9, 5.2, 6.3, 5.4, 6.5, 5.5, 5.9, 7.0, 6.4, 5.1, 6.3)

grupo2 &lt;- c(8.8, 8.5, 8.4, 8.5, 7.6, 8.7, 8.0, 7.9, 8.2, 8.0, 7.8, 8.6, 
            8.5, 7.9, 8.5, 8.3, 8.4, 8.2, 8.3, 7.9, 8.2, 7.7, 7.8, 7.7, 
            8.1, 8.0, 8.3, 8.2, 8.1, 8.3, 8.1, 8.8, 7.7, 9.1, 7.6, 8.4, 
            8.2, 8.3, 8.1, 8.7)

# Crear un data frame en formato largo para facilitar los gráficos
datos &lt;- data.frame(
  valor = c(grupo1, grupo2),
  grupo = c(rep(&quot;Grupo 1&quot;, length(grupo1)), rep(&quot;Grupo 2&quot;, length(grupo2)))
)

# Gráfico de densidad comparativo
plot1&lt;-ggplot(datos, aes(x = valor, fill = grupo, color = grupo)) +
  geom_density(alpha = 0.3) +
  labs(title = &quot;Comparación de Densidades entre los Grupos&quot;,
       x = &quot;Valor&quot;,
       y = &quot;Densidad&quot;) +
  theme_minimal()

# Gráfico de boxplot comparativo
plot2&lt;-ggplot(datos, aes(x = grupo, y = valor, fill = grupo)) +
  geom_boxplot() +
  labs(title = &quot;Comparación de Boxplots entre los Grupos&quot;,
       x = &quot;Grupo&quot;,
       y = &quot;Valor&quot;) +
  theme_minimal()

# Prueba de normalidad de Shapiro-Wilk para cada grupo
shapiro_test_grupo1 &lt;- shapiro.test(grupo1)
shapiro_test_grupo2 &lt;- shapiro.test(grupo2)

# Mostrar resultados de la prueba de normalidad
print(&quot;Prueba de normalidad de Shapiro-Wilk para Grupo 1:&quot;)</code></pre>
<pre><code>[1] &quot;Prueba de normalidad de Shapiro-Wilk para Grupo 1:&quot;</code></pre>
<pre class="r"><code>print(shapiro_test_grupo1)</code></pre>
<pre><code>
    Shapiro-Wilk normality test

data:  grupo1
W = 0.96485, p-value = 0.3018</code></pre>
<pre class="r"><code>print(&quot;Prueba de normalidad de Shapiro-Wilk para Grupo 2:&quot;)</code></pre>
<pre><code>[1] &quot;Prueba de normalidad de Shapiro-Wilk para Grupo 2:&quot;</code></pre>
<pre class="r"><code>print(shapiro_test_grupo2)</code></pre>
<pre><code>
    Shapiro-Wilk normality test

data:  grupo2
W = 0.97873, p-value = 0.6424</code></pre>
<p>Para evaluar la adecuación del uso de pruebas paramétricas en la
comparación de los índices de desempeño entre los métodos de
capacitación, se realizó la <strong>prueba de normalidad de
Shapiro-Wilk</strong> en ambas muestras.</p>
<p><span class="math display">\[
H_0: \text{Los índices  del método siguen una distribución normal}
\]</span></p>
<p><span class="math display">\[
H_1: \text{Los índices  del método  no siguen una distribución normal}
\]</span></p>
<p>El nivel de significancia utilizado para la prueba es <strong><span
class="math inline">\(\alpha = 0.05\)</span></strong>. Los valores
obtenidos para cada grupo son:</p>
<ul>
<li><p><strong>Grupo 1</strong>: <span class="math inline">\(valor-p =
0.3018\)</span></p></li>
<li><p><strong>Grupo 2</strong>: <span class="math inline">\(valor-p=
0.6424\)</span></p></li>
</ul>
<p>Dado que en ambos casos los <span
class="math inline">\(valores-p\)</span> son mayores al nivel de
significancia de 0.05, no se encuentra evidencia suficiente para
rechazar la hipótesis nula de normalidad de los índices de cada método.
En consecuencia, se asume que las muestras provienen de distribuciones
normales, lo que permite la aplicación de pruebas paramétricas para la
comparación de los métodos de capacitación.</p>
<pre>
    Shapiro-Wilk normality test

data:  grupo1
W = 0.96485, p-value = 0.3018
</pre>
<pre>
    Shapiro-Wilk normality test

data:  grupo2
W = 0.97873, p-value = 0.6424
</pre>
<p>La <strong>Figura 2.70</strong> presenta las curvas de densidad de
los índices por método. Las distribuciones son aproximadamente
simétricas, lo que respalda la normalidad observada en el test de
Shapiro-Wilk. También refleja que la media del grupo 2 es mayor que la
media del grupo 1.</p>
<p>La <strong>Figura 2.71</strong> presenta los diagramas de caja de los
índices de desempeño por cada método de capacitación. Se observa que las
varianzas parecen similares entre los dos grupos, lo que sugiere que el
supuesto de igualdad de varianzas podría cumplirse. No obstante, se debe
verificar usando un test de hipótesis. Asimismo, se evidencia una
diferencia en las medias de los índices de desempeño entre los grupos,
lo que podría indicar que el método de capacitación aplicado en el Grupo
2 produce mejores resultados en comparación con el Grupo 1.</p>
<br/><br/>
<center>
<img src="img/fig270.png" width="80%" style="display: block; margin: auto;" />
<strong>Figura 2.70</strong> Comparación de la distribución de los
índices por método.
</center>
<p><br/><br/></p>
<br/><br/>
<center>
<img src="img/fig271.png" width="80%" style="display: block; margin: auto;" />
<strong>Figura 2.71</strong> Comparación de la distribución de los
índices por método.
</center>
<p><br/><br/></p>
<p>Antes de aplicar una prueba de hipótesis para comparar las
<strong>medias poblacionales</strong> de los dos métodos de
capacitación, es necesario determinar si las <strong>varianzas
poblacionales</strong> pueden asumirse como <strong>iguales o
diferentes</strong>. Esta información es fundamental para seleccionar la
prueba estadística más adecuada.</p>
<p>Para evaluar si las varianzas poblacionales son <strong>iguales o
distintas</strong>, se plantea la siguiente prueba de hipótesis:</p>
<p><span class="math display">\[
H_0: \sigma^{2}_{1} = \sigma^{2}_{2}
\]</span></p>
<p><span class="math display">\[
H_1: \sigma^{2}_{1} \neq \sigma^{2}_{2}
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span> plantea que las
<strong>varianzas poblacionales son iguales</strong> y, por lo tanto, se
puede aplicar una <strong>prueba t de Student</strong> con varianzas
iguales.</p></li>
<li><p><span class="math inline">\(H_1\)</span> indica que las
<strong>varianzas son diferentes</strong>, en cuyo caso se recomienda
emplear la <strong>prueba t de Welch</strong>, que no asume igualdad de
varianzas.</p></li>
</ul>
<p>Para contrastar esta hipótesis, se utiliza el <strong>test de Fisher
(prueba F para igualdad de varianzas)</strong>, implementado en
<strong>R</strong> mediante la función <code>var.test()</code>. Los
resultados obtenidos son los siguientes:</p>
<pre>
data:  grupo1 and grupo2
F = 1.2975, num df = 35, denom df = 39, p-value = 0.4282
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
    0.6776032 2.5137013
sample estimates:
    ratio of variances 
1.297479 
</pre>
<p>La <strong>prueba de Fisher (prueba F para igualdad de
varianzas)</strong> ha arrojado un <span
class="math inline">\(valor-p\)</span> de 0.4282. Dado que este valor es
<strong>mayor</strong> al nivel de significación predefinido (<span
class="math inline">\(\alpha = 0.05\)</span>), <strong>no se rechaza la
hipótesis nula</strong>. Esto sugiere que <strong>no existe evidencia
suficiente</strong> en la muestra para concluir que las varianzas
poblacionales sean <strong>diferentes</strong>.</p>
<p>Por lo tanto, se asume que las varianzas son
<strong>iguales</strong>, lo que permite utilizar la <strong>prueba t de
Student para muestras independientes</strong> bajo esta suposición.</p>
<p>Dado que el interés es evaluar si la media del <strong>grupo
1</strong> es <strong>menor</strong> que la media del <strong>grupo
2</strong>, se establece la siguiente prueba de hipótesis:</p>
<p><span class="math display">\[
H_0: \mu_{1} \geq \mu_{2}
\]</span></p>
<p><span class="math display">\[
H_1: \mu_{1} &lt; \mu_{2}
\]</span></p>
<p>donde:</p>
<ul>
<li><p><strong><span class="math inline">\(H_0\)</span></strong>
establece que la <strong>media del grupo 1 es mayor o igual</strong> a
la del grupo 2.</p></li>
<li><p><strong><span class="math inline">\(H_1\)</span></strong> plantea
que la <strong>media del grupo 1 es menor</strong> que la del grupo 2,
lo que indicaría que el segundo método de capacitación genera mejores
resultados.</p></li>
</ul>
<p>A continuación, se presentan los códigos utilizados para aplicar los
test estadísticos en <strong>R</strong>:</p>
<pre>
# Test de Fisher 
var.test(grupo1,grupo2)


# Prueba de diferencia de medias con t-test de Student
t.test(grupo1, grupo2,
alternative ="less",
mu = 0, 
paired = FALSE, 
var.equal = TRUE,
conf.level = 0.95)
</pre>
<pre class="r"><code># Test de Fisher 
var.test(grupo1,grupo2)</code></pre>
<pre><code>
    F test to compare two variances

data:  grupo1 and grupo2
F = 1.2975, num df = 35, denom df = 39, p-value = 0.4282
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.6776032 2.5137013
sample estimates:
ratio of variances 
          1.297479 </code></pre>
<pre class="r"><code># Prueba de diferencia de medias con t-test de Student
t.test(grupo1, grupo2,
alternative =&quot;less&quot;,
mu = 0, 
paired = FALSE, 
var.equal = TRUE,
conf.level = 0.95)</code></pre>
<pre><code>
    Two Sample t-test

data:  grupo1 and grupo2
t = -25.413, df = 74, p-value &lt; 2.2e-16
alternative hypothesis: true difference in means is less than 0
95 percent confidence interval:
      -Inf -2.072933
sample estimates:
mean of x mean of y 
 5.991667  8.210000 </code></pre>
<p>El resultado de implementar el <strong>t-test de Student</strong> es
como se muestra:</p>
<pre>
data:  grupo1 and grupo2
t = -25.413, df = 74, p-value < 2.2e-16
alternative hypothesis: true difference in means is less than 0
95 percent confidence interval:
      -Inf -2.072933
sample estimates:
mean of x mean of y 
 5.991667  8.210000 
</pre>
<p>Dado que el <span class="math inline">\(valor-p\)</span> es menor que
<span class="math inline">\(2.2 \times 10^{-16}\)</span>, el cual es
significativamente inferior al nivel de significancia de menos del 1%,
se rechaza la hipótesis nula. Esto indica que existe evidencia
estadísticamente significativa para concluir que la media del grupo 1 es
menor que la media del grupo 2.</p>
</p>
</div>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p>La empresa del <strong>Ejemplo anterior</strong> ha determinado que
el <strong>método de capacitación del Grupo 2</strong> produce mejores
resultados en comparación con el <strong>Grupo 1</strong>. Sin embargo,
con el fin de realizar una <strong>valoración adicional</strong> y
obtener una <strong>visión más general de los métodos
empleados</strong>, se ha decidido comparar los resultados del
<strong>Grupo 2</strong> con un <strong>tercer grupo externo</strong>,
denominado <strong>Grupo 3</strong>.</p>
<p>El objetivo es evaluar si el desempeño del <strong>Grupo 2</strong>
sigue siendo significativamente superior en comparación con el
<strong>Grupo 3</strong>. Para ello, se aplicará una <strong>prueba de
hipótesis sobre la diferencia de medias</strong> entre estos dos
grupos.</p>
<p>Dado que el interés radica en evaluar si la <strong>media del Grupo
2</strong> es <strong>mayor que la media del Grupo 3</strong>, se
establece una <strong>prueba de hipótesis unilateral
derecha</strong>:</p>
<p><span class="math display">\[
H_0: \mu_2 \leq \mu_3
\]</span></p>
<p><span class="math display">\[
H_1: \mu_2 &gt; \mu_3
\]</span></p>
<p>donde:</p>
<ul>
<li><p><strong><span class="math inline">\(H_0\)</span></strong>: La
media del <strong>Grupo 2</strong> es menor o igual a la del
<strong>Grupo 3</strong>.</p></li>
<li><p><strong><span class="math inline">\(H_1\)</span></strong>: La
media del <strong>Grupo 2</strong> es mayor que la del <strong>Grupo
3</strong>, lo que indicaría que el método aplicado al <strong>Grupo
2</strong> sigue siendo superior.</p></li>
</ul>
<p>Para evaluar si existen diferencias en la distribución de los índices
de desempeño según el método de capacitación aplicado, se generan
gráficos de densidad y boxplots que permiten una visualización
comparativa entre ambos grupos:</p>
<pre>
# Cargar librerías necesarias
library(ggplot2)
library(dplyr)
library(tidyr)

# Definir los datos
grupo1 <- c(6.8, 6.1, 5.8, 5.9, 5.8, 6.4, 5.7, 6.0, 5.9, 6.4, 6.0, 5.7, 
            6.5, 6.5, 6.0, 5.9, 5.7, 5.8, 5.9, 5.8, 6.0, 6.0, 5.8, 5.7, 
            6.1, 5.9, 5.2, 6.3, 5.4, 6.5, 5.5, 5.9, 7.0, 6.4, 5.1, 6.3)

grupo2 <- c(8.8, 8.5, 8.4, 8.5, 7.6, 8.7, 8.0, 7.9, 8.2, 8.0, 7.8, 8.6, 
            8.5, 7.9, 8.5, 8.3, 8.4, 8.2, 8.3, 7.9, 8.2, 7.7, 7.8, 7.7, 
            8.1, 8.0, 8.3, 8.2, 8.1, 8.3, 8.1, 8.8, 7.7, 9.1, 7.6, 8.4, 
            8.2, 8.3, 8.1, 8.7)

grupo3 <- c(8.4, 7.5, 6.9, 6.6, 7.0, 5.5, 5.5, 7.9, 6.9, 7.3, 4.7, 5.5, 
            6.7, 8.3, 6.0, 6.3, 5.5, 8.4, 7.1, 5.3, 6.9, 5.5, 7.2, 6.5, 
            6.1, 7.8, 7.4, 6.6, 6.8, 6.0, 6.9, 7.4, 4.9, 6.2, 7.3, 6.2)

# Crear un data frame en formato largo para facilitar los gráficos
datos <- data.frame(
  valor = c(grupo1, grupo2, grupo3),
  grupo = c(rep("Grupo 1", length(grupo1)), 
            rep("Grupo 2", length(grupo2)), 
            rep("Grupo 3", length(grupo3)))
)

# Gráfico de densidad comparativo
plot1 <- ggplot(datos, aes(x = valor, fill = grupo, color = grupo)) +
  geom_density(alpha = 0.3) +
  labs(title = "Comparación de Densidades entre los Grupos",
       x = "Valor",
       y = "Densidad") +
  theme_minimal()

# Gráfico de boxplot comparativo
plot2 <- ggplot(datos, aes(x = grupo, y = valor, fill = grupo)) +
  geom_boxplot() +
  labs(title = "Comparación de Boxplots entre los Grupos",
       x = "Grupo",
       y = "Valor") +
  theme_minimal()

# Prueba de normalidad de Shapiro-Wilk para cada grupo
shapiro_test_grupo1 <- shapiro.test(grupo1)
shapiro_test_grupo2 <- shapiro.test(grupo2)
shapiro_test_grupo3 <- shapiro.test(grupo3)

# Mostrar resultados de la prueba de normalidad
print("Prueba de normalidad de Shapiro-Wilk para Grupo 1:")
print(shapiro_test_grupo1)

print("Prueba de normalidad de Shapiro-Wilk para Grupo 2:")
print(shapiro_test_grupo2)

print("Prueba de normalidad de Shapiro-Wilk para Grupo 3:")
print(shapiro_test_grupo3)

# Imprimir los gráficos
print(plot1)
print(plot2)
</pre>
<pre class="r"><code># Cargar librerías necesarias
library(ggplot2)
library(dplyr)
library(tidyr)

# Definir los datos
grupo1 &lt;- c(6.8, 6.1, 5.8, 5.9, 5.8, 6.4, 5.7, 6.0, 5.9, 6.4, 6.0, 5.7, 
            6.5, 6.5, 6.0, 5.9, 5.7, 5.8, 5.9, 5.8, 6.0, 6.0, 5.8, 5.7, 
            6.1, 5.9, 5.2, 6.3, 5.4, 6.5, 5.5, 5.9, 7.0, 6.4, 5.1, 6.3)

grupo2 &lt;- c(8.8, 8.5, 8.4, 8.5, 7.6, 8.7, 8.0, 7.9, 8.2, 8.0, 7.8, 8.6, 
            8.5, 7.9, 8.5, 8.3, 8.4, 8.2, 8.3, 7.9, 8.2, 7.7, 7.8, 7.7, 
            8.1, 8.0, 8.3, 8.2, 8.1, 8.3, 8.1, 8.8, 7.7, 9.1, 7.6, 8.4, 
            8.2, 8.3, 8.1, 8.7)

grupo3 &lt;- c(8.4, 7.5, 6.9, 6.6, 7.0, 5.5, 5.5, 7.9, 6.9, 7.3, 4.7, 5.5, 
            6.7, 8.3, 6.0, 6.3, 5.5, 8.4, 7.1, 5.3, 6.9, 5.5, 7.2, 6.5, 
            6.1, 7.8, 7.4, 6.6, 6.8, 6.0, 6.9, 7.4, 4.9, 6.2, 7.3, 6.2)

# Crear un data frame en formato largo para facilitar los gráficos
datos &lt;- data.frame(
  valor = c(grupo1, grupo2, grupo3),
  grupo = c(rep(&quot;Grupo 1&quot;, length(grupo1)), 
            rep(&quot;Grupo 2&quot;, length(grupo2)), 
            rep(&quot;Grupo 3&quot;, length(grupo3)))
)

# Gráfico de densidad comparativo
plot1 &lt;- ggplot(datos, aes(x = valor, fill = grupo, color = grupo)) +
  geom_density(alpha = 0.3) +
  labs(title = &quot;Comparación de Densidades entre los Grupos&quot;,
       x = &quot;Valor&quot;,
       y = &quot;Densidad&quot;) +
  theme_minimal()

# Gráfico de boxplot comparativo
plot2 &lt;- ggplot(datos, aes(x = grupo, y = valor, fill = grupo)) +
  geom_boxplot() +
  labs(title = &quot;Comparación de Boxplots entre los Grupos&quot;,
       x = &quot;Grupo&quot;,
       y = &quot;Valor&quot;) +
  theme_minimal()

# Prueba de normalidad de Shapiro-Wilk para cada grupo
shapiro_test_grupo1 &lt;- shapiro.test(grupo1)
shapiro_test_grupo2 &lt;- shapiro.test(grupo2)
shapiro_test_grupo3 &lt;- shapiro.test(grupo3)

# Mostrar resultados de la prueba de normalidad
print(&quot;Prueba de normalidad de Shapiro-Wilk para Grupo 1:&quot;)</code></pre>
<pre><code>[1] &quot;Prueba de normalidad de Shapiro-Wilk para Grupo 1:&quot;</code></pre>
<pre class="r"><code>print(shapiro_test_grupo1)</code></pre>
<pre><code>
    Shapiro-Wilk normality test

data:  grupo1
W = 0.96485, p-value = 0.3018</code></pre>
<pre class="r"><code>print(&quot;Prueba de normalidad de Shapiro-Wilk para Grupo 2:&quot;)</code></pre>
<pre><code>[1] &quot;Prueba de normalidad de Shapiro-Wilk para Grupo 2:&quot;</code></pre>
<pre class="r"><code>print(shapiro_test_grupo2)</code></pre>
<pre><code>
    Shapiro-Wilk normality test

data:  grupo2
W = 0.97873, p-value = 0.6424</code></pre>
<pre class="r"><code>print(&quot;Prueba de normalidad de Shapiro-Wilk para Grupo 3:&quot;)</code></pre>
<pre><code>[1] &quot;Prueba de normalidad de Shapiro-Wilk para Grupo 3:&quot;</code></pre>
<pre class="r"><code>print(shapiro_test_grupo3)</code></pre>
<pre><code>
    Shapiro-Wilk normality test

data:  grupo3
W = 0.97559, p-value = 0.5961</code></pre>
<pre class="r"><code># Imprimir los gráficos
#print(plot1)
#print(plot2)</code></pre>
<p>Dado el resultado del test de normalidad de Shapiro-Wilk para los
índices de desempeño del método 3: <span
class="math inline">\(valor-p\)</span> = 0.5961. El <span
class="math inline">\(valor-p=0.5961\)</span> es mayor que 0.05, por lo
que no se rechaza la hipótesis nula de normalidad. No hay evidencia
suficiente para afirmar que los índices de desempeño del método 3 no
siguen una distribución normal con una significancia del 5%.</p>
<p>La <strong>Figura 2.72</strong> presenta la curva de densidad de los
índices obtenidos mediante el método 3. Se observa que la distribución
de los valores es aproximadamente simétrica, lo que respalda los
resultados obtenidos en la prueba de normalidad de Shapiro-Wilk. Esta
evidencia sugiere que los índices de desempeño del método 3 pueden ser
modelados adecuadamente mediante una distribución normal, permitiendo el
uso de pruebas paramétricas para el análisis estadístico.</p>
<pre>
    Shapiro-Wilk normality test

data:  grupo3
W = 0.97559, p-value = 0.5961
</pre>
<br/><br/>
<center>
<img src="img/fig272.png" width="80%" style="display: block; margin: auto;" />
<strong>Figura 2.72</strong> Comparación de distribuciones de desempeño
de los Grupo 2 y Grupo 3.
</center>
<p><br/><br/></p>
<p>La <strong>Figura 2.73</strong> permite visualizar la comparación
entre los índices obtenidos en los tres métodos de capacitación. Se
observa que aproximadamente el 23% de los valores superiores del método
3 coinciden con el 75% de los valores inferiores del método 2. Esto
sugiere que, si bien el método 2 presenta en general valores más altos,
existe una superposición parcial con el método 3, lo que indica que
algunos participantes del tercer grupo alcanzaron niveles de desempeño
comparables a los del segundo grupo.</p>
<br/><br/>
<center>
<img src="img/fig273.png" width="80%" style="display: block; margin: auto;" />
<strong>Figura 2.73</strong> Comparación de distribuciones de desempeño
de los Grupo 2 y Grupo 3.
</center>
<p><br/><br/></p>
<p>Antes de comparar las medias, es necesario determinar si las
varianzas poblacionales de ambos grupos pueden considerarse iguales o
diferentes. Se utiliza el test de Fisher (prueba F para igualdad de
varianzas), obteniendo los siguientes resultados: El <span
class="math inline">\(valor-p\)</span> obtenido es <span
class="math inline">\(1.33 \times 10^{-8}\)</span>, que es menor que el
nivel de significancia 0.05. Por lo tanto, se rechaza la hipótesis nula,
lo que indica que las varianzas poblacionales de los índices de los
métodos 2 y 3 son significativamente diferentes. Dado que las varianzas
poblacionales no son iguales, se emplea la prueba t de Welch, que no
asume igualdad de varianzas.</p>
<pre>
# Test de Fisher 
var.test(grupo3,grupo2)

# Prueba de diferencia de medias con t-test de Student
t.test(grupo3, grupo2,
alternative ="less",
mu = 0, 
paired = FALSE, 
var.equal = FALSE,
conf.level = 0.95)
</pre>
<pre class="r"><code># Test de Fisher 
var.test(grupo3,grupo2)</code></pre>
<pre><code>
    F test to compare two variances

data:  grupo3 and grupo2
F = 7.2974, num df = 35, denom df = 39, p-value = 1.334e-08
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
  3.811031 14.137763
sample estimates:
ratio of variances 
          7.297388 </code></pre>
<pre class="r"><code># Prueba de diferencia de medias con t-test de Student
t.test(grupo3, grupo2,
alternative =&quot;less&quot;,
mu = 0, 
paired = FALSE, 
var.equal = FALSE,
conf.level = 0.95)</code></pre>
<pre><code>
    Welch Two Sample t-test

data:  grupo3 and grupo2
t = -9.2548, df = 43.571, p-value = 3.781e-12
alternative hypothesis: true difference in means is less than 0
95 percent confidence interval:
      -Inf -1.285811
sample estimates:
mean of x mean of y 
 6.638889  8.210000 </code></pre>
<p>Por tanto, para evaluar si los índices de desempeño en los métodos de
capacitación aplicados a los grupos 3 y 2 presentan diferencias
significativas, se realizan dos pruebas estadísticas: Prueba de igualdad
de varianzas mediante el test de Fisher (prueba F) y Prueba de
diferencia de medias mediante el t-test de Welch para muestras
independientes con varianzas diferentes.</p>
<pre>
F test to compare two variances

data:  grupo3 and grupo2
F = 7.2974, num df = 35, denom df = 39, p-value = 1.334e-08
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
  3.811031 14.137763
sample estimates:
ratio of variances 
          7.297388 
</pre>
<p>Respecto al test de medias, el <span
class="math inline">\(valor-p\)</span> obtenido es <span
class="math inline">\(3.781 \times 10^{-12}\)</span>, que es menor que
0.01. Por lo tanto, se rechaza la hipótesis nula y se acepta la
hipótesis alternativa, lo que indica que la media de los índices del
grupo 2 es significativamente mayor que la del grupo 3 con una
significancia menor al 1%.</p>
<pre>
Welch Two Sample t-test

data:  grupo3 and grupo2
t = -9.2548, df = 43.571, p-value = 3.781e-12
alternative hypothesis: true difference in means is less than 0
95 percent confidence interval:
      -Inf -1.285811
sample estimates:
mean of x mean of y 
 6.638889  8.210000 
</pre>
</p>
</div>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p>El presente análisis tiene como objetivo evaluar si la
<strong>campaña publicitaria</strong> implementada por la empresa logró
<strong>incrementar el conocimiento</strong> de los usuarios sobre el
beneficio de acumulación de millas de viajero al utilizar la tarjeta de
crédito. Para ello, se comparan los resultados de dos encuestas
independientes, realizadas antes y después de la campaña.</p>
<p><strong>Datos de la encuesta</strong>:</p>
<p>Se dispone de la siguiente información:</p>
<ul>
<li><p><strong>Encuesta 1 (Antes de la campaña):</strong></p>
<ul>
<li><p>Tamaño muestral: <span class="math inline">\(n_1 =
100\)</span></p></li>
<li><p>Usuarios que conocían el beneficio: <span
class="math inline">\(x_1 = 57\)</span></p></li>
<li><p>Proporción muestral: <span class="math inline">\(\hat{p}_1 =
\frac{x_1}{n_1} = 0.57\)</span></p></li>
</ul></li>
<li><p><strong>Encuesta 2 (Después de la campaña):</strong></p>
<ul>
<li><p>Tamaño muestral: <span class="math inline">\(n_2 =
150\)</span></p></li>
<li><p>Usuarios que conocían el beneficio: <span
class="math inline">\(x_2 = 87\)</span></p></li>
<li><p>Proporción muestral: <span class="math inline">\(\hat{p}_2 =
\frac{x_2}{n_2} = 0.58\)</span></p></li>
</ul></li>
</ul>
<p>Para determinar si el conocimiento del beneficio aumentó después de
la campaña, se plantea la siguiente prueba de hipótesis:</p>
<p><span class="math display">\[
H_0: P_1 \geq P_2
\]</span></p>
<p><span class="math display">\[
H_1: P_1 &lt; P_2
\]</span></p>
<p>donde:</p>
<ul>
<li><p><strong><span class="math inline">\(H_0\)</span></strong>: La
proporción de usuarios que conocen el beneficio antes de la campaña es
mayor o igual a la proporción después de la campaña, lo que sugiere que
la campaña no tuvo un impacto positivo.</p></li>
<li><p><strong><span class="math inline">\(H_1\)</span></strong>: La
proporción de usuarios que conocen el beneficio <strong>es mayor después
de la campaña</strong>, lo que indicaría que la estrategia publicitaria
fue efectiva.</p></li>
</ul>
<p>El siguiente código implementa el <strong>test de proporciones para
muestras independientes</strong>, empleando la función
<code>prop.test()</code> en <strong>R</strong>:</p>
<pre>
prop.test(c(57,87),c(100,150),
p = NULL,
alternative = "less",
conf.level = 0.95)
</pre>
<pre class="r"><code>prop.test(c(57,87),c(100,150),
p = NULL,
alternative = &quot;less&quot;,
conf.level = 0.95)</code></pre>
<pre><code>
    2-sample test for equality of proportions with continuity correction

data:  c(57, 87) out of c(100, 150)
X-squared = 0.00068243, df = 1, p-value = 0.4896
alternative hypothesis: less
95 percent confidence interval:
 -1.0000000  0.1033338
sample estimates:
prop 1 prop 2 
  0.57   0.58 </code></pre>
<p>El <span class="math inline">\(valor-p\)</span> obtenido es 0.4896,
lo que implica que no se rechaza la hipótesis nula con una significancia
del 5%. Por tanto, no existe evidencia estadística suficiente para
concluir que la proporción de usuarios que conocen el beneficio después
de la campaña es mayor que la proporción antes de la campaña. Esto
sugiere, que con una significancia del 5% que la campaña publicitaria no
tuvo un impacto significativo en el conocimiento del beneficio de
acumulación de millas.</p>
<pre>

    2-sample test for equality of proportions with continuity correction

data:  c(57, 87) out of c(100, 150)
X-squared = 0.00068243, df = 1, p-value = 0.4896
alternative hypothesis: less
95 percent confidence interval:
 -1.0000000  0.1033338
sample estimates:
prop 1 prop 2 
  0.57   0.58 
</pre>
</p>
</div>
</br></br>
<h2>
Relaciones entre la potencia, el tamaño de los efectos y el tamaño de la
muestra
</h2>
<p>Al realizar una <strong>prueba t de Student</strong> para la
comparación de <strong>medias entre dos grupos independientes</strong>,
es fundamental analizar el impacto que tienen tanto <strong>el tamaño
del efecto</strong> como el <strong>tamaño muestral</strong> en la
<strong>potencia estadística</strong> de la prueba.</p>
<p>Sin embargo, cuando los tamaños de los grupos <strong>son muy
desbalanceados</strong>, la potencia puede <strong>verse afectada
negativamente</strong>, incluso cuando el tamaño del efecto es
considerablemente grande. Desequilibrios extremos en el tamaño de los
grupos pueden <strong>reducir la precisión</strong> de la estimación y,
en consecuencia, <strong>disminuir la capacidad de la prueba para
detectar diferencias reales</strong>.</p>
<p>La <strong>potencia de una prueba estadística</strong> se define
formalmente como la <strong>probabilidad de rechazar la hipótesis nula
cuando la hipótesis alternativa es verdadera</strong>. Es decir, mide la
<strong>capacidad de la prueba</strong> para detectar una diferencia
real entre los grupos cuando esta realmente existe.</p>
<p>De manera práctica, si una prueba estadística <strong>tiene baja
potencia</strong>, existe un <strong>riesgo elevado</strong> de cometer
un <strong>error de tipo II</strong>, es decir, de <strong>no detectar
una diferencia significativa</strong> cuando en realidad la diferencia
existe en la población.</p>
<p>Existen dos factores principales que afectan la <strong>potencia de
la prueba</strong>:</p>
<ol style="list-style-type: decimal">
<li><p><strong>El tamaño del efecto <span
class="math inline">\(\left(d\right)\)</span></strong>: Cuanto
<strong>mayor</strong> es la diferencia entre las medias poblacionales
en relación con la variabilidad de los datos, <strong>mayor será la
potencia</strong> de la prueba.</p></li>
<li><p><strong>El tamaño muestral (<span
class="math inline">\(n\)</span>)</strong>: Con <strong>tamaños
muestrales más grandes</strong>, la variabilidad en la estimación de las
medias disminuye, lo que incrementa la potencia de la prueba.</p></li>
</ol>
<p>A continuación, se presentan <strong>simulaciones</strong> que
muestran cómo el <strong>tamaño muestral</strong> y el <strong>tamaño
del efecto</strong> afectan la <strong>potencia de la prueba t de
Student</strong>. Se emplea la función <code>power.t.test()</code> en
<strong>R</strong> para calcular la potencia bajo diferentes
escenarios.</p>
<p>Los tamaños de muestra se asumen iguales en ambos grupos, ya que el
argumento <code>n</code> en <code>power.t.test()</code> se refiere al
tamaño de muestra por grupo en una <strong>prueba t de dos muestras
independientes</strong>. En <code>type="two.sample"</code>, la función
asume por defecto que ambos grupos tienen el mismo tamaño de
muestra.</p>
<p>Si deseas especificar tamaños de muestra diferentes para cada grupo,
debes usar <code>power.t.test()</code> de otra forma, o bien emplear
<code>pwr.t2n.test()</code> de la librería <code>pwr</code>.</p>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p><strong>Variando los tamaños de los efectos: </strong></p>
<p>En el análisis de potencia estadística, se busca modelar la relación
entre el <strong>tamaño muestral</strong> y la <strong>potencia de la
prueba</strong>, manteniendo <strong>constante el nivel de
significancia</strong> (<span class="math inline">\(\alpha =
0.05\)</span>). Este análisis permite evaluar cómo la cantidad de datos
recopilados influye en la capacidad de la prueba para detectar efectos
reales en la población.</p>
<p>A continuación, se presentan los resultados de la simulación para
distintos tamaños del <strong>efecto de Cohen <span
class="math inline">\(\left(d\right)\)</span></strong>, los cuales se
categorizan de la siguiente manera:</p>
<ul>
<li><p><strong>Muy pequeño:</strong> <span class="math inline">\(d =
0.1\)</span></p></li>
<li><p><strong>Pequeño:</strong> <span class="math inline">\(d =
0.2\)</span></p></li>
<li><p><strong>Mediano:</strong> <span class="math inline">\(d =
0.5\)</span></p></li>
<li><p><strong>Grande:</strong> <span class="math inline">\(d =
0.8\)</span></p></li>
</ul>
<p>Las figuras siguientes ilustran la relación entre el tamaño de la
muestra y la potencia estadística para cada uno de estos escenarios,
permitiendo visualizar cómo el incremento en el tamaño muestral
<strong>aumenta la probabilidad de detectar diferencias
significativas</strong> cuando realmente existen.</p>
<p>La función <code>power.t.test</code> se usa para calcular la potencia
estadística, el tamaño de la muestra, el nivel de significancia o el
tamaño del efecto en una prueba t. En este caso, el código está
configurado para una prueba t para <strong>dos muestras
independientes</strong> (´type=“two.sample”´).</p>
<pre>
#Sys.setlocale("LC_ALL", "es_ES.UTF-8")

#Se necesita el paquete pwr 
if(!require(pwr)){install.packages("pwr");library("pwr")}

# t-TEST
# Se aplicará power.t.test del paquete stats (ya en R). Calcula la potencia de la prueba t de una o dos muestras, o determina los parámetros para obtener un valor particular de la potencia.

d<-seq(.1,2,by=.1) # 20 tamaños de los efectos
n<-1:150 # Tamaños muestrales

t.test.power.effect <-as.data.frame(do.call("cbind",lapply(1:length(d),function(i)
  {
        sapply(1:length(n),function(j)
        {
            power.t.test(n=n[j],d=d[i],sig.level=0.05,power=NULL,type= "two.sample")$power
        })
    })))

# Si algunas potencias no se pueden calcular, se ajustan a cero:
t.test.power.effect[is.na(t.test.power.effect)] <- 0 
colnames(t.test.power.effect)<-paste (d,"effect size")

#Graficando los resultados

prueba <-t.test.power.effect #data frame de 150 X 20 (para graficar)
cuts_num<-c(2,5,8) # cortes

#Cortes basados en: Cohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum Associates, Publishers.
cuts_cat<-c("pequeño","medio","grande") 

columnas <- 1:ncol(prueba) #Lista de los valores 1:20
color_linea<-rainbow(length(columnas), alpha=.5) # Lista de 20 colores
grosor_linea=3 # Grosor de la línea

#Para el tipo de línea: (“blank”, “solid”, “dashed”, “dotted”, “dotdash”, “longdash”, “twodash”) ó  (0, 1, 2, 3, 4, 5, 6). 
#Note que lty = “solid” is idéntica a lty=1.

tipo_linea <- rep(1,length(color_linea))        #Repetir length(color)=20 veces el 1
tipo_linea[cuts_num]<-c(2:(length(cuts_num)+1)) #Asignar 2, 3, 4 en las posiciones 2, 5, 8 de tipo_linea

#Resaltar posiciones importantes
cuts_num<-c(2,5,8) # Cortes

#Cortes basados en: Cohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum Associates, Publishers.
cuts_cat<-c("pequeño","medio","grande") 
color_linea[cuts_num]<-c("black")

efecto <- d # Listado de los 20 valores de 20
efecto[cuts_num] <- cuts_cat  #Reemplazar en "efecto" las posiciones cuts_num (2, 5, 8) por las categorías de cuts_cat

par(fig=c(0,.8,0,1),new=TRUE)

#Gráfica
plot(1, type="n", #no produce puntos ni líneas
     frame.plot=FALSE, 
     xlab="Tamaño muestral", ylab="Potencia", 
     xlim=c(1,150),  ylim=c(0,1), 
     main="t-Test", axes = FALSE)

#Editando los ejes, grid, etc.
abline(v=seq(0,150,by=10), col = "lightgray", lty = "dotted") # Grid vertical
abline(h=seq(0,1,by=.05), col = "lightgray", lty = "dotted")  # Grid horizontal
axis(1,seq(0,150,by=10)) # Números en eje X
axis(2,seq(0,1,by=.05))  # Números en eje Y

#Plot de las lineas 
#columnas <- 1:ncol(prueba) # lista de los valores 1:20
for(i in 1:length(columnas)) #length(columnas)=20
  {
  lines(1:150,
        #prueba (data frame de 150 X 20, para graficar)
        #columna <- 1:ncol(prueba) listado de valores 1:20 
        prueba[,columnas[i]], #filtrar "prueba" para valor de columna
        col=color_linea[i],   #color_linea[cuts_num]<-c("black")
        lwd=grosor_linea,     #grosor de cada linea
        lty=tipo_linea[i]     #tipo_linea[cuts_num]<-c(2:(length(cuts_num)+1))
       )
  }

#Leyendas
par(fig=c(.65,1,0,1),new=TRUE)
plot.new()
legend("top",legend=efecto, col=color_linea, lwd=3, lty=tipo_linea, title="Tamaño efecto", 
        bty="n" #Opciones: o (complete box), n (no box), 7, L, C, U
      )
</pre>
<br/><br/>
<center>
<img src="img/fig274.png" width="80%" style="display: block; margin: auto;" />
<strong>Figura 2.74</strong> Comparación de la potencia del t-test
variando el tamaño del efecto y el tamaño de muestra.
</center>
<p><br/><br/></p>
<pre>
library(ggplot2)
library(reshape)
library(plotly)

obj <- cbind(size=1:150, prueba) #Agregando el tamaño al data frame "prueba" 

# Usar melt y unir con "effect" para el mapeo
#El data frame "obj" se reconstruye con respecto al parámetro id="size". 
melted <- cbind(reshape::melt(obj, id="size"), effect=rep(d,each=150)) 

p<- ggplot(data=melted, aes(x=size, y=value, color=as.factor(effect))) + 
        geom_line(size=0.7,alpha=.5) +
        ylab("Potencia") + 
        xlab("Tamaño muestral") + 
        ggtitle("t-Test")+
        theme_bw() +
        #guides(fill=guide_legend(title="Efecto"))
        #scale_fill_discrete(name = "Efecto")
        #labs(fill='Efecto') 
        #scale_fill_manual("Efecto"#,values=c("orange","red")
        scale_color_discrete(name = "Tamaño del efecto")    
                             
# Interactive plot
plotly::ggplotly(p)
</pre>
<br/><br/>
<center>
<img src="img/fig275.png" width="80%" style="display: block; margin: auto;" />
<strong>Figura 2.75</strong> Comparación de la potencia del t-test
variando el tamaño del efecto y el tamaño de muestra.
</center>
<p><br/><br/></p>
</p>
</div>
<p>En el <strong>Ejemplo 7.2</strong> del recurso <a
href="https://rpubs.com/hllinas/MgEst_Hipotesis_teoriaR">RPubs</a>, se
presentan <strong>simulaciones</strong> que ilustran cómo el
<strong>tamaño muestral</strong> y el <strong>tamaño del efecto</strong>
influyen en la <strong>potencia estadística</strong> de la
<strong>prueba t de Student</strong>. Para este análisis, se emplea la
función <code>pwr.t2n.test</code> en <strong>R</strong>, lo que permite
cuantificar la potencia bajo distintos escenarios experimentales.</p>
<p>Para evaluar la influencia del <strong>tamaño del efecto <span
class="math inline">\(\left(d\right)\)</span></strong> en la
<strong>potencia estadística</strong>, se modela su relación manteniendo
constante el <strong>nivel de significancia</strong> (<span
class="math inline">\(\alpha = 0.05\)</span>). Este análisis permite
comprender cómo la magnitud del efecto influye en la capacidad de una
prueba estadística para detectar diferencias significativas entre
grupos.</p>
<p>El análisis se lleva a cabo utilizando distintos tamaños de muestra,
representados por:</p>
<ul>
<li><p><strong><span class="math inline">\(n_1\)</span></strong>: Número
de sujetos en el <strong>Grupo 1</strong></p></li>
<li><p><strong><span class="math inline">\(n_2\)</span></strong>: Número
de sujetos en el <strong>Grupo 2</strong></p></li>
</ul>
<p>Dado un tamaño muestral fijo, se exploran distintos valores de
<strong><span class="math inline">\(d\)</span></strong> para observar su
impacto en la potencia de la prueba. A través de esta evaluación, se
pueden identificar los escenarios en los que el tamaño del efecto
permite alcanzar una potencia adecuada para el estudio.</p>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
