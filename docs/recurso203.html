<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Métodos y Simulación Estadística" />


<title>Variables conjuntas</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"> </a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Inicio
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Probabilidad
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso101.html">Introducción</a>
    </li>
    <li>
      <a href="recurso102.html">Conceptos Básicos</a>
    </li>
    <li>
      <a href="recurso103.html">Enfoques y Postulados</a>
    </li>
    <li>
      <a href="recurso104.html">Tipos de Probabilidad</a>
    </li>
    <li>
      <a href="recurso104b.html">Independencia</a>
    </li>
    <li>
      <a href="recurso104c.html">Teorema de Bayes</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Variable Aleatoria
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso201.html">Variable Aleatoria: Univariado</a>
    </li>
    <li>
      <a href="recurso202.html">Valor Esperado</a>
    </li>
    <li>
      <a href="recurso203.html">Variables Conjuntas</a>
    </li>
    <li>
      <a href="recurso204.html">Modelos Discretos: Univariado</a>
    </li>
    <li>
      <a href="recurso205.html">Modelos Continuos: Univariado</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Inferencia Estadística
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso301.html">Conceptos Básicos</a>
    </li>
    <li>
      <a href="recurso302.html">Estimación Puntual</a>
    </li>
    <li>
      <a href="recurso305.html">Teorema del Límite Central</a>
    </li>
    <li>
      <a href="recurso303.html">Propiedades de los Estimadores</a>
    </li>
    <li>
      <a href="recurso304.html">Métodos de Estimación</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Intervalos de Confianza
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso401.html">Paramétrico: Una Población</a>
    </li>
    <li>
      <a href="recurso402.html">Paramétrico: Dos Poblaciones</a>
    </li>
    <li>
      <a href="recurso403.html">Estimación no Paramétrica</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pruebas de Hipótesis
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso501.html">Introducción</a>
    </li>
    <li>
      <a href="recurso502.html">Paramétrico: Una Población</a>
    </li>
    <li>
      <a href="recurso503.html">Paramétrico: Dos Poblaciones</a>
    </li>
    <li>
      <a href="recurso504.html">Pruebas no Paramétricas</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Casos y Simulaciones
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso404.html">Caso 1</a>
    </li>
    <li>
      <a href="recurso405.html">Caso 2</a>
    </li>
    <li>
      <a href="recurso406.html">Simulación 1</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Referencias
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso1000.html">Referencias</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore"><span
style="color:#686868"><strong>Variables conjuntas</strong></span></h1>
<h4 class="author">Métodos y Simulación Estadística</h4>

</div>


<p>Cuando se analizan dos variables simultáneamente, se forma una
<strong>variable aleatoria bivariada</strong> <span
class="math inline">\((X, Y)\)</span>, definida sobre un plano. La
<strong>probabilidad conjunta</strong> de <span
class="math inline">\((X, Y)\)</span> describe la probabilidad de que
ambas variables tomen valores específicos simultáneamente. Esta
probabilidad genera una <strong>superficie tridimensional</strong>, como
se ilustra en la <strong>Figura 2.15</strong> que corresponde a una
normal bivariada.</p>
<br/><br/>
<center>
<img src="img/normal_bi.png" width="80%" style="display: block; margin: auto;" />
<strong>Figura 2.15</strong> Distribución normal bivariada.
</center>
<p><br/><br/></p>
</br></br>
<h2>
Introducción
</h2>
<p>En muchos experimentos, los resultados son influenciados por
múltiples variables. Ejemplos comunes incluyen:</p>
<ul>
<li><p>Precio de un producto y su volumen de ventas.</p></li>
<li><p>Tiempo de preparación para un examen y la calificación
obtenida.</p></li>
<li><p>Cantidad de arena y cemento en una mezcla de concreto.</p></li>
<li><p>Cantidad de abono aplicado y la producción de una
planta.</p></li>
</ul>
<p>En estos casos, es necesario emplear una función de densidad que
describa la probabilidad conjunta de ambas variables. Esta función
caracteriza cómo se comportan <strong>simultáneamente</strong> las
variables involucradas. Se puede analizar la relación entre las
variables:</p>
<ul>
<li><p><strong>Continua-continua:</strong> Ambas variables son
continuas.</p></li>
<li><p><strong>Discreta-discreta:</strong> Ambas variables son
discretas.</p></li>
<li><p><strong>Continua-discreta:</strong> Una variable es continua y la
otra es discreta.</p></li>
</ul>
<p>Esta guía se centra en los casos más representativos:</p>
<ul>
<li><p><strong>Discreta-discreta</strong>: Ejemplificado mediante tablas
de probabilidad conjunta y distribuciones marginales.</p></li>
<li><p><strong>Continua-continua:</strong> Ilustrado mediante funciones
de densidad conjunta y gráficos de superficies.</p></li>
</ul>
</br></br>
<h2>
Discreto-discreto
</h2>
</br></br>
<h3>
Función de distribución de probabilidad conjunta
</h3>
<p>Cuando <strong><span class="math inline">\(X\)</span></strong> y
<strong><span class="math inline">\(Y\)</span></strong> son variables
aleatorias discretas, la <strong>función de probabilidad
conjunta</strong> se define como: <span class="math display">\[
f_{X,Y}(x,y) = P(X = x, Y = y)
\]</span> Esta función representa la probabilidad de que <span
class="math inline">\(X\)</span> tome el valor <span
class="math inline">\(x\)</span> y <span
class="math inline">\(Y\)</span> tome el valor <span
class="math inline">\(y\)</span> simultáneamente.</p>
</br></br>
<h3>
Propiedades de la distribución conjunta
</h3>
<p>Para ser válida, la función de distribución de probabilidad conjunta
debe cumplir con las siguientes características:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Totalidad de la probabilidad:</strong> La suma de todas
las probabilidades conjuntas es igual a 1: <span class="math display">\[
\sum_{x=x_{(1)}}^{x_{(n)}} \sum_{y=y_{(1)}}^{y_{(n)}} f_{X,Y}(x,y) = 1
\]</span> Esto asegura que la probabilidad total cubre todos los
resultados posibles.</p></li>
<li><p><strong>No negatividad:</strong> Todas las probabilidades deben
ser no negativas: <span class="math display">\[
f_{X,Y}(x,y) \geq 0 \quad \text{para todo } x,y
\]</span> Esta función describe la probabilidad de ocurrencia simultánea
de dos eventos discretos. Se suele representar mediante una
<strong>tabla de probabilidad conjunta</strong>, donde las filas
corresponden a valores de <span class="math inline">\(X\)</span> y las
columnas a valores de <span class="math inline">\(Y\)</span>.</p></li>
</ol>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p>Considere las variables:</p>
<ul>
<li><p><strong><span class="math inline">\(X\)</span>:</strong> Número
de fallas de una máquina por día, con <span class="math inline">\(R_X =
\{1,2,3\}\)</span>.</p></li>
<li><p><strong><span class="math inline">\(Y\)</span>:</strong> Número
de veces que el operario llama al técnico, con <span
class="math inline">\(R_Y = \{1,2,3\}\)</span>.</p></li>
</ul>
<p>La función de probabilidad conjunta <span
class="math inline">\(f_{X,Y}(x,y)\)</span>, que modela el número de
fallas y el número de llamadas, está dada en la <strong>Tabla
2.7</strong>. En esta, se observa que la probabilidad de que el operario
realice una llamada por una falla es 0.05, mientras que la probabilidad
de que realice dos llamadas por dos fallas es 0.10.</p>
<br/><br/>
<center>
<strong>Tabla 2.7</strong> Distribución conjunta de <span
class="math inline">\(X\)</span>, <span
class="math inline">\(Y\)</span>.
</center>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
<th align="center"><span class="math inline">\(y\)</span></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center"><span
class="math inline">\(f_{X,Y}(x,y)\)</span></td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(x\)</span></td>
<td align="center">1</td>
<td align="center">0.05</td>
<td align="center">0.05</td>
<td align="center">0.10</td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center">2</td>
<td align="center">0.05</td>
<td align="center">0.10</td>
<td align="center">0.35</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">3</td>
<td align="center">0</td>
<td align="center">0.20</td>
<td align="center">0.10</td>
</tr>
</tbody>
</table>
<p>Los valores de la <strong>Tabla 2.7</strong> son no negativos y
cumplen que su suma es igual a 1. Esto se puede verificar con los
siguientes códigos en <strong>R</strong>:</p>
<pre>
fxy <- matrix(c(0.05, 0.05, 0.00,
                0.05, 0.10, 0.20,
                0.10, 0.35, 0.10),
              ncol = 3, byrow = FALSE)
colnames(fxy) <- c("Y=1", "Y=2", "Y=3")
rownames(fxy) <- c("X=1", "X=2", "X=3")
print(fxy)

suma_total <- sum(fxy)
print(paste("Suma total: ", suma_total))
</pre>
<p>La función de probabilidad conjunta <span
class="math inline">\(f_{X,Y}(x,y)\)</span> se puede representar
mediante un gráfico tridimensional, como se muestra en la <strong>Figura
2.16</strong>. En el plano <span class="math inline">\(X\)</span>-<span
class="math inline">\(Y\)</span>, se ubican los valores conjuntos de las
variables, mientras que la altura de las rectas sobre cada punto indica
la probabilidad correspondiente en el eje <span
class="math inline">\(Z\)</span>. El gráfico se puede obtener con los
siguientes códigos:</p>
<pre>
library(plot3D)

# Valores de fxy, X y Y proporcionados
fxy <- matrix(c(0.05, 0.05, 0.00,
                0.05, 0.10, 0.20,
                0.10, 0.35, 0.10),
              ncol = 3, byrow = FALSE)
colnames(fxy) <- c("Y=1", "Y=2", "Y=3")
rownames(fxy) <- c("X=1", "X=2", "X=3")
print(fxy)

x <- rep(1:3, each = 3)
y <- rep(1:3, times = 3)
fxy_vals <- as.vector(fxy)


# Gráfico 3D 
scatter3D(x = x, 
          y = y, 
          z = fxy_vals,
          colvar = NULL, col = "blue",
          pch = 19, cex = 1.5,
          phi = 20, theta = 45,
          zlab = "f(x,y)", xlab = "X", ylab = "Y",
          bty = "b2",
          col.panel = "steelblue",
          col.grid = "darkblue")

# Añadir líneas 
for (i in 1:length(x)) {
  lines3D(x = rep(x[i], 2),
          y = rep(y[i], 2),
          z = c(0, fxy_vals[i]),
          col = "blue",
          lwd = 2,
          add = TRUE)
}
</pre>
<br/><br/>
<center>
<img src="img/plot3Discretas.png" width="80%" style="display: block; margin: auto;" />
<strong>Figura 2.16</strong> Distribución conjunta discreta-discreta.
</center>
<p><br/><br/></p>
</p>
</div>
</br></br>
<h3>
Distribución marginal
</h3>
<p>A partir de la <strong>función de distribución conjunta</strong> de
dos variables aleatorias, se pueden obtener las <strong>distribuciones
marginales</strong>, las cuales describen el comportamiento individual
de cada variable, sin considerar la otra. Estas distribuciones se
denotan comúnmente como <span class="math inline">\(g(x)\)</span> para
<span class="math inline">\(X\)</span> y <span
class="math inline">\(h(y)\)</span> para <span
class="math inline">\(Y\)</span>.</p>
<p>Si <span class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> son <strong>variables aleatorias
discretas</strong>, entonces:</p>
<ul>
<li><p>La distribución marginal de <span
class="math inline">\(X\)</span>, que representa la probabilidad de cada
valor de <span class="math inline">\(X\)</span>, se calcula como:</p>
<p><span class="math display">\[
g(x) = f_{X}(x) = \sum_{y=y_{(1)}}^{y_{(n)}} f_{X,Y}(x,y)
\]</span></p>
<p>Esta suma acumula todas las probabilidades conjuntas correspondientes
a un valor fijo de <span class="math inline">\(X\)</span>.</p></li>
<li><p>De manera análoga, la distribución marginal de <span
class="math inline">\(Y\)</span> está dada por:</p>
<p><span class="math display">\[
h(y) = f_{Y}(y) = \sum_{x=x_{(1)}}^{x_{(n)}} f_{X,Y}(x,y)
\]</span></p>
<p>En este caso, la suma acumula todas las probabilidades conjuntas
asociadas a un valor fijo de <span
class="math inline">\(Y\)</span>.</p></li>
</ul>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p>Este ejemplo ilustra cómo obtener las <strong>funciones
marginales</strong> <span class="math inline">\(g(x)\)</span> y <span
class="math inline">\(h(y)\)</span> a partir de la <strong>Tabla
2.7</strong> de distribución conjunta.</p>
<p>La función marginal de <span class="math inline">\(X\)</span> se
obtiene <strong>sumando las probabilidades por columnas</strong>, lo que
equivale a acumular todas las probabilidades asociadas a <span
class="math inline">\(Y\)</span> para cada valor de <span
class="math inline">\(X\)</span>. El siguiente código en
<strong>R</strong> realiza este cálculo:</p>
<pre>
# Valores de fxy, X y Y proporcionados
fxy <- matrix(c(0.05, 0.05, 0.00,
                0.05, 0.10, 0.20,
                0.10, 0.35, 0.10),
              ncol = 3, byrow = FALSE)
colnames(fxy) <- c("Y=1", "Y=2", "Y=3")
rownames(fxy) <- c("X=1", "X=2", "X=3")

# Calcula la suma marginal por filas (suma sobre Y) para obtener g(x)
gx <- addmargins(fxy, 1)

# Asigna nombres a las filas, incluyendo la fila de sumas g(x)
rownames(gx) <- c("1", "2", "3", "g(x)")

# Tabla resultante gx
print(gx)
</pre>
<p>La salida computacional muestra los valores de la distribución
marginal <span class="math inline">\(g(x)\)</span>:</p>
<pre>
      Y=1  Y=2  Y=3
1    0.05 0.05 0.10
2    0.05 0.10 0.35
3    0.00 0.20 0.10
g(x) 0.10 0.35 0.55
</pre>
<p>La función marginal de <span class="math inline">\(Y\)</span> se
obtiene sumando las probabilidades por filas, es decir, acumulando todas
las probabilidades de <span class="math inline">\(X\)</span> para cada
valor de <span class="math inline">\(Y\)</span>. El siguiente código en
<strong>R</strong> realiza este cálculo:</p>
<pre>
# Valores de fxy, X y Y proporcionados
fxy <- matrix(c(0.05, 0.05, 0.00,
                0.05, 0.10, 0.20,
                0.10, 0.35, 0.10),
              ncol = 3, byrow = FALSE)
colnames(fxy) <- c("Y=1", "Y=2", "Y=3")
rownames(fxy) <- c("X=1", "X=2", "X=3")

# Calcula la suma marginal por columnas (suma sobre X) para obtener h(y)
hy <- addmargins(fxy, 2)

# Asigna nombres a las columnas, incluyendo la columna de sumas h(y)
colnames(hy) <- c("1", "2", "3", "h(y)")

# Mostra la tabla resultante hy
print(hy)
</pre>
<p>La salida computacional muestra los valores de la distribución
marginal <span class="math inline">\(h(y)\)</span>:</p>
<pre>
       1    2    3 h(y)
X=1 0.05 0.05 0.10  0.2
X=2 0.05 0.10 0.35  0.5
X=3 0.00 0.20 0.10  0.3
</pre>
</p>
</div>
<!-- </br></br> -->
<!-- <h3>Función de distribución conjunta acumulada </h3> -->
<!-- Si $X$ y $Y$ son **variables aleatorias discretas**, su función de distribución conjunta acumulada $F_{X,Y}(x,y)$ se expresa como: -->
<!-- $$ -->
<!-- F_{X,Y}(x,y) = \sum_{t_x = -\infty}^{x} \sum_{t_y = -\infty}^{y} f_{X,Y}t_x,t_y) -->
<!-- $$ -->
<!-- </br></br> -->
<!-- <h4>Propiedades de la función de distribución conjunta acumulada $F_{X,Y}(x,y)$</h4> -->
<!-- **1. Límites:** -->
<!-- - En los extremos negativos, la probabilidad acumulada es cero: -->
<!--   $$ -->
<!--   F_{X,Y}(-\infty, -\infty) = 0 -->
<!--   $$ -->
<!-- - En los extremos positivos, la probabilidad acumulada es uno: -->
<!--   $$ -->
<!--   F_{X,Y}(+\infty, +\infty) = 1 -->
<!--   $$ -->
<!-- **2. Monotonía:** -->
<!-- - $F_{X,Y}(x,y)$ es **monótonamente no decreciente**, lo que significa que: -->
<!--   - Si $x_1 \leq x_2$, entonces $F_{X,Y}(x_1,y) \leq F_{X,Y}(x_2,y)$. -->
<!--   - Si $y_1 \leq y_2$, entonces $F_{X,Y}(x,y_1) \leq F_{X,Y}(x,y_2)$. -->
<!--  **3. Relaciones marginales:** -->
<!-- - La distribución marginal de $X$ se obtiene haciendo tender $y$ a infinito: -->
<!--   $$ -->
<!--   F_X(x) = \lim_{y \to +\infty} F_{X,Y}(x,y) -->
<!--   $$ -->
<!-- - La distribución marginal de $Y$ se obtiene haciendo tender $x$ a infinito: -->
<!--   $$ -->
<!--   F_Y(y) = \lim_{x \to +\infty} F_{X,Y}(x,y) -->
<!--   $$ -->
<!-- Estas propiedades son esenciales garantizar la coherencia de la función de distribución acumulada. -->
<!-- </br></br> -->
<!-- <div class="caja-ejemplo"> -->
<!-- <h3>Ejemplo:</h3> -->
<!-- <p> -->
<!-- Este ejemplo ilustra cómo se calcula la **función de distribución acumulada conjunta (FDA conjunta)**, sumando las probabilidades de la distribución conjunta hasta la posición $(2,2)$. -->
<!-- La FDA conjunta se obtiene mediante la **suma acumulada** de las probabilidades sobre filas y columnas hasta los valores observados: -->
<!-- $$ -->
<!-- \begin{equation} -->
<!-- \begin{array}{rl} -->
<!-- F(2,2) =  & \sum_{x=1}^{2} \sum_{y=1}^{2} f_{X,Y}(x,y)  \\ -->
<!--          = & f(1,1) + f(1,2) + f(2,1) + f(2,2) \\ -->
<!--          = & 0.05 + 0.05 + 0.05 + 0.10  \\ -->
<!--          = & 0.25 -->
<!-- \end{array} -->
<!-- \end{equation} -->
<!-- $$  -->
<!-- </p> -->
<!-- </div> -->
</br></br>
<h3>
Función de probabilidad condicional
</h3>
<p>La <strong>función de probabilidad condicional</strong> describe cómo
se distribuye la probabilidad de <span class="math inline">\(X\)</span>
cuando se conoce que <span class="math inline">\(Y\)</span> ha tomado un
valor específico <span class="math inline">\(y_0\)</span>:</p>
<p><span class="math display">\[
f_{X|Y}(x|y_0) =
\begin{cases}
    \dfrac{f_{X,Y}(x,y_0)}{h(y_0)}, &amp; \text{si } h(y_0) &gt; 0 \\
    0, &amp; \text{en otro caso}
\end{cases}
\]</span></p>
<p>Aquí, <span class="math inline">\(f_{X|Y}(x|y_0)\)</span> representa
la probabilidad de que <span class="math inline">\(X\)</span> tome el
valor <span class="math inline">\(x\)</span> <strong>dado</strong> que
<span class="math inline">\(Y = y_0\)</span>. El denominador <span
class="math inline">\(h(y_0)\)</span> corresponde a la
<strong>distribución marginal de <span
class="math inline">\(Y\)</span></strong>, que funciona como un factor
de normalización.</p>
<div class="caja-nota">
<h3>
Nota:
</h3>
<blockquote>
<p>
<ul>
<li>Si <span class="math inline">\(h(y_0) = 0\)</span>, la probabilidad
condicional no está definida.</li>
</ul>
</p>
<ul>
<li>En el caso de una variable discreta, se cumple que: <span
class="math display">\[
\sum_{x} f_{X|Y}(x|y_0) = 1
\]</span></li>
</ul>
</blockquote>
</div>
<hr />
<p>De manera análoga, la <strong>función de probabilidad
condicional</strong> describe la distribución de <span
class="math inline">\(Y\)</span> cuando se conoce que <span
class="math inline">\(X\)</span> ha tomado un valor específico <span
class="math inline">\(x_0\)</span>:</p>
<p><span class="math display">\[
f_{Y|X}(y|x_0) =
\begin{cases}
    \dfrac{f_{X,Y}(x_0,y)}{g(x_0)}, &amp; \text{si } g(x_0) &gt; 0 \\
    0, &amp; \text{en otro caso}
\end{cases}
\]</span></p>
<p>En este caso, <span class="math inline">\(f_{Y|X}(y|x_0)\)</span>
representa la <strong>probabilidad condicional</strong> de que <span
class="math inline">\(Y\)</span> tome el valor <span
class="math inline">\(y\)</span> dado que <span class="math inline">\(X
= x_0\)</span>.<br />
El denominador <span class="math inline">\(g(x_0)\)</span> corresponde a
la <strong>distribución marginal de <span
class="math inline">\(X\)</span></strong> y cumple el papel de
normalización.</p>
<div class="caja-nota">
<h3>
Nota:
</h3>
<blockquote>
<p>
<ul>
<li>Si <span class="math inline">\(g(x_0) = 0\)</span>, la probabilidad
condicional no está definida.</li>
</ul>
</p>
<ul>
<li>Para una variable discreta, se cumple que: <span
class="math display">\[
\sum_{y} f_{Y|X}(y|x_0) = 1
\]</span></li>
</ul>
</blockquote>
</div>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p>Continuando con el ejemplo de la <strong>Tabla 2.7</strong>, en este
ejemplo se muestra el proceso para obtener la función de probabilidad
condicional de <span class="math inline">\(X\)</span> dado que <span
class="math inline">\(Y=2\)</span>.</p>
<p>El valor de la distribución marginal de <span
class="math inline">\(Y\)</span> en <span
class="math inline">\(y=2\)</span>, está determinada por la expresión:
<span class="math display">\[h(y=2) = 0.050 + 0.10 + 0.35 =
0.50\]</span></p>
<p>La función condicional <span
class="math inline">\(f_{X|Y}(x|y_0)\)</span> se calcula como: <span
class="math display">\[f_{X|Y}(x|y_0=2) =
\frac{f_{X,Y}(x,y=2)}{h(y=2)}\]</span> La tabla siguiente muestra los
resultados de <span class="math inline">\(f_{X|Y}(x|y_0=2)\)</span> para
los distintos valores de <span class="math inline">\(X\)</span>:</p>
<table>
<colgroup>
<col width="10%" />
<col width="33%" />
<col width="43%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(x\)</span></th>
<th><span class="math inline">\(f_{X|Y}(x|y_0=2)\)</span></th>
<th>Cálculo</th>
<th>Resultado</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(\frac{f(1,2)}{0.50}\)</span></td>
<td><span class="math inline">\(\frac{0.05}{0.50}\)</span></td>
<td>0.10</td>
</tr>
<tr class="even">
<td>2</td>
<td><span class="math inline">\(\frac{f(2,2)}{0.50}\)</span></td>
<td><span class="math inline">\(\frac{0.10}{0.50}\)</span></td>
<td>0.20</td>
</tr>
<tr class="odd">
<td>3</td>
<td><span class="math inline">\(\frac{f(3,2)}{0.50}\)</span></td>
<td><span class="math inline">\(\frac{0.20}{0.50}\)</span></td>
<td>0.40</td>
</tr>
</tbody>
</table>
</p>
</div>
</br></br>
<h2>
Continuo-continuo
</h2>
</br></br>
<h3>
Función de densidad conjunta
</h3>
<p>Cuando <span class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> son <strong>variables aleatorias
continuas</strong>, su <strong>función de densidad conjunta</strong>
<span class="math inline">\(f_{X,Y}(x,y)\)</span> permite determinar la
probabilidad de que estas variables tomen valores dentro de una región
específica <span class="math inline">\(R\)</span>.</p>
<p>La probabilidad de que <span class="math inline">\((X, Y)\)</span> se
encuentren dentro de la región <span class="math inline">\(R\)</span>
está dada por: <span class="math display">\[
P((X,Y) \in R) = \int\int_{R} f_{X,Y}(x,y) \,dx\,dy
\]</span> Esta integral representa el <strong>volumen</strong> bajo la
superficie <span class="math inline">\(f_{X,Y}(x,y)\)</span> sobre la
región <span class="math inline">\(R\)</span>.</p>
</br></br>
<h3>
Propiedades de la función de densidad conjunta <span
class="math inline">\(f_{X,Y}(x,y)\)</span>
</h3>
<p>Para que <span class="math inline">\(f_{X,Y}(x,y)\)</span> sea válida
como densidad de probabilidad, debe cumplir:</p>
<ol style="list-style-type: decimal">
<li><p><strong>No negatividad:</strong> La densidad siempre es positiva
o nula: <span class="math display">\[f(x,y) \geq 0, \quad \forall
(x,y)\]</span></p></li>
<li><p><strong>Totalidad:</strong> La integral doble sobre todo el
espacio es 1: <span class="math display">\[
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f_{X,Y}(x,y) \,dx\,dy =
1
\]</span> Es importante tener en cuenta que <span
class="math inline">\(f_{X,Y}(x,y)\)</span> no es una probabilidad, sino
una densidad; la probabilidad se obtiene integrando. El área bajo la
superficie en cualquier región específica es la probabilidad de que
<span class="math inline">\((X, Y)\)</span> esté en esa región. La
integral total bajo toda la superficie es <strong>1</strong>,
garantizando que cubre todo el espacio de posibilidades.</p></li>
</ol>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p>Se modelan la proporción de ácido <span
class="math inline">\(X\)</span> y de ácido <span
class="math inline">\(Y\)</span> (en litros) en una mezcla mediante la
función de densidad conjunta <span
class="math inline">\(f_{X,Y}(x,y)\)</span> definida como:</p>
<p><span class="math display">\[
f_{X,Y}(x,y) = \left\{ \begin{matrix}
  (x+y) &amp; \text{si } 0 \leq x \leq 1 \text{ y } 0 \leq y \leq 1 \\\\
  0 &amp; \text{en otro caso}
\end{matrix} \right.
\]</span></p>
<p>Para verificar que <span class="math inline">\(f_{X,Y}(x,y)\)</span>
es una función de densidad válida, la integral doble sobre la región
definida debe ser igual a 1:</p>
<p><span class="math display">\[
\int_{0}^{1} \int_{0}^{1} (x+y) \,dx\,dy
\]</span></p>
<p>Integración respecto a <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[
\int_{0}^{1} (x+y) \,dx = \left( \frac{x^2}{2} + yx \right)
\Bigg|_{0}^{1} = \frac{1}{2} + y
\]</span></p>
<p>Integración respecto a <span class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[
\int_{0}^{1} \left( \frac{1}{2} + y \right) \,dy = \left( \frac{1}{2}y +
\frac{y^2}{2} \right) \Bigg|_{0}^{1}
= \frac{1}{2} + \frac{1}{2} = 1
\]</span> El valor de la integral doble es <strong>1</strong>,
confirmando que <span class="math inline">\(f_{X,Y}(x,y)\)</span> es una
<strong>función de densidad conjunta válida</strong>.</p>
<p>Se puede usar la librería <code>cubature</code> para integrar
numéricamente la función conjunta <span
class="math inline">\(f_{X,Y}(x,y) = x + y\)</span> en el intervalo
<span class="math inline">\([0,1] \times [0,1]\)</span> como se muestra
a continuación:</p>
<pre>
# Cargar la librería 'cubature' para realizar la integración numérica
library(cubature)

# Define la función conjunta f(x,y) = x + y
fxy <- function(x) {
  return(x[1] + x[2])  # x[1] = x, x[2] = y
}

# Realiza la integración numérica en el intervalo [0,1] para x y y
Ifxy <- adaptIntegrate(
  fxy,
  lowerLimit = c(0, 0),  # Límites inferiores para x e y
  upperLimit = c(1, 1)   # Límites superiores para x e y
)

# Muestra el valor de la integral calculada
Ifxy$integral
</pre>
<p>La función conjunta <span class="math inline">\(f_{X,Y}(x,y) = x +
y\)</span> se puede graficar como en la <strong>Figura 2.17</strong> con
los códigos siguientes:</p>
<pre>
library(plot3D)

# Definir la función conjunta
density_function <- function(x, y) {
  ifelse(x >= 0 & x <= 1 & y >= 0 & y <= 1, x + y, 0)
}

# Crear una cuadrícula de valores
gx <- seq(0, 1, length.out = 30)
gy <- seq(0, 1, length.out = 30)
g <- expand.grid(x = gx, y = gy)
g$z <- mapply(density_function, g$x, g$y)

# Crear el gráfico 3D
persp3D(
  x = gx, 
  y = gy, 
  z = matrix(g$z, nrow = 30),
  col = "lightblue", 
  theta = 45, 
  phi = 30, 
  xlab = "X", 
  ylab = "Y", 
  zlab = "f(X,Y)",
  main = ""
)
</pre>
<img src="img/Figura318.png" width="80%" style="display: block; margin: auto;" />
<strong>Figura 2.17</strong> Distribución conjunta <span
class="math inline">\(f_{X,Y}(x,y) = x + y\)</span> para <span
class="math inline">\(0 \leq x \leq 1\)</span> y <span
class="math inline">\(0 \leq y \leq 1\)</span>.
</center>
</p>
</div>
</br></br>
<h3>
Función de densidad marginal
</h3>
<p>Cuando <span class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> son <strong>variables aleatorias
continuas</strong>, sus distribuciones marginales se obtienen
<strong>integrando la función de densidad conjunta</strong>.</p>
<p>La <strong>función de densidad marginal de <span
class="math inline">\(X\)</span></strong> se define como:</p>
<p><span class="math display">\[
g(x) = f_{X}(x) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) \,dy
\]</span></p>
<p>Esta integral suma las contribuciones de la densidad conjunta para
todos los posibles valores de <span class="math inline">\(Y\)</span>,
obteniendo así la distribución marginal de <span
class="math inline">\(X\)</span>.</p>
<p>De manera análoga, la <strong>función de densidad marginal de <span
class="math inline">\(Y\)</span></strong> se expresa como:</p>
<p><span class="math display">\[
h(y) = f_{Y}(y) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) \,dx
\]</span></p>
<p>En este caso, la integral acumula la densidad conjunta sobre todos
los valores de <span class="math inline">\(X\)</span>, obteniendo así la
distribución marginal de <span class="math inline">\(Y\)</span>.</p>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p>Continuando con el ejemplo anterior, la <strong>función de densidad
marginal de <span class="math inline">\(X\)</span></strong>, denotada
por <span class="math inline">\(g(x)\)</span>, se obtiene integrando la
función de densidad conjunta respecto a <span
class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[
g(x) = \int_{0}^{1} (x + y) \, dy = \left( xy + \frac{y^{2}}{2} \right)
\Bigg|_{0}^{1} = x + \frac{1}{2}
\]</span></p>
<p>Por lo tanto, la expresión completa de la densidad marginal de <span
class="math inline">\(X\)</span> es:</p>
<p><span class="math display">\[
g(x) =
\begin{cases}
x + \dfrac{1}{2}, &amp; \text{si } 0 \leq x \leq 1 \\
0, &amp; \text{en otro caso}
\end{cases}
\]</span></p>
<p>De forma análoga, la <strong>función de densidad marginal de <span
class="math inline">\(Y\)</span></strong>, denotada por <span
class="math inline">\(h(y)\)</span>, se obtiene integrando la densidad
conjunta respecto a <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[
h(y) = \int_{0}^{1} (x + y) \, dx = \left( \frac{x^2}{2} + yx \right)
\Bigg|_{0}^{1} = \frac{1}{2} + y
\]</span></p>
<p>Así, la expresión completa de la densidad marginal de <span
class="math inline">\(Y\)</span> es:</p>
<p><span class="math display">\[
h(y) =
\begin{cases}
y + \dfrac{1}{2}, &amp; \text{si } 0 \leq y \leq 1 \\
0, &amp; \text{en otro caso}
\end{cases}
\]</span></p>
<blockquote>
<p><strong>Nota:</strong> Aunque las fórmulas para las funciones
marginales se definen como integrales en todo el dominio (<span
class="math inline">\(-\infty\)</span> a <span
class="math inline">\(\infty\)</span>), en este ejemplo las funciones se
anulan fuera del intervalo <span class="math inline">\([0,1]\)</span>
porque la densidad conjunta <span class="math inline">\(f_{X,Y}(x,y) = x
+ y\)</span> está definida solo en el cuadrado <span
class="math inline">\(0 \leq x \leq 1\)</span>, <span
class="math inline">\(0 \leq y \leq 1\)</span>.</p>
</blockquote>
</p>
</div>
<!-- </br></br> -->
<!-- <h3>Función de densidad de probabilidad conjunta acumulada</h3> -->
<!-- Para variables aleatorias continuas, la función de distribución conjunta se expresa como: -->
<!-- $$ -->
<!-- F_{X,Y}(x,y) = P(X \leq x, Y \leq y) = \int_{-\infty}^{x} \int_{-\infty}^{y} f_{X,Y}(s,t) \,ds\,dt -->
<!-- $$ -->
<!-- </br></br> -->
<!-- <h4>Propiedades de la función de distribución conjunta</h4> -->
<!-- - **Monotonía:** $F_{X,Y}(x,y)$ es una función **no decreciente**. -->
<!-- - **Límites en extremos:** -->
<!--   - $F_{X,Y}(x,-\infty) = 0$ -->
<!--   - $F_{X,Y}(-\infty,y) = 0$ -->
<!--   - $F_{X,Y}(-\infty,-\infty) = 0$ -->
<!-- - **Límite máximo:** $F_{X,Y}(+\infty,+\infty) = 1$ -->
<!-- - **Relaciones marginales:** -->
<!--   - $F_{X,Y}(+\infty,y) = F_Y(y)$ -->
<!--   - $F_{X,Y}(x,+\infty) = F_X(x)$ -->
<!-- La probabilidad de que $(X,Y)$ esté en una región rectangular es: -->
<!-- $$ -->
<!-- P(x_1 < X \leq x_2, y_1 < Y \leq y_2) = F_{X,Y}(x_2,y_2) - F_{X,Y}(x_1,y_2) - F_{X,Y}(x_2,y_1) + F_{X,Y}(x_1,y_1) -->
<!-- $$ -->
</br></br>
<h3>
Función de densidad condicionales
</h3>
<p>La <strong>función de densidad condicional de <span
class="math inline">\(X\)</span></strong> dado que <span
class="math inline">\(Y = y_0\)</span> se define como:</p>
<p><span class="math display">\[
f_{X|Y}(x|y_0) =
\begin{cases}
\displaystyle\frac{f_{X,Y}(x, y_0)}{h(y_0)}, &amp; \text{si } h(y_0)
&gt; 0 \\
0, &amp; \text{en otro caso}
\end{cases}
\]</span></p>
<p>De manera análoga, la <strong>función de densidad condicional de
<span class="math inline">\(Y\)</span></strong> dado que <span
class="math inline">\(X = x_0\)</span> se expresa como:</p>
<p><span class="math display">\[
f_{Y|X}(y|x_0) =
\begin{cases}
\displaystyle\frac{f_{X,Y}(x_0, y)}{g(x_0)}, &amp; \text{si } g(x_0)
&gt; 0 \\
0, &amp; \text{en otro caso}
\end{cases}
\]</span></p>
<p>Estas funciones describen cómo se distribuye una variable continua
cuando se conoce el valor de la otra. En ambos casos, el denominador
corresponde a la <strong>densidad marginal</strong> de la variable
condicionante, y actúa como un factor de normalización para asegurar que
la densidad condicional se integre a 1 sobre su dominio.</p>
</br></br>
<h3>
Covarianza
</h3>
<p>La <strong>covarianza</strong> cuantifica la <strong>relación
lineal</strong> entre dos variables aleatorias <span
class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span>, y se define como la esperanza del
producto de sus desviaciones respecto a sus medias:</p>
<p><span class="math display">\[
\text{Cov}[X,Y] = E[(X - E[X])(Y - E[Y])]
\]</span></p>
<p>Esta expresión mide cómo varían conjuntamente <span
class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> alrededor de sus valores esperados. Una
forma algebraicamente equivalente de calcular la covarianza es:</p>
<p><span class="math display">\[
\text{Cov}[X,Y] = E[XY] - E[X]E[Y]
\]</span></p>
</br></br>
<h4>
Cálculo de <span class="math inline">\(E[XY]\)</span> según el tipo de
variables
</h4>
<ul>
<li><p><strong>Caso discreto-discreto:</strong></p>
<p>Si <span class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> son variables aleatorias discretas, el
valor esperado del producto se calcula mediante una <strong>suma
doble</strong> sobre sus respectivos recorridos:</p>
<p><span class="math display">\[
E[XY] = \sum_{x \in R_X} \sum_{y \in R_Y} xy \, f_{X,Y}(x, y)
\]</span></p></li>
<li><p><strong>Caso continuo-continuo:</strong></p>
<p>Si <span class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> son variables continuas, se utiliza una
<strong>integral doble</strong> sobre todo el dominio de la función de
densidad conjunta:</p>
<p><span class="math display">\[
E[XY] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} xy \, f_{X,Y}(x,
y) \, dx \, dy
\]</span></p></li>
</ul>
</br></br>
<h4>
Interpretación de la covarianza
</h4>
<ul>
<li><p><span class="math inline">\(\text{Cov}[X,Y] &gt; 0\)</span>:
Existe una <strong>asociación lineal positiva</strong>, es decir, cuando
<span class="math inline">\(X\)</span> aumenta, <span
class="math inline">\(Y\)</span> tiende a aumentar también.</p></li>
<li><p><span class="math inline">\(\text{Cov}[X,Y] &lt; 0\)</span>:
Existe una <strong>asociación lineal negativa</strong>, es decir, cuando
<span class="math inline">\(X\)</span> aumenta, <span
class="math inline">\(Y\)</span> tiende a disminuir.</p></li>
<li><p><span class="math inline">\(\text{Cov}[X,Y] = 0\)</span>: No hay
evidencia de una relación lineal entre <span
class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span>. Sin embargo, podrían estar
relacionadas de manera no lineal.</p></li>
</ul>
<blockquote>
<p><strong>Nota:</strong> Aunque la covarianza indica la dirección de la
asociación lineal, su magnitud <strong>depende de las unidades de las
variables</strong> y por tanto no es comparable entre diferentes
contextos. Para una medida estandarizada se utiliza el
<strong>coeficiente de correlación de Pearson</strong>.</p>
</blockquote>
</br></br>
<h3>
Coeficiente de correlación de Pearson (<span
class="math inline">\(\rho\)</span>)
</h3>
<p>El <strong>coeficiente de correlación de Pearson</strong> (<span
class="math inline">\(\rho\)</span>) cuantifica la <strong>fuerza y
dirección</strong> de la asociación lineal entre dos variables
aleatorias <span class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span>. Se define como la covarianza entre
ambas variables, normalizada por el producto de sus desviaciones
estándar:</p>
<p><span class="math display">\[
\rho = \frac{\text{Cov}[X,Y]}{\sqrt{\text{Var}(X) \cdot \text{Var}(Y)}}
\]</span></p>
<p>Esta medida es <strong>adimensional</strong> y siempre está acotada
en el intervalo:</p>
<p><span class="math display">\[
-1 \leq \rho \leq 1
\]</span></p>
</br></br>
<h4>
Interpretación del coeficiente <span class="math inline">\(\rho\)</span>
</h4>
<ul>
<li><p><span class="math inline">\(\rho = 1\)</span>: Existe una
<strong>relación lineal positiva perfecta</strong>. A medida que <span
class="math inline">\(X\)</span> aumenta, <span
class="math inline">\(Y\)</span> también lo hace
proporcionalmente.</p></li>
<li><p><span class="math inline">\(\rho = -1\)</span>: Existe una
<strong>relación lineal negativa perfecta</strong>. A medida que <span
class="math inline">\(X\)</span> aumenta, <span
class="math inline">\(Y\)</span> disminuye proporcionalmente.</p></li>
<li><p><span class="math inline">\(\rho = 0\)</span>: <strong>No hay
relación lineal</strong> entre <span class="math inline">\(X\)</span> y
<span class="math inline">\(Y\)</span>. Sin embargo, podrían estar
relacionadas de forma no lineal.</p></li>
<li><p><strong>Valores intermedios</strong> (por ejemplo, <span
class="math inline">\(\rho = 0.6\)</span>, <span
class="math inline">\(\rho = -0.8\)</span>) indican distintos grados de
<strong>asociación lineal</strong>, siendo más fuerte cuanto más cercano
esté <span class="math inline">\(\rho\)</span> a <span
class="math inline">\(\pm 1\)</span>.</p></li>
</ul>
<blockquote>
<p><strong>Nota:</strong> A diferencia de la covarianza, el coeficiente
de correlación permite comparar la fuerza de la relación lineal entre
variables de diferentes escalas o unidades.</p>
</blockquote>
<p>La <strong>Tabla 2.8</strong> presenta una pauta para interpertar los
valores de <span class="math inline">\(\rho\)</span>.</p>
<br/><br/>
<center>
<strong>Tabla 2.8</strong> Grados de asociación lineal según <span
class="math inline">\(\rho\)</span>.
</center>
<table>
<colgroup>
<col width="54%" />
<col width="45%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Rango de <span
class="math inline">\(\rho\)</span></strong></th>
<th><strong>Grado de asociación lineal</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(-1.00 \leq \rho &lt; -0.90\)</span></td>
<td>Negativa muy fuerte</td>
</tr>
<tr class="even">
<td><span class="math inline">\(-0.90 \leq \rho &lt; -0.75\)</span></td>
<td>Negativa considerable</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(-0.75 \leq \rho &lt; -0.50\)</span></td>
<td>Negativa media</td>
</tr>
<tr class="even">
<td><span class="math inline">\(-0.50 \leq \rho &lt; -0.25\)</span></td>
<td>Negativa débil</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(-0.25 \leq \rho &lt; -0.10\)</span></td>
<td>Negativa muy débil</td>
</tr>
<tr class="even">
<td><span class="math inline">\(-0.10 \leq \rho &lt; 0.10\)</span></td>
<td>No existe correlación</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(0.10  \leq  \rho &lt; 0.25\)</span></td>
<td>Positiva muy débil</td>
</tr>
<tr class="even">
<td><span class="math inline">\(0.25  \leq  \rho &lt; 0.50\)</span></td>
<td>Positiva débil</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(0.50  \leq  \rho &lt; 0.75\)</span></td>
<td>Positiva media</td>
</tr>
<tr class="even">
<td><span class="math inline">\(0.75  \leq  \rho &lt; 0.90\)</span></td>
<td>Positiva considerable</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(0.90  \leq  \rho \leq 1.00\)</span></td>
<td>Positiva muy fuerte</td>
</tr>
</tbody>
</table>
<p>Los gráficos de la <strong>Figura 2.18</strong> muestran la relación
entre dos variables para diferentes valores del coeficiente de
correlación de Pearson (<span class="math inline">\(\rho\)</span>),
destacando cómo varía la asociación lineal negativa:</p>
<ul>
<li><p><strong><span class="math inline">\(\rho = -1.0\)</span>
(a):</strong> Relación lineal negativa exacta; todos los puntos se
alinean sobre una recta descendente.</p></li>
<li><p><strong><span class="math inline">\(\rho = -0.90\)</span>
(b):</strong> Relación negativa lineal casi perfecta, con una ligera
dispersión alrededor de una línea descendente.</p></li>
<li><p><strong><span class="math inline">\(\rho = -0.75\)</span>
(c):</strong> Patrón descendente lineal claro, aunque con más dispersión
que en <span class="math inline">\(\rho = -0.90\)</span>.</p></li>
<li><p><strong><span class="math inline">\(\rho = -0.50\)</span>
(d):</strong> Relación lineal negativa moderada, con una nube de puntos
más dispersa pero con tendencia descendente.</p></li>
<li><p><strong><span class="math inline">\(\rho = -0.25\)</span>
(e):</strong> Relación lineal negativa leve; la tendencia descendente es
poco perceptible.</p></li>
<li><p><strong><span class="math inline">\(\rho = 0.0\)</span>
(f):</strong> No se observa un patrón lineal; la distribución de puntos
es aleatoria.</p></li>
</ul>
<p>A medida que <span class="math inline">\(\rho\)</span> se acerca a
-1, la relación negativa lineal es más fuerte y los puntos están más
alineados. Cuando <span class="math inline">\(\rho\)</span> se aproxima
a 0, la relación lineal desaparece, y la dispersión es aleatoria.</p>
<center>
<img src="img/Rho1.png" width="100%" style="display: block; margin: auto;" />
<strong>Figura 2. 18</strong> Correlaciones negativas (a) <span
class="math inline">\(\rho = -1.0\)</span>. <span
class="math inline">\(\hspace{.5cm}\)</span> (b) <span
class="math inline">\(\rho = -0.90\)</span>. <br/> (c) <span
class="math inline">\(\rho = -0.75\)</span>. <span
class="math inline">\(\hspace{.5cm}\)</span>(d) <span
class="math inline">\(\rho = -0.50\)</span>. <span
class="math inline">\(\hspace{.5cm}\)</span> (e) <span
class="math inline">\(\rho = -0.25\)</span>. <span
class="math inline">\(\hspace{.5cm}\)</span> (f) <span
class="math inline">\(\rho = 0.0\)</span>.
</center>
<p><br/><br/> Los gráficos de la <strong>Figura 2.19</strong> muestran
la relación entre dos variables para diferentes valores del coeficiente
de correlación de Pearson (<span class="math inline">\(\rho\)</span>),
destacando cómo varía la asociación lineal positiva.</p>
<ul>
<li><p><strong><span class="math inline">\(\rho = 0.10\)</span>
(a):</strong> Relación positiva lineal apenas perceptible; los puntos
están dispersos.</p></li>
<li><p><strong><span class="math inline">\(\rho = 0.25\)</span>
(b):</strong> Tendencia ligeramente lineal ascendente, pero con
considerable dispersión.</p></li>
<li><p><strong><span class="math inline">\(\rho = 0.50\)</span>
(c):</strong> Relación positiva lineal más clara; los puntos tienden a
alinearse en una dirección ascendente.</p></li>
<li><p><strong><span class="math inline">\(\rho = 0.75\)</span>
(d):</strong> Tendencia ascendente lineal marcada; los puntos están más
próximos a una línea.</p></li>
<li><p><strong><span class="math inline">\(\rho = 0.90\)</span>
(e):</strong> Relación casi lineal; los puntos forman una franja muy
estrecha en dirección ascendente.</p></li>
<li><p><strong><span class="math inline">\(\rho = 1.0\)</span>
(f):</strong> Relación lineal perfecta; todos los puntos están alineados
sobre una recta ascendente.</p></li>
</ul>
<p>A medida que <span class="math inline">\(\rho\)</span> se acerca a 1,
la relación positiva lineal es más fuerte y los puntos están más
alineados. Cuando <span class="math inline">\(\rho\)</span> es bajo, la
tendencia lineal positiva es leve, y la dispersión es mayor.</p>
<center>
<img src="img/Rho2.png" width="100%" style="display: block; margin: auto;" />
<strong>Figura 2. 19</strong> Correlaciones positivas (a) <span
class="math inline">\(\rho = 0.10\)</span>.<span
class="math inline">\(\hspace{.5cm}\)</span> (b) <span
class="math inline">\(\rho = 0.25\)</span>. <br/> (c) <span
class="math inline">\(\rho = 0.50\)</span>.<span
class="math inline">\(\hspace{.5cm}\)</span> (d) <span
class="math inline">\(\rho = 0.75\)</span>. <span
class="math inline">\(\hspace{.5cm}\)</span> (e) <span
class="math inline">\(\rho = 0.90\)</span>. <span
class="math inline">\(\hspace{.5cm}\)</span> (f) <span
class="math inline">\(\rho = 1.0\)</span>.
</center>
</br></br>
<h2>
Independencia
</h2>
<p>Sean <span class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> dos <strong>variables
aleatorias</strong>, ya sean discretas o continuas, con:</p>
<ul>
<li><p><strong>Función de probabilidad (o densidad) conjunta:</strong>
<span class="math inline">\(f_{X,Y}(x, y)\)</span></p></li>
<li><p><strong>Funciones marginales:</strong> <span
class="math inline">\(g(x)\)</span> para <span
class="math inline">\(X\)</span> y <span
class="math inline">\(h(y)\)</span> para <span
class="math inline">\(Y\)</span></p></li>
</ul>
<p>Se dice que <span class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> son <strong>estadísticamente
independientes</strong> si, y solo si, para todo par de valores <span
class="math inline">\(x\)</span> y <span
class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[
f_{X,Y}(x, y) = g(x) \cdot h(y)
\]</span></p>
<p>Es decir, la <strong>función conjunta</strong> se puede descomponer
como el <strong>producto de las funciones marginales</strong>. Esto
implica que el conocimiento del valor de una variable <strong>no
proporciona información</strong> sobre la otra: el comportamiento de una
es <strong>completamente independiente</strong> del comportamiento de la
otra.</p>
</br>
<h4>
Propiedades clave:
</h4>
<ul>
<li><p><strong>Relación con la esperanza:</strong></p>
<p>Si <span class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> son independientes, entonces se cumple
que: <span class="math display">\[
E[XY] = E[X] \cdot E[Y]
\]</span></p></li>
<li><p><strong>Relación con la covarianza:</strong></p>
<p>La independencia implica covarianza nula: <span
class="math display">\[
\text{Cov}(X, Y) = 0
\]</span> Sin embargo, el recíproco <strong>no siempre es
cierto</strong>: una covarianza igual a cero <strong>no garantiza
independencia</strong>, ya que podría existir una relación no lineal
entre las variables.</p></li>
</ul>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p>Continuando con el ejemplo anterior, la <strong>función de densidad
conjunta</strong> está dada por:</p>
<p><span class="math display">\[
f_{X,Y}(x,y) =
\begin{cases}
x + y, &amp; \text{si } 0 \leq x \leq 1 \text{ y } 0 \leq y \leq 1 \\
0, &amp; \text{en otro caso}
\end{cases}
\]</span></p>
<p>Las <strong>funciones de densidad marginal</strong> de <span
class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> son:</p>
<p><span class="math display">\[
g(x) =
\begin{cases}
x + \dfrac{1}{2}, &amp; \text{si } 0 \leq x \leq 1 \\
0, &amp; \text{en otro caso}
\end{cases}
\]</span></p>
<p><span class="math display">\[
h(y) =
\begin{cases}
y + \dfrac{1}{2}, &amp; \text{si } 0 \leq y \leq 1 \\
0, &amp; \text{en otro caso}
\end{cases}
\]</span></p>
<p>Para que <span class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> sean <strong>estadísticamente
independientes</strong>, debe cumplirse que:</p>
<p><span class="math display">\[
f_{X,Y}(x,y) = g(x) \cdot h(y)
\]</span></p>
<p>Primero se calcula el producto de las densidades marginales:</p>
<p><span class="math display">\[
g(x) \cdot h(y) = (x + \tfrac{1}{2})(y + \tfrac{1}{2}) = xy +
\frac{x}{2} + \frac{y}{2} + \frac{1}{4}
\]</span></p>
<p>Ahora de compara este resultado con la densidad conjunta:</p>
<p><span class="math display">\[
f_{X,Y}(x,y) = x + y
\]</span></p>
<p>Claramente:</p>
<p><span class="math display">\[
x + y \neq xy + \frac{x}{2} + \frac{y}{2} + \frac{1}{4}
\]</span></p>
<p>Por lo tanto, como:</p>
<p><span class="math display">\[
f_{X,Y}(x,y) \neq g(x) \cdot h(y),
\]</span></p>
<p>se concluye que <strong>las variables <span
class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span> no son independientes</strong>.</p>
</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
