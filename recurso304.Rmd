---
title: <span style="color:#686868"> **Métodos de estimación**</span>
author: "Métodos y Simulación estadística"
output:
  html_document:
    toc: no
    toc_depth: 2
    toc_float: yes
    code_folding: hide
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, comment = NA)
```


</br></br>
<h2>Introducción</h2>


En estadística inferencial, uno de los principales objetivos es **estimar los parámetros desconocidos** de una distribución de probabilidad a partir de una muestra de datos observados. Existen varios enfoques para realizar estas estimaciones, siendo dos de los más utilizados el **método de los momentos** y el **método de máxima verosimilitud**.

Los métodos de estimación permiten obtener valores aproximados de parámetros poblacionales desconocidos, como la **media**, la **varianza**, la **tasa de ocurrencia de eventos**, entre otros. Estos métodos son fundamentales en diversas áreas, tales como:

- **Econometría y Finanzas:** Para estimar tasas de crecimiento, volatilidad o distribuciones de precios de activos.

- **Ingeniería y Fiabilidad:** Para modelar la vida útil de componentes y sistemas.

- **Biometría y Ciencias de la Salud:** Para estimar parámetros en modelos epidemiológicos o tasas de incidencia de enfermedades.

- **Machine Learning y Ciencia de Datos:** En ajuste de modelos probabilísticos y optimización de parámetros en aprendizaje automático.



</br></br>
<h2>Métodos de estimación</h2>



</br></br>
<h3>Método de momentos</h3>
<br/><br/>


---

El **método de los momentos** (MOM) es un enfoque intuitivo basado en la idea de que los **momentos poblacionales** pueden ser aproximados por los **momentos muestrales**. Si una variable aleatoria \( X \) tiene una distribución con parámetros \( \theta_1, \theta_2, \dots, \theta_k \), el método de los momentos establece ecuaciones de la forma:

\[
E[X^r] = \frac{1}{n} \sum_{i=1}^{n} X_i^r
\]

para \( r = 1, 2, \dots, k \), donde los momentos muestrales se igualan a los momentos poblacionales teóricos, y se resuelve el sistema de ecuaciones para obtener estimaciones de los parámetros.

Características del Método de los Momentos:

- Es **fácil de calcular** en muchas distribuciones.

- No requiere suposiciones fuertes sobre la distribución subyacente.

- En algunos casos, puede no proporcionar estimadores óptimos en términos de **sesgo** y **varianza mínima**.

---

</br></br>
<h3>Método de máxima verosimilitud</h3>
<br/><br/>


El **método de máxima verosimilitud** (MLE) es un enfoque más formal y ampliamente utilizado. Este método busca **maximizar la función de verosimilitud**, que mide la **probabilidad de observar los datos** en función de los parámetros desconocidos.

Dada una muestra \( X_1, X_2, ..., X_n \) con función de densidad \( f(x; \theta) \), la función de verosimilitud está dada por:

\[
L(\theta) = \prod_{i=1}^{n} f(X_i; \theta).
\]

En la práctica, se trabaja con la **log-verosimilitud**:

\[
\ell(\theta) = \sum_{i=1}^{n} \log f(X_i; \theta).
\]

Para encontrar el estimador de máxima verosimilitud \( \hat{\theta} \), se resuelve:

\[
\frac{d}{d\theta} \ell(\theta) = 0.
\]

Características del método de máxima verosimilitud: 

- Proporciona **estimadores asintóticamente eficientes**, lo que significa que convergen a los valores verdaderos con menor varianza posible a medida que el tamaño de la muestra aumenta.

- Es ampliamente utilizado en **modelos paramétricos**, incluyendo distribuciones normales, Poisson, binomial, exponencial y muchas más.

- En algunos casos, las soluciones requieren **algoritmos numéricos** debido a la complejidad de las derivadas.

---



</br></br>
<div class="caja-ejemplo">
<h3>Ejemplo:</h3>
<p>

En una **fábrica de bombillas**, se estudia la **duración de vida útil** (en horas) de las bombillas antes de que fallen. Se ha observado que la vida útil de una bombilla sigue una **distribución Gamma** con parámetros \( \alpha \) (forma) y \( \beta \) (escala). 

Para estimar los parámetros de esta distribución, se selecciona una muestra aleatoria de **10 bombillas** y se registran sus tiempos de vida útil en horas:

<pre>
vida_util <- c(1200, 1350, 1100, 1450, 1300, 1250, 1400, 1280, 1320, 1380)
</pre>

Se desea estimar los valores de $\alpha$ y $\beta$ utilizando el método de los momentos. 

---
Paso 1:  Determinación de los momentos poblacionales

Para una **distribución Gamma** con parámetros \( \alpha \) (forma) y \( \beta \) (escala), los primeros momentos poblacionales están dados por:

- **Media poblacional**:

  \[
  E[X] = \alpha \beta
  \]

  Esto significa que el valor esperado de la duración de vida útil de una bombilla es igual al producto de los parámetros \( \alpha \) y \( \beta \).

- **Varianza poblacional**:

  \[
  \text{Var}(X) = \alpha \beta^2
  \]

  
- **Segundo momento poblacional**:  

  Se puede obtener utilizando la propiedad de la varianza:

  \[
  E[X^2] = \text{Var}(X) + (E[X])^2
  \]

  Sustituyendo las expresiones de la varianza y la media:

  \[
  E[X^2] = \alpha \beta^2 + (\alpha \beta)^2
  \]

  Factorizando:

  \[
  E[X^2] = \alpha \beta^2 (1 + \alpha)
  \]


Paso 2:  Determinación de los momentos muestrales

En la práctica, los momentos poblacionales son desconocidos, por lo que deben ser estimados a partir de una muestra aleatoria de tamaño \( n \). Los **momentos muestrales** son las estimaciones empíricas de los momentos poblacionales y se calculan como sigue:

- **Media muestral**:

  \[
  M_1 = \bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i
  \]

  La media muestral \( \bar{X} \) es la estimación empírica del valor esperado \( E[X] \).

- **Varianza muestral**:

  \[
  S^2 = \frac{1}{n} \sum_{i=1}^{n} X_i^2 - \bar{X}^2
  \]

  La varianza muestral \( S^2 \) estima la varianza poblacional \( \text{Var}(X) \) y nos da una medida de la dispersión de los datos alrededor de la media.

- **Segundo momento muestral**:

  \[
  M_2 = \frac{1}{n} \sum_{i=1}^{n} X_i^2
  \]

  El segundo momento muestral \( M_2 \) es una estimación del momento poblacional \( E[X^2] \) y se relaciona con la varianza de la siguiente manera:

  \[
  M_2 = S^2 + \bar{X}^2
  \]

  Estos momentos muestrales nos permitirán encontrar estimaciones para los parámetros \( \alpha \) y \( \beta \) en el siguiente paso, mediante la igualación con los momentos poblacionales.
 

Paso 3:  Aplicación del Método de los Momentos

El **método de los momentos** consiste en igualar los momentos muestrales con los momentos poblacionales y resolver el sistema resultante para obtener estimaciones de los parámetros desconocidos.

A partir de los **momentos poblacionales** de una distribución Gamma \( X \sim \text{Gamma}(\alpha, \beta) \):

\[
E[X] = \alpha \beta, \quad E[X^2] = \alpha \beta^2 + (\alpha \beta)^2
\]

Y los **momentos muestrales** determinados:

\[
M_1 = \bar{X}, \quad M_2 = \frac{1}{n} \sum_{i=1}^{n} X_i^2
\]

Igualamos los momentos muestrales con los poblacionales:

\[
M_1 = E[X] \quad \Rightarrow \quad \bar{X} = \alpha \beta
\]

\[
M_2 = E[X^2] \quad \Rightarrow \quad S^2 + \bar{X}^2 = \alpha \beta^2 + (\alpha \beta)^2
\]

Reemplazamos \( \alpha \beta = \bar{X} \):

\[
S^2 + \bar{X}^2 = \frac{\bar{X}^2}{\alpha} + \bar{X}^2
\]

Despejamos \( \alpha \):

\[
S^2 = \frac{\bar{X}^2}{\alpha} \quad \Rightarrow \quad \alpha = \frac{\bar{X}^2}{S^2}
\]

Ahora, sustituimos \( \alpha \) en la ecuación \( \bar{X} = \alpha \beta \) para despejar \( \beta \):

\[
\beta = \frac{S^2}{\bar{X}}
\]

Por lo tanto, los estimadores de los parámetros \( \alpha \) y \( \beta \) por el método de los momentos son:

\[
\hat{\alpha} = \frac{\bar{X}^2}{S^2}, \quad \hat{\beta} = \frac{S^2}{\bar{X}}
\]

Estos estimadores permiten obtener aproximaciones de los parámetros poblacionales basándose en una muestra aleatoria. En la siguiente sección, se analizará su interpretación y comparación con otros métodos de estimación.

Paso 4:  Cálculo numérico 

Con los siguientes códigos el problema se resuelve numéricamente.

<pre>
# Datos de la muestra
vida_util <- c(1200, 1350, 1100, 1450, 1300, 1250, 1400, 1280, 1320, 1380)

# Cálculo de la media muestral
media_muestral <- mean(vida_util)

# Cálculo del segundo momento muestral
segundo_momento_muestral <- mean(vida_util^2)

# Estimación de alpha
alpha_est <- media_muestral^2 / (segundo_momento_muestral - media_muestral^2)

# Estimación de beta
beta_est <- media_muestral / alpha_est

alpha_est
beta_est
</pre>

```{r, echo=TRUE, fig.height=3.5}
# Datos de la muestra
vida_util <- c(1200, 1350, 1100, 1450, 1300, 1250, 1400, 1280, 1320, 1380)

# Cálculo de la media muestral
media_muestral <- mean(vida_util)

# Cálculo del segundo momento muestral
segundo_momento_muestral <- mean(vida_util^2)

# Estimación de alpha
alpha_est <- media_muestral^2 / (segundo_momento_muestral - media_muestral^2)

# Estimación de beta
beta_est <- media_muestral / alpha_est

alpha_est
beta_est

```


Y los resultados de las estimaciones de los parámetros de la distribución Gamma
son:

<pre>

> alpha_est
[1] 179.4534
> beta_est
[1] 7.260936

</pre>

Ahora reemplazando en los estimadores determinados analíticamente tenemos:

<pre>

# Datos de la muestra
vida_util <- c(1200, 1350, 1100, 1450, 1300, 1250, 1400, 1280, 1320, 1380)

# Cálculo de la media muestral
media_muestral <- mean(vida_util)

# Cálculo del segundo momento muestral
segundo_momento_muestral <- mean(vida_util^2)

# Estimación de alpha
alpha_est <- media_muestral^2 / (segundo_momento_muestral - media_muestral^2)

# Estimación de beta
beta_est <- media_muestral / alpha_est

alpha_est
beta_est

</pre>


```{r, echo=TRUE, fig.height=3.5}

# Datos de la muestra
vida_util <- c(1200, 1350, 1100, 1450, 1300, 1250, 1400, 1280, 1320, 1380)

# Cálculo de la media muestral
media_muestral <- mean(vida_util)

# Cálculo del segundo momento muestral
segundo_momento_muestral <- mean(vida_util^2)

# Estimación de alpha
alpha_est <- media_muestral^2 / (segundo_momento_muestral - media_muestral^2)

# Estimación de beta
beta_est <- media_muestral / alpha_est

alpha_est
beta_est
```

</p>
</div>

También se obtuvieron los mismos resultados:
<pre>

> alpha_est
[1] 179.4534
> beta_est
[1] 7.260936

</pre>


</br></br>
<div class="caja-ejemplo">
<h3>Ejemplo:</h3>
<p>

En una **fábrica de bombillas LED**, es crucial modelar la **vida útil** de sus productos para optimizar el control de calidad y establecer garantías. Se sabe que el tiempo de funcionamiento continuo antes de que una bombilla falle sigue una **distribución exponencial** con parámetro \( \lambda \), donde la **media poblacional** está dada por:

\[
E[X] = \frac{1}{\lambda}
\]

Para estimar el parámetro \( \lambda \), se selecciona una muestra aleatoria de **\( n = 10 \)** bombillas y se registran sus tiempos de vida en horas. 

Con base en estos datos determinado como:

<pre>
# Cargar librería
set.seed(123)  # Fijar semilla para reproducibilidad

# Simular una muestra de tiempos de vida útil de bombillas (Exponencial con lambda desconocido)
muestra <- rexp(10, rate = 1/5000)  # Vida media esperada de 5000 horas
</pre>


```{r, echo=TRUE, fig.height=3.5}
# Cargar librería
set.seed(123)  # Fijar semilla para reproducibilidad

# Simular una muestra de tiempos de vida útil de bombillas (Exponencial con lambda desconocido)
muestra <- rexp(10, rate = 1/5000)  # Vida media esperada de 5000 horas
``` 


Paso 1: Planteamiento de la función de verosimilitud

Para estimar el parámetro \( \lambda \) de la distribución **Exponencial**, consideramos que los tiempos de vida útil de las bombillas \( X_1, X_2, \dots, X_n \) son variables aleatorias **independientes e idénticamente distribuidas (i.i.d.)** con función de densidad:

\[
f(x; \lambda) = \lambda e^{-\lambda x}, \quad x > 0
\]

Dado que la muestra está compuesta por \( n \) observaciones \( X_1, X_2, \dots, X_n \), la **función de verosimilitud** se define como el producto de las densidades de cada observación:

\[
L(\lambda) = \prod_{i=1}^{n} \lambda e^{-\lambda X_i}
\]

Expandiendo el producto:

\[
L(\lambda) = \lambda^n e^{-\lambda \sum X_i}
\]

Esta función representa la **probabilidad conjunta** de observar la muestra dada la distribución poblacional con el parámetro \( \lambda \). El siguiente paso consiste en transformar esta función en la **log-verosimilitud** para facilitar su optimización.


Paso 2: Función log-verosimilitud y estimador de máxima verosimilitud

Para facilitar la derivación del estimador de máxima verosimilitud, aplicamos el logaritmo natural a la función de verosimilitud:

\[
\ell(\lambda) = \log L(\lambda) = \log \left( \lambda^n e^{-\lambda \sum X_i} \right)
\]

Utilizando las propiedades del logaritmo:

\[
\ell(\lambda) = n \log \lambda - \lambda \sum X_i
\]

Para encontrar el **estimador de máxima verosimilitud (EMV)** de \( \lambda \), derivamos la función log-verosimilitud con respecto a \( \lambda \):

\[
\frac{d\ell(\lambda)}{d\lambda} = \frac{n}{\lambda} - \sum X_i
\]

Igualamos a **cero** para encontrar el valor óptimo de \( \lambda \):

\[
\frac{n}{\lambda} - \sum X_i = 0
\]

Despejamos \( \lambda \):

\[
\hat{\lambda} = \frac{n}{\sum X_i}
\]

Este es el **estimador de máxima verosimilitud** de \( \lambda \). En términos de la **media muestral** \( \bar{X} \), podemos reescribirlo como:

\[
\hat{\lambda} = \frac{1}{\bar{X}}
\]

Este resultado muestra que el estimador de máxima verosimilitud del parámetro \( \lambda \) es el **inverso de la media muestral**. A continuación, implementaremos este estimador en **R** para calcularlo a partir de una muestra simulada.

<pre>
# Cargar librería
set.seed(123)  # Fijar semilla para reproducibilidad

# Simular una muestra de tiempos de vida útil de bombillas (Exponencial con lambda desconocido)
muestra <- rexp(10, rate = 1/5000)  # Vida media esperada de 5000 horas

# Calcular la media muestral
media_muestral <- mean(muestra)

# Estimador de máxima verosimilitud
lambda_estimado <- 1 / media_muestral

# Mostrar resultados
cat("Muestra de tiempos de vida útil (horas):", muestra, "\n")
cat("Media muestral (X̄):", media_muestral, "\n")
cat("Estimador de lambda (EMV):", lambda_estimado, "\n")
</pre>


```{r, echo=TRUE, fig.height=3.5}
# Cargar librería
set.seed(123)  # Fijar semilla para reproducibilidad

# Simular una muestra de tiempos de vida útil de bombillas (Exponencial con lambda desconocido)
muestra <- rexp(10, rate = 1/5000)  # Vida media esperada de 5000 horas

# Calcular la media muestral
media_muestral <- mean(muestra)

# Estimador de máxima verosimilitud
lambda_estimado <- 1 / media_muestral

# Mostrar resultados
#cat("Muestra de tiempos de vida útil (horas):", muestra, "\n")
#cat("Media muestral (X̄):", media_muestral, "\n")
#cat("Estimador de lambda (EMV):", lambda_estimado, "\n")
```



Los resultados obtenidos a partir de la muestra generada son:

- **Media muestral observada**:  
  \[
  \bar{X} = 3184.148
  \]
  
- **Estimador de \( \lambda \) (EMV) calculado**:  
  \[
  \hat{\lambda} = \frac{1}{\bar{X}} = 0.0003141
  \]
  
- **Valor real de \( \lambda \)**:  
  \[
  0.0002
  \]

Se observa que el valor estimado de \( \lambda \) difiere del valor real debido a la **variabilidad muestral**. Como la muestra es **pequeña (\( n = 10 \))**, la media muestral puede diferir considerablemente de la media poblacional.


</p>
</div>





