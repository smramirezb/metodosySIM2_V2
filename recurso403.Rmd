---
title: <span style="color:#686868"> **Estimación no paramétrica**</span>
author: "Métodos y Simulación Estadística"
output:
  html_document:
    toc: no
    toc_depth: 2
    toc_float: yes
    code_folding: hide
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, comment = NA)

# install.packages('gtools')
# install.packages("TeachingSampling")

#load library
library(gtools)
library(TeachingSampling)
library(readr)
library(paqueteMETODOS)

c1="#FF7F00"
c2="#034A94"
c3="#0EB0C6"
c4="#686868"

data("CarreraLuz22")
data("evaluacion")

```

</br></br>
<h2>Introducción</h2>


En estadística, los **intervalos de confianza no paramétricos** son herramientas fundamentales cuando se trabaja con datos que no siguen una distribución normal o cuya distribución es desconocida. A diferencia de los métodos paramétricos, que asumen una forma específica de la distribución (como la normalidad), los métodos no paramétricos no requieren suposiciones fuertes sobre la población de la cual se extrae la muestra.

Los métodos no paramétricos son útiles en diversas situaciones, tales como:

- **Poblaciones con distribución desconocida**: Se aplican cuando no se puede asumir una distribución específica para los datos.
- **Muestras pequeñas**: En situaciones donde el tamaño de la muestra no permite aplicar el Teorema del Límite Central de manera confiable.
- **Datos con valores extremos o atípicos**: Son más robustos que los métodos paramétricos ante la presencia de outliers.
- **Distribuciones sesgadas**: Se aplican cuando los datos muestran asimetría o colas largas.

Cuando se extrae una muestra de una población que no es normal y se requiere estimar un intervalo de confianza, se pueden utilizar métodos de **estimación bootstrap**. 



</br></br>
<h2>Intervalos Bootstrap</h2>



</br></br>
<h3>Muestra bootstrap</h3>

Las **muestras bootstrap** son subconjuntos de datos generados a partir de una muestra original mediante **remuestreo con reemplazo**. Es un método no paramétrico que permite estimar la distribución de una estadística sin asumir una forma específica de la distribución poblacional.

**Procedimiento:**

El procedimiento para generar muestras bootstrap es:

1. Se tiene una muestra original de tamaño \( n \): \( X_1, X_2, ..., X_n \).
2. Se generan **\( B \)** muestras bootstrap seleccionando **\( n \)** observaciones con **reemplazo** de la muestra original.

Posteriormente para cada muestra bootstrap, se calcula la estadística de interés (por ejemplo, la media o la mediana). Luego, se obtiene la distribución empírica de la estadística a partir de las muestras bootstrap, lo que permite construir intervalos de confianza.



</br></br>
<div class="caja-ejemplo">
<h3>Ejemplo:</h3>
<p>

Las **muestras bootstrap** se generan a partir de una muestra original mediante **remuestreo con reemplazo**. A continuación, se muestra un ejemplo con 20 datos.

**Datos Originales**

\[
X = \{3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50\}
\]

Se puede generar varias muestras bootstrap seleccionando **con reemplazo** 20 valores de la muestra original. Algunas posibles muestras bootstrap son:

**Ejemplos de Muestras Bootstrap**

\[
X_1^* = \{10, 25, 5, 10, 20, 35, 50, 12, 3, 7, 9, 33, 45, 42, 15, 5, 37, 28, 40, 30\}
\]

\[
X_2^* = \{15, 15, 20, 5, 10, 22, 28, 40, 45, 37, 30, 25, 50, 3, 12, 9, 18, 35, 33, 7\}
\]

\[
X_3^* = \{42, 33, 40, 12, 18, 9, 5, 7, 15, 22, 50, 28, 25, 3, 35, 30, 10, 37, 45, 20\}
\]

Cada una de estas muestras bootstrap tiene **el mismo tamaño** que la muestra original (20 datos), pero debido al remuestreo con reemplazo, algunos valores pueden repetirse mientras que otros pueden no aparecer en una muestra dada.


Si se desea generar estas muestras en **R**, puedes utilizar el siguiente código:

<pre>
set.seed(123)  # Para reproducibilidad

# Datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Generar tres muestras bootstrap de tamaño 20
X1_star <- sample(X, size = 20, replace = TRUE)
X2_star <- sample(X, size = 20, replace = TRUE)
X3_star <- sample(X, size = 20, replace = TRUE)

# Mostrar las muestras
list(X1_star, X2_star, X3_star)
</pre>



```{r,echo=TRUE}
set.seed(123)  # Para reproducibilidad

# Datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Generar tres muestras bootstrap de tamaño 20
X1_star <- sample(X, size = 20, replace = TRUE)
X2_star <- sample(X, size = 20, replace = TRUE)
X3_star <- sample(X, size = 20, replace = TRUE)

# Mostrar las muestras
list(X1_star, X2_star, X3_star)
```

</p>
</div>



</br></br>
<h3>Intervalos de confianza Bootstrap</h3>

Existen varios métodos para calcular intervalos de confianza usando bootstrap. Los más comunes son:

1. **Intervalo Percentil Bootstrap**
2. **Intervalo Normal Bootstrap**
3. **Intervalo de Sesgo-Acelerado (BCa)**
4. **Intervalo de Studentizado (t-bootstrap)**

La **Tabla 2.12** presenta un resumen de los ventajes y desventajas de los métodos
de intervalos Bootstrap.


<br/><br/>
<center>
**Tabla 2.12** Resumen de los Métodos Bootstrap.
</center> 
| **Método de Intervalo Bootstrap** | **Ventajas** | **Desventajas** |
|-----------------------------------|-------------|---------------|
| **Percentil Bootstrap** | Simple y fácil de implementar. | Puede ser sesgado si la distribución no es simétrica. |
| **Normal Bootstrap** | Fácil de calcular con media y desviación estándar. | Supone normalidad, lo que puede ser incorrecto. |
| **BCa (Sesgo-Acelerado)** | Corrige sesgo y asimetría, más preciso. | Más costoso computacionalmente. |
| **Studentizado (t-bootstrap)** | Mejor cuando hay heterogeneidad en la varianza. | Necesita estimar errores estándar adicionales. |




---


</br></br></br>
<h4>Intervalo Percentil Bootstrap</h4>


Este método es el más simple y se basa en los percentiles de la distribución empírica obtenida por bootstrap.


**Procedimiento:**

1. Generar \( B \) muestras bootstrap y calcular la estadística de interés \( \hat{\theta}^*_b \) en cada una.
2. Ordenar los valores de \( \hat{\theta}^*_b \) de menor a mayor.
3. Tomar los percentiles \( \alpha/2 \) y \( 1 - \alpha/2 \) para obtener el intervalo de confianza al **\( 100(1-\alpha) \% \)**:

   \[
   \left[ \hat{\theta}^*_{\lfloor B \cdot \alpha/2 \rfloor}, \hat{\theta}^*_{\lfloor B \cdot (1-\alpha/2) \rfloor} \right]
   \]


---

</br></br>
<div class="caja-ejemplo">
<h3>Ejemplo:</h3>
<p>

En este ejemplo, se determina un intervalo de confianza para la media ilustrando el método **Intervalo Percentil Bootstrap** con 
$B=10$, con el objetivo de facilitar la comprensión del método. Posteriormente, con un objetivo inferencial se realiza el cálculo para 
$B=1000$.

---

1. **Generación de Muestras Bootstrap**

El **método bootstrap** consiste en generar múltiples muestras a partir de los datos originales mediante **remuestreo con reemplazo**. En este caso, se tiene un conjunto de datos con \( n = 20 \) observaciones:

\[
X = \{3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50\}
\]

Para obtener una estimación más robusta de la media o cualquier otra estadística, se genera \( B = 1000 \) muestras bootstrap, sin embargo para facilitar la comprensión se usa \( B = 10 \) seleccionando con reemplazo **20 valores** de la muestra original.  

Algunas posibles muestras bootstrap generadas son:

\[
X_1^* = \{10, 25, 5, 10, 20, 35, 50, 12, 3, 7, 9, 33, 45, 42, 15, 5, 37, 28, 40, 30\}
\]

\[
X_2^* = \{15, 15, 20, 5, 10, 22, 28, 40, 45, 37, 30, 25, 50, 3, 12, 9, 18, 35, 33, 7\}
\]

\[
X_3^* = \{42, 33, 40, 12, 18, 9, 5, 7, 15, 22, 50, 28, 25, 3, 35, 30, 10, 37, 45, 20\}
\]

Cada muestra tiene el mismo tamaño (\( n = 20 \)), pero debido al **remuestreo con reemplazo**, algunos valores pueden aparecer más de una vez mientras que otros pueden no aparecer en una muestra específica.

Para generar estas muestras en **R**, se utiliza el siguiente código:


<pre>
# Fijar semilla para reproducibilidad
set.seed(123)

# Datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Número de muestras bootstrap
B <- 10  

# Generar B muestras bootstrap
bootstrap_samples <- replicate(B, sample(X, size = length(X), replace = TRUE))

# Mostrar las primeras diez muestras generadas
#bootstrap_samples[, 1:10]
</pre>


```{r,echo=TRUE}
# Fijar semilla para reproducibilidad
set.seed(123)

# Datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Número de muestras bootstrap
B <- 10  

# Generar B muestras bootstrap
bootstrap_samples <- replicate(B, sample(X, size = length(X), replace = TRUE))

# Mostrar las primeras diez muestras generadas
#bootstrap_samples[, 1:10]
```

Con estas muestras bootstrap, una por cada columna, se puede  calcular las estimaciones de interés, como la media y la mediana, y posteriormente construir intervalos de confianza.


<pre>
> bootstrap_samples[, 1:10]
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]   35   33    3   50   22   12   50   33   45    50
 [2,]   45   40   12   33   28   37   37   12   22    12
 [3,]   33   25   35    7   50   25   25   18   30    42
 [4,]    7   15   20   18   33    9   37   28   25    40
 [5,]   22   28   35   37   40   28   50    9   25    10
 [6,]   42   35   37   28   33   33   18   30   50    50
 [7,]   25   22   50   33    7   45    7   33   15     7
 [8,]   10   30   12    7   18   15    9   37   50    33
 [9,]   50   15   25   33   33   20   50    3   20     3
[10,]   33   20   18   15   45   15   28   18   20     5
[11,]   10   20   15    7   35    5   40   18   10     9
[12,]   45   22   37   35   40   37   22   22   33    22
[13,]   20   15   40   10   25   30   50   18   33     3
[14,]    7   12   42   18   15   45   25   42   12    10
[15,]   18    5   40   45   35   50   18   20    3    18
[16,]   15   10    5   22   12   35   33   15   22    30
[17,]   22   18    9   42   33   15   30   15   40    42
[18,]   20   28   30   22   15    9    5   22   40    22
[19,]   45   30   10   28   22    3   25   25   15    12
[20,]    9   42   45    5   10   18   30    3   20    15
</pre>



---


2. **Cálculo de la Estadística de Interés**

Una vez generadas las muestras bootstrap, el siguiente paso es calcular la **estadística de interés** en cada muestra. En este caso, se utiliza la **media muestral** \( \hat{\theta}_b^* \) como nuestra estadística de interés.

Para cada muestra bootstrap \( X_b^* \), la media se calcula como:

\[
\hat{\theta}_b^* = \frac{1}{n} \sum_{i=1}^{n} X_{bi}^*
\]

donde:

- \( X_{bi}^* \) representa los valores en la muestra bootstrap \( b \).
- \( n = 20 \) es el tamaño de cada muestra bootstrap.
- \( B = 10 \) es el número total de muestras bootstrap generadas.

A continuación, se presentan las medias calculadas para algunas de las muestras bootstrap generadas:

| **Muestra Bootstrap** | **Media Bootstrap \( \hat{\theta}^* \)** |
|----------------------|--------------------------------|
| \( X_1^* \) | \( \bar{X}_1^* = 25.6 \) |
| \( X_2^* \) | \( \bar{X}_2^* = 23.8 \) |
| \( X_3^* \) | \( \bar{X}_3^* = 26.1 \) |
| \( X_4^* \) | \( \bar{X}_4^* = 24.7 \) |
| \( X_5^* \) | \( \bar{X}_5^* = 22.9 \) |

Para calcular las medias de las muestras bootstrap en **R**, se utilizan el siguiente código:

<pre>
# Calcular la media de cada muestra bootstrap
bootstrap_means <- colMeans(bootstrap_samples)

# Mostrar las primeras diez medias calculadas
bootstrap_means[1:10]
</pre>

```{r, echo=TRUE}
# Calcular la media de cada muestra bootstrap
bootstrap_means <- colMeans(bootstrap_samples)

# Mostrar las primeras diez medias calculadas
#bootstrap_means[1:10]
```


<pre>
> bootstrap_means[1:10]
 [1] 25.65 23.25 26.00 24.75 27.55 24.30 29.45 21.05 26.50 21.75
</pre>

Estos valores proporcionan una distribución empírica de la media muestral, la cual se utiliza en el siguiente paso para calcular intervalos de confianza bootstrap

---


3. **Ordenar las Estimaciones Bootstrap**

Después de calcular la estadística de interés para cada muestra bootstrap, el siguiente paso es **ordenar** estas estimaciones para facilitar el cálculo de los intervalos de confianza.

En este caso, se calcula las **medias bootstrap** \( \hat{\theta}_b^* \) y ahora se ordenan en orden ascendente:

\[
\hat{\theta}^*_{(1)} \leq \hat{\theta}^*_{(2)} \leq \dots \leq \hat{\theta}^*_{(B)}
\]

donde:

- \( \hat{\theta}^*_{(b)} \) representa la media de la muestra bootstrap ordenada en la posición \( b \).
- \( B = 10 \) es el número total de muestras bootstrap generadas.


Las medias calculadas de las 10 muestras bootstrap son:

\[
\hat{\theta}^* = \{ 25.65, 23.25, 26.00, 24.75, 27.55, 24.30, 29.45, 21.05, 26.50, 21.75 \}
\]


Ordenando los valores de menor a mayor:

\[
\hat{\theta}^*_{\text{ordenado}} = \{ 21.05, 21.75, 23.25, 24.30, 24.75, 25.65, 26.00, 26.50, 27.55, 29.45 \}
\]

| **Índice \( b \)** | **Media Bootstrap Ordenada \( \hat{\theta}^*_{(b)} \)** |
|--------------------|------------------------------------|
| 1  | 21.05 |
| 2  | 21.75 |
| 3  | 23.25 |
| 4  | 24.30 |
| 5  | 24.75 |
| 6  | 25.65 |
| 7  | 26.00 |
| 8  | 26.50 |
| 9  | 27.55 |
| 10 | 29.45 |

El **código en R para Ordenar las Estimaciones**

Para realizar esta ordenación en **R**, se utiliza el siguiente código:

<pre>
# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Mostrar las medias ordenadas
bootstrap_means_sorted
</pre>


```{r,echo=TRUE}
# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Mostrar las medias ordenadas
bootstrap_means_sorted
```

<pre>
> bootstrap_means_sorted
 [1] 21.05 21.75 23.25 24.30 24.75 25.65 26.00 26.50 27.55 29.45
</pre>

---


4. **Determinar los Percentiles para el Intervalo de Confianza**

El **intervalo de confianza percentil bootstrap** se obtiene a partir de los percentiles \( \alpha/2 \) y \( 1 - \alpha/2 \) de la distribución empírica de la estadística obtenida con el bootstrap. Dado que se trabaja con un nivel de confianza del **95%**, se establece:

\[
\alpha = 0.05, \quad \alpha/2 = 0.025
\]

Para **\( B = 10 \)**, los índices de los percentiles correspondientes al **2.5%** y **97.5%** se calculan como:

\[
\lfloor B \cdot \alpha/2 \rfloor + 1 = \lfloor 10 \times 0.025 \rfloor + 1 = 1
\]

\[
\lfloor B \cdot (1 - \alpha/2) \rfloor = \lfloor 10 \times 0.975 \rfloor = 10
\]

Esto significa que el intervalo de confianza al **95%** se encuentra entre:

\[
\left[ \hat{\theta}^*_{(1)}, \hat{\theta}^*_{(10)} \right]
\]

Usando los valores ordenados previamente, el intervalo de confianza para la media poblacional es:

\[
\left[ 21.05, 29.45 \right]
\]


Para calcular estos percentiles en **R**, se utiliza:

<pre>
# Determinar los percentiles para el intervalo de confianza al 95%
alpha <- 0.05
lower_index <- floor(B * alpha / 2) + 1  # Índice para el percentil 2.5%
upper_index <- floor(B * (1 - alpha / 2))  # Índice para el percentil 97.5%

# Obtener los valores correspondientes
IC_lower <- bootstrap_means_sorted[lower_index]
IC_upper <- bootstrap_means_sorted[upper_index]

# Mostrar el intervalo de confianza
IC <- c(IC_lower, IC_upper)
IC
</pre>

```{r,echo=TRUE}
# Determinar los percentiles para el intervalo de confianza al 95%
alpha <- 0.05
lower_index <- floor(B * alpha / 2) + 1  # Índice para el percentil 2.5%
upper_index <- floor(B * (1 - alpha / 2))  # Índice para el percentil 97.5%

# Obtener los valores correspondientes
IC_lower <- bootstrap_means_sorted[lower_index]
IC_upper <- bootstrap_means_sorted[upper_index]

# Mostrar el intervalo de confianza
IC <- c(IC_lower, IC_upper)
IC
```

Un  **intervalo de confianza Percentil Bootstrap** de la media obtenido para $B=10$ es: 
\[
\left[ 21.05, 29.45 \right]
\]

<pre>
> IC
[1] 21.05 27.55
</pre>

---

</br></br>
Finalmente, para efectos inferenciales,  se repite el proceso usando $B=1000$  usando los siguientes códigos:


<pre>
set.seed(123)  # Para asegurar reproducibilidad

# Datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Número de muestras bootstrap
B <- 1000  

# Generar B muestras bootstrap
bootstrap_samples <- replicate(B, sample(X, size = length(X), replace = TRUE))

# Mostrar las primeras diez muestras generadas
bootstrap_samples[, 1:10]

# Calcular la media de cada muestra bootstrap
bootstrap_means <- colMeans(bootstrap_samples)

# Mostrar las primeras diez medias calculadas
bootstrap_means[1:10]

# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Mostrar las medias ordenadas
bootstrap_means_sorted

# Determinar los percentiles para el intervalo de confianza al 95%
alpha <- 0.05
lower_index <- floor(B * alpha / 2) + 1  # Índice para el percentil 2.5%
upper_index <- floor(B * (1 - alpha / 2))  # Índice para el percentil 97.5%

# Obtener los valores correspondientes
IC_lower <- bootstrap_means_sorted[lower_index]
IC_upper <- bootstrap_means_sorted[upper_index]

# Mostrar el intervalo de confianza
IC <- c(IC_lower, IC_upper)
IC
</pre>


```{r,echo=TRUE}
set.seed(123)  # Para asegurar reproducibilidad

# Datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Número de muestras bootstrap
B <- 1000  

# Generar B muestras bootstrap
bootstrap_samples <- replicate(B, sample(X, size = length(X), replace = TRUE))

# Mostrar las primeras diez muestras generadas
#bootstrap_samples[, 1:10]

# Calcular la media de cada muestra bootstrap
bootstrap_means <- colMeans(bootstrap_samples)

# Mostrar las primeras diez medias calculadas
bootstrap_means[1:10]

# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Mostrar las medias ordenadas
#bootstrap_means_sorted

# Determinar los percentiles para el intervalo de confianza al 95%
alpha <- 0.05
lower_index <- floor(B * alpha / 2) + 1  # Índice para el percentil 2.5%
upper_index <- floor(B * (1 - alpha / 2))  # Índice para el percentil 97.5%

# Obtener los valores correspondientes
IC_lower <- bootstrap_means_sorted[lower_index]
IC_upper <- bootstrap_means_sorted[upper_index]

# Mostrar el intervalo de confianza
#IC <- c(IC_lower, IC_upper)
#IC
```



Un  **intervalo de confianza Percentil Bootstrap** de la media  para $B=1000$ es:


\[
\left[ 18.3, 30.2 \right]
\]


</p>
</div>


---






</br></br></br>
<h4>Intervalo Normal Bootstrap</h4>


Este método asume que la estadística estimada sigue una distribución normal, lo cual se justifica por el teorema central del límite cuando el número de muestras bootstrap es suficientemente grande. Para calcular el intervalo de confianza, se utiliza la **media** de las estimaciones bootstrap y la **desviación estándar** de esas estimaciones.

La fórmula del **intervalo de confianza normal bootstrap** es:

\[
\left[ \hat{\theta}^*_b - z_{\alpha/2} \cdot s_{\hat{\theta}^*_b}, \hat{\theta}^*_b + z_{\alpha/2} \cdot s_{\hat{\theta}^*_b} \right]
\]

Donde:

- \( \hat{\theta}_b^* \) es la **media de las estimaciones bootstrap**, que es el valor de la estadística de interés calculada a partir de las muestras bootstrap.
- \( s_{\hat{\theta}^*_b} \) es la **desviación estándar de las estimaciones bootstrap**, que mide la dispersión de las estimaciones bootstrap alrededor de la media \( \hat{\theta}^*_b \).
- \( z_{\alpha/2} \) es el **valor crítico** de la distribución normal estándar correspondiente al nivel de confianza deseado. Para un intervalo de confianza del 95%, \( z_{\alpha/2} = 1.96 \), pues se determina el cuantil que tiene a la derecha un área de 0.025 bajo la curva normal.

Este método es adecuado cuando las estimaciones bootstrap tienen una distribución aproximadamente normal. El valor \( z_{\alpha/2} \) se obtiene de la distribución normal estándar y corresponde al cuantil que tiene de área a la derecha \( \alpha/2 \).

---


</br></br>
<div class="caja-ejemplo">
<h3>Ejemplo:</h3>
<p>

En este ejemplo, se determina un intervalo de confianza para la media ilustrando el método **Intervalo Normal Bootstrap** con 
$B=10$, con el objetivo de facilitar la comprensión del método. Posteriormente, se realiza el cálculo para 
$B=1000$.

---

1. **Generación de Muestras Bootstrap**

En este ejemplo, utilizamos un conjunto de datos original con \( n = 20 \) observaciones. El conjunto de datos es el siguiente:

\[
X = \{3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50\}
\]

El **método bootstrap** consiste en generar múltiples muestras a partir de los datos originales mediante **remuestreo con reemplazo**. En este caso, generaremos \( B = 10 \) muestras bootstrap (aunque en un caso real \( B = 1000 \) es más adecuado).

Algunas de las muestras bootstrap generadas son las siguientes:

\[
X_1^* = \{10, 25, 5, 10, 20, 35, 50, 12, 3, 7, 9, 33, 45, 42, 15, 5, 37, 28, 40, 30\}
\]

\[
X_2^* = \{15, 15, 20, 5, 10, 22, 28, 40, 45, 37, 30, 25, 50, 3, 12, 9, 18, 35, 33, 7\}
\]

\[
X_3^* = \{42, 33, 40, 12, 18, 9, 5, 7, 15, 22, 50, 28, 25, 3, 35, 30, 10, 37, 45, 20\}
\]

En **R**, el código para generar estas muestras bootstrap es el siguiente:

<pre>
# Fijar semilla para reproducibilidad
set.seed(123)

# Datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Número de muestras bootstrap
B <- 10  

# Generar B muestras bootstrap
bootstrap_samples <- replicate(B, sample(X, size = length(X), replace = TRUE))

# Mostrar las primeras diez muestras generadas
bootstrap_samples[, 1:10]
</pre>

```{r, echo=TRUE}
# Fijar semilla para reproducibilidad
set.seed(123)

# Datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Número de muestras bootstrap
B <- 10  

# Generar B muestras bootstrap
bootstrap_samples <- replicate(B, sample(X, size = length(X), replace = TRUE))

# Mostrar las primeras diez muestras generadas
# bootstrap_samples[, 1:10]
```

Se obtiene una muestra de $n=20$ por cada columna.

<pre>
> bootstrap_samples[, 1:10]
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]   35   33    3   50   22   12   50   33   45    50
 [2,]   45   40   12   33   28   37   37   12   22    12
 [3,]   33   25   35    7   50   25   25   18   30    42
 [4,]    7   15   20   18   33    9   37   28   25    40
 [5,]   22   28   35   37   40   28   50    9   25    10
 [6,]   42   35   37   28   33   33   18   30   50    50
 [7,]   25   22   50   33    7   45    7   33   15     7
 [8,]   10   30   12    7   18   15    9   37   50    33
 [9,]   50   15   25   33   33   20   50    3   20     3
[10,]   33   20   18   15   45   15   28   18   20     5
[11,]   10   20   15    7   35    5   40   18   10     9
[12,]   45   22   37   35   40   37   22   22   33    22
[13,]   20   15   40   10   25   30   50   18   33     3
[14,]    7   12   42   18   15   45   25   42   12    10
[15,]   18    5   40   45   35   50   18   20    3    18
[16,]   15   10    5   22   12   35   33   15   22    30
[17,]   22   18    9   42   33   15   30   15   40    42
[18,]   20   28   30   22   15    9    5   22   40    22
[19,]   45   30   10   28   22    3   25   25   15    12
[20,]    9   42   45    5   10   18   30    3   20    15
</pre>


---

2. **Cálculo de la Estadística de Interés**

Una vez que se han generado las muestras bootstrap, el siguiente paso es calcular la **estadística de interés** en cada muestra. En este caso, se utiliza **la media muestral** \( \hat{\theta}_b^* \) como nuestra estadística de interés.

Para cada muestra bootstrap \( X_b^* \), la media se calcula como:

\[
\hat{\theta}_b^* = \frac{1}{n} \sum_{i=1}^{n} X_{bi}^*
\]

Donde:

- \( X_{bi}^* \) representa los valores de la muestra bootstrap \( b \).
- \( n = 20 \) es el tamaño de cada muestra bootstrap.
- \( B = 10 \) es el número total de muestras bootstrap generadas.

En **R**, se puede calcular la media de cada muestra bootstrap usando la función `colMeans()`. Aquí está el código correspondiente:


<pre>
# Calcular la media de cada muestra bootstrap
bootstrap_means <- colMeans(bootstrap_samples)

# Mostrar las primeras diez medias calculadas
bootstrap_means[1:10]
</pre>

```{r,echo=TRUE}
# Calcular la media de cada muestra bootstrap
bootstrap_means <- colMeans(bootstrap_samples)

# Mostrar las primeras diez medias calculadas
bootstrap_means[1:10]
```

Las medias muestrales, una por cada muestra bootstrap son las siguientes:

<pre>
> bootstrap_means[1:10]
 [1] 25.65 23.25 26.00 24.75 27.55 24.30 29.45 21.05 26.50 21.75
 
</pre>

Estas medias son las estimaciones de la estadística de interés (en este caso, la media muestral) para cada muestra bootstrap y formarán la base para la construcción del intervalo de confianza en los pasos posteriores.


---

3. **Ordenar las Estimaciones Bootstrap**

Después de calcular la estadística de interés (en este caso, las medias bootstrap) en cada muestra, el siguiente paso es **ordenar** estas estimaciones. El ordenamiento facilita el cálculo de los intervalos de confianza al identificar los percentiles correspondientes.

En este caso, se ordenan las **medias bootstrap** \( \hat{\theta}_b^* \) en orden ascendente. La ordenación se realiza de la siguiente manera:

\[
\hat{\theta}^*_{(1)} \leq \hat{\theta}^*_{(2)} \leq \dots \leq \hat{\theta}^*_{(B)}
\]

Donde:

- \( \hat{\theta}^*_{(b)} \) representa la media de la muestra bootstrap ordenada en la posición \( b \).
- \( B = 10 \) es el número total de muestras bootstrap generadas.

El siguiente código en **R** ordena las medias bootstrap en orden ascendente:

<pre>
# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Mostrar las medias ordenadas
bootstrap_means_sorted <- choose(50, 5)
bin_coeff
</pre>


```{r,echo=TRUE}
# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Mostrar las medias ordenadas
# bootstrap_means_sorted
```

Las medias ordenadas son las siguientes:

<pre>
> bootstrap_means_sorted
 [1] 21.05 21.75 23.25 24.30 24.75 25.65 26.00 26.50 27.55 29.45
 
</pre>

---

4. **Determinar el Intervalo de Confianza Normal Bootstrap**

El **intervalo de confianza normal bootstrap** se determina utilizando la **media** y la **desviación estándar** de las estimaciones bootstrap, junto con el valor crítico de la distribución normal estándar \( z_{\alpha/2} \).

La fórmula para el **intervalo de confianza normal bootstrap** es:

\[
\hat{\theta}^*_b \pm z_{\alpha/2} \cdot s_{\hat{\theta}^*_b}
\]

Donde:

- \( \hat{\theta}^*_b \) es la **media de las estimaciones bootstrap**, que es el valor de la estadística de interés calculada a partir de las muestras bootstrap.
- \( s_{\hat{\theta}^*_b} \) es la **desviación estándar de las estimaciones bootstrap**, que mide la dispersión de las estimaciones bootstrap alrededor de la media \( \hat{\theta}^*_b \).
- \( z_{\alpha/2} = 1.96 \) es el **valor crítico** de la distribución normal estándar para un nivel de confianza del 95%.



**Cálculo de la Media y Desviación Estándar de las Medias Bootstrap**

Primero, se calcula la **media** y la **desviación estándar** de las medias bootstrap generadas:

<pre>
# Calcular la media y la desviación estándar de las medias bootstrap
mean_bootstrap <- mean(bootstrap_means)
sd_bootstrap <- sd(bootstrap_means)

# Mostrar resultados
mean_bootstrap
sd_bootstrap
</pre>


```{r,echo=TRUE}
# Calcular la media y la desviación estándar de las medias bootstrap
mean_bootstrap <- mean(bootstrap_means)
sd_bootstrap <- sd(bootstrap_means)

# Mostrar resultados
#mean_bootstrap
#sd_bootstrap
```

Los resultados de \( \hat{\theta}_b^* \) y \( s_{\hat{\theta}^*_b} \) son:

<pre>

> mean_bootstrap
[1] 25.025
> sd_bootstrap
[1] 2.576631

</pre>


Luego, se utiliza  el valor crítico \( z_{\alpha/2} = 1.96 \) para un nivel de confianza del 95% y la fórmula para calcular el intervalo de confianza:

<pre>

# Valor crítico z para un 95% de confianza
z_alpha <- qnorm(1 - alpha / 2)

# Calcular el intervalo de confianza
CI_lower <- mean_bootstrap - z_alpha * sd_bootstrap
CI_upper <- mean_bootstrap + z_alpha * sd_bootstrap

# Mostrar el intervalo de confianza
CI <- c(CI_lower, CI_upper)
CI

</pre>



```{r,echo=TRUE}
# Valor crítico z para un 95% de confianza
z_alpha <- qnorm(1 - alpha / 2)

# Calcular el intervalo de confianza
CI_lower <- mean_bootstrap - z_alpha * sd_bootstrap
CI_upper <- mean_bootstrap + z_alpha * sd_bootstrap

# Mostrar el intervalo de confianza
CI <- c(CI_lower, CI_upper)
#CI
```

Un  **intervalo de confianza normal bootstrap** que proporciona una estimación de la media poblacional utilizando la aproximación normal  usando $B$=10 está determinado por los valores:

<pre>
> CI
[1] 19.9749 30.0751

</pre>




---

A continuación y pensando en efectos inferenciales se determina un **intervalo de confianza normal bootstrap** de la media poblacional

usando $B$=1000. Los códigos se ajustan a continuación al nuevo valor de $B$.


<pre>
# Fijar semilla para reproducibilidad
set.seed(123)

# Datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Número de muestras bootstrap
B <- 1000  

# Generar B muestras bootstrap
bootstrap_samples <- replicate(B, sample(X, size = length(X), replace = TRUE))

# Mostrar las primeras diez muestras generadas
bootstrap_samples[, 1:10]

# Calcular la media de cada muestra bootstrap
bootstrap_means <- colMeans(bootstrap_samples)

# Mostrar las primeras diez medias calculadas
bootstrap_means[1:10]

# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Mostrar las medias ordenadas
# bootstrap_means_sorted

# Calcular la media y la desviación estándar de las medias bootstrap
mean_bootstrap <- mean(bootstrap_means)
sd_bootstrap <- sd(bootstrap_means)

# Mostrar resultados
mean_bootstrap
sd_bootstrap

# Valor crítico z para un 95% de confianza
z_alpha <- qnorm(1 - alpha / 2)

# Calcular el intervalo de confianza
CI_lower <- mean_bootstrap - z_alpha * sd_bootstrap
CI_upper <- mean_bootstrap + z_alpha * sd_bootstrap

# Mostrar el intervalo de confianza
CI <- c(CI_lower, CI_upper)
CI
</pre>





```{r, echo=TRUE}
# Fijar semilla para reproducibilidad
set.seed(123)

# Datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Número de muestras bootstrap
B <- 1000  

# Generar B muestras bootstrap
bootstrap_samples <- replicate(B, sample(X, size = length(X), replace = TRUE))

# Mostrar las primeras diez muestras generadas
bootstrap_samples[, 1:10]

# Calcular la media de cada muestra bootstrap
bootstrap_means <- colMeans(bootstrap_samples)

# Mostrar las primeras diez medias calculadas
bootstrap_means[1:10]

# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Mostrar las medias ordenadas
# bootstrap_means_sorted

# Calcular la media y la desviación estándar de las medias bootstrap
mean_bootstrap <- mean(bootstrap_means)
sd_bootstrap <- sd(bootstrap_means)

# Mostrar resultados
mean_bootstrap
sd_bootstrap

# Valor crítico z para un 95% de confianza
z_alpha <- qnorm(1 - alpha / 2)

# Calcular el intervalo de confianza
CI_lower <- mean_bootstrap - z_alpha * sd_bootstrap
CI_upper <- mean_bootstrap + z_alpha * sd_bootstrap

# Mostrar el intervalo de confianza
#CI <- c(CI_lower, CI_upper)
#CI
```

Un  **IC Normal Bootstrap** para la media usando $B$=1000 está determinado por los valores:

<pre>

> CI
[1] 18.24582 30.38738

</pre>



</p>
</div>










---

</br></br></br>
Previo a la explicación del método **Intervalo Sesgo-Acelerado (BCa)** es necesario entender el **Método Jackknife**, pues requiere de su aplicación para determinar el parámetro de aceleración $a$ que requiere el método BCa.


</br></br>
<h4>Método Jackknife</h4>

El **método Jackknife** es una técnica de remuestreo utilizada en estadística para estimar la precisión de una estimación, como su sesgo o su varianza. En lugar de generar múltiples muestras bootstrap con reemplazo, el Jackknife genera múltiples muestras dejando fuera una única observación en cada iteración.

El Jackknife es especialmente útil cuando se tiene un conjunto de datos pequeño o mediano y se quiere estimar la estabilidad de una estadística de interés, como la media, la varianza, la pendiente de una regresión, etc.

**¿Cómo funciona el Jackknife?**

1. **Definición del Conjunto de Datos**: Si se supone que se tiene se tiene un conjunto de datos con \( n \) observaciones: \( X = \{X_1, X_2, \dots, X_n\} \).

2. **Generación de Muestras Jackknife**: Para cada muestra Jackknife, se excluye una de las observaciones del conjunto de datos original y se calcula la estadística de interés (por ejemplo, la media) para el conjunto de datos restante. Este proceso se repite para cada observación en el conjunto de datos. Es decir, se crean \( n \) muestras Jackknife, donde cada muestra deja fuera una observación distinta.

   - Para la primera muestra Jackknife, se excluye \( X_1 \) y se calcula la estadística de interés usando el conjunto de datos \( X' = \{X_2, X_3, \dots, X_n\} \).
   - Para la segunda muestra Jackknife, se excluye \( X_2 \) y se calcula la estadística de interés usando el conjunto \( X' = \{X_1, X_3, \dots, X_n\} \).
   - Se continua este proceso hasta que se hayan excluido todas las observaciones una por una.

3. **Cálculo de la Estadística Jackknife**: Una vez obtenidas las estadísticas de interés de todas las muestras Jackknife, se calcula la **media** de las estimaciones obtenidas.

   - La media de las estimaciones Jackknife es la estimación que se usa para representar la "media" del proceso de remuestreo.

4. **Estimación de la Precisión**: A partir de las estadísticas Jackknife, se puden calcular **medidas de precisión** como la **varianza Jackknife**, que ofrece una estimación de cuán dispersas están las estimaciones obtenidas.


**Fórmula del Jackknife**

Se denota como \( \hat{\theta} \) a la estadística de interés calculada con el conjunto de datos completo. Luego, para cada muestra Jackknife se calcula la estadística Jackknife \( \hat{\theta}_{(i)} \), donde \( i \) es la observación que se excluye:

\[
\hat{\theta}_{(i)} = f(X_{-i})
\]

Donde:

- \(\hat{\theta}_{(i)}\)=\( f(X_{-i}) \) es la estadística calculada excluyendo la observación \( X_i \).
- \( \hat{\theta} \) es la estadística calculada con todos los datos de la muestra original.

La **media Jackknife** es:

\[
\bar{\theta}_{\cdot}=\bar{\hat{\theta}}_{\text{Jackknife}} = \frac{1}{n} \sum_{i=1}^{n} \hat{\theta}_{(i)}
\]

Y la **varianza Jackknife** se estima como:

\[
\text{Var}_{\text{Jackknife}} = \frac{n-1}{n} \sum_{i=1}^{n} (\hat{\theta}_{(i)} - \bar{\hat{\theta}}_{\text{Jackknife}})^2
\]

---

</br></br></br>
<h4>Intervalo Sesgo-Acelerado (BCa)</h4>

El **Intervalo Sesgo-Acelerado (BCa)** es un método de intervalo de confianza bootstrap avanzado que ajusta la estimación del intervalo de confianza para corregir tanto el sesgo como la aceleración de la estadística de interés. Este método es más robusto que el **Intervalo Percentil Bootstrap** y el **Intervalo Normal Bootstrap**, especialmente cuando la distribución de las estimaciones bootstrap no es simétrica o cuando las estimaciones son sesgadas.

El Intervalo BCa utiliza dos componentes clave para calcular el intervalo de confianza:

-  El **sesgo** (Bias), que mide la diferencia entre la media de las estimaciones bootstrap y la estadística calculada a partir de los datos originales.

- **La aceleración** (Acceleration), que mide cómo cambia la varianza de las estimaciones bootstrap con respecto al valor de la estadística de interés.

El proceso se realiza en los siguientes pasos:

1. **Generar las muestras bootstrap**: Al igual que en otros métodos bootstrap, primero se generan $B$ muestras bootstrap y se calcula la estadística de interés $\hat{\theta}^{*}_b$ para cada muestra.

2. **Cálculo del Sesgo**: El **sesgo** en el método BCa se corrige para ajustar las estimaciones bootstrap y hacerlas más precisas. Este ajuste se realiza calculando el sesgo \( z_0 \), que mide la diferencia entre la media de las estimaciones bootstrap y la estadística calculada a partir de los datos originales.

El sesgo \( z_0 \) se calcula utilizando la siguiente fórmula:

\[
z_0 = \Phi^{-1} \left( \frac{\# \{ \hat{\theta}^{*}_b < \hat{\theta} \}}{B} \right)
\]

Donde:

- \( \hat{\theta}^{*}_b \) es la estadística de interés calculada para la muestra bootstrap \( b \).
- \( \hat{\theta} \) es la estadística de interés calculada a partir de los datos originales.
- \( B \) es el número total de muestras bootstrap generadas.
- \( \Phi^{-1} \) es la función inversa de la distribución acumulada de la normal estándar.

Este valor de \( z_0 \) representa el ajuste necesario para corregir el sesgo en las estimaciones bootstrap, permitiendo que el intervalo de confianza sea más preciso y ajustado a la distribución real de los datos.



3. **Cálculo del Parámetro de Aceleración \( a \)**: El **parámetro de aceleración** \( a \) ajusta el intervalo de confianza para tener en cuenta cómo varía la dispersión de las estimaciones bootstrap con respecto al valor de la estadística. Este ajuste se calcula utilizando el método **Jackknife**, que estimará cómo cambia la varianza de las estimaciones bootstrap al excluir una observación de los datos originales.

La fórmula para calcular el parámetro de aceleración \( a \) es:

\[
a = \frac{ \sum_{i=1}^{n} (\hat{\theta}_{(i)} - \bar{\theta}_{\cdot})^3 }{6 \left[ \sum_{i=1}^{n} (\hat{\theta}_{(i)} - \bar{\theta}_{\cdot})^2 \right]^{3/2} }
\]

Donde

- \( \hat{\theta}_{(i)} \) es la estadística de interés calculada al excluir la observación \( i \) del conjunto de datos original.
- \( \bar{\theta}_{\cdot} \) es la media de las estadísticas \( \hat{\theta}_{(i)} \) calculadas a partir de las muestras "Jackknife".

El parámetro de aceleración \( a \) describe cómo la varianza de las estimaciones bootstrap cambia en función de la estadística de interés. Es un valor clave para ajustar el intervalo BCa, ya que permite tener en cuenta las fluctuaciones en la dispersión de las estimaciones.


4. **Cálculo de los Percentiles Ajustados**

Una vez calculados el **sesgo** \( z_0 \) y el **parámetro de aceleración** \( a \), podemos proceder a calcular los percentiles ajustados para determinar el intervalo de confianza **BCa**.

Los percentiles ajustados se calculan utilizando las siguientes fórmulas:

\[
\alpha_1 = \Phi\left(z_0 + \frac{z_0 + z_{\alpha/2}}{1 - a(z_0 + z_{\alpha/2})}\right)
\]

\[
\alpha_2 = \Phi\left(z_0 + \frac{z_0 + z_{1-\alpha/2}}{1 - a(z_0 + z_{1-\alpha/2})}\right)
\]

Donde:

- \( \Phi \) es la **función de distribución acumulada** de la normal estándar.
- \( z_{\alpha/2} \) y \( z_{1-\alpha/2} \) son los valores críticos de la normal estándar para los percentiles inferiores y superiores, respectivamente, del intervalo de confianza deseado (por ejemplo, para un intervalo del 95%, \( \alpha = 0.05 \)).
- \( z_0 \) es el **sesgo** calculado previamente.
- \( a \) es el **parámetro de aceleración** calculado previamente




</br></br>
<div class="caja-ejemplo">
<h3>Ejemplo:</h3>
<p>
En este ejemplo, se usa la misma muestra original que en los ejemplos anteriores y se determina un intervalo de confianza para la media ilustrando el método **Intervalo Normal Bootstrap** con 
$B=10$, con el objetivo de facilitar la comprensión del método. Posteriormente, se realiza el cálculo para 
$B=1000$.

---

1. **Cálculo del Sesgo \( z_0 \)**: El sesgo \( z_0 \) se calcula utilizando la siguiente fórmula:

\[
z_0 = \Phi^{-1} \left( \frac{\# \{ \hat{\theta}^{*}_b < \hat{\theta} \}}{B} \right)
\]

Donde:

- \( \hat{\theta}^{*}_b \) es la estadística de interés calculada para la muestra bootstrap \( b \).
- \( \hat{\theta} \) es la estadística de interés calculada a partir de los datos originales.
- \( B \) es el número total de muestras bootstrap generadas.
- \( \Phi^{-1} \) es la función inversa de la distribución acumulada de la normal estándar.

Este valor de \( z_0 \) representa el ajuste necesario para corregir el sesgo en las estimaciones bootstrap, permitiendo que el intervalo de confianza sea más preciso y ajustado a la distribución real de los datos.

**Cálculo del Sesgo en R**

En **R**, el sesgo \( z_0 \) se puede calcular utilizando el paquete `boot`, que permite generar muestras bootstrap y calcular sus medias con `boot(X, stat_function, R = B)`, en este caso la función `stat_function` calcula las medias. 

Seguidamente se comparan las medias bootstrap con la media de la muestra original mediante `bootstrap_results$t < original_stat` y se cuentan el número de resultados que son menores que la media original usando el código `sum(bootstrap_results$t < original_stat)`. Este resultado se divide entre el valor de $B$ correspondiente a `length(bootstrap_results$t)`. 

Para las muestras bootstrap generadas con la semilla `set.seed(123)`, se obtuvo con el código `sum(bootstrap_results$t < original_stat) / length(bootstrap_results$t)` el valor de 0.4. Luego se determina el cuantil de la normal estándar que tiene acumulado de área a la izquierda el valor de 0.4  y se encontró el valor de `z_0` -0.2533471.


Los códigos aplicados son los siguientes:


<pre>
# Instalar y cargar el paquete 'boot' si es necesario
# install.packages("boot")
library(boot)

# Definir los datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Definir la función de estadística de interés (en este caso, la media)
stat_function <- function(X, indices) {
  return(mean(X[indices]))
}

# Fijar semilla para reproducibilidad
set.seed(123)

# Número de muestras bootstrap
B <- 10 

# Realizar el bootstrap
bootstrap_results <- boot(X, stat_function, R = B)

# Calcular el sesgo z_0

# media bootstrap
bootstrap_mean <- mean(bootstrap_results$t)

# Estadística original calculada con los datos
original_stat <- mean(X)

# Calcular la proporción de estimaciones bootstrap menores que la estadística original
prop_less_than_original <- sum(bootstrap_results$t < original_stat) / length(bootstrap_results$t)

# Calcular el sesgo z_0 usando la función inversa de la normal estándar
z_0 <- qnorm(prop_less_than_original)

# Mostrar el valor de z_0
z_0
</pre>



```{r,echo=TRUE}
# Instalar y cargar el paquete 'boot' si es necesario
# install.packages("boot")
library(boot)

# Definir los datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Definir la función de estadística de interés (en este caso, la media)
stat_function <- function(X, indices) {
  return(mean(X[indices]))
}

# Fijar semilla para reproducibilidad
set.seed(123)

# Número de muestras bootstrap
B <- 10 

# Realizar el bootstrap
bootstrap_results <- boot(X, stat_function, R = B)

# Calcular el sesgo z_0

# media bootstrap
bootstrap_mean <- mean(bootstrap_results$t)

# Estadística original calculada con los datos
original_stat <- mean(X)

# Calcular la proporción de estimaciones bootstrap menores que la estadística original
prop_less_than_original <- sum(bootstrap_results$t < original_stat) / length(bootstrap_results$t)

# Calcular el sesgo z_0 usando la función inversa de la normal estándar
z_0 <- qnorm(prop_less_than_original)

# Mostrar el valor de z_0
#z_0
```


2. **Cálculo del Parámetro de Aceleración \( a \)**

El **parámetro de aceleración** \( a \) ajusta el intervalo de confianza para tener en cuenta cómo varía la dispersión de las estimaciones bootstrap con respecto al valor de la estadística. Este ajuste se calcula utilizando el método **Jackknife**, que estimará cómo cambia la varianza de las estimaciones bootstrap al excluir una observación de los datos originales.

La fórmula para calcular el parámetro de aceleración \( a \) es:

\[
a = \frac{ \sum_{i=1}^{n} (\hat{\theta}_{(i)} - \bar{\theta}_{\cdot})^3 }{6 \left[ \sum_{i=1}^{n} (\hat{\theta}_{(i)} - \bar{\theta}_{\cdot})^2 \right]^{3/2} }
\]

Donde:

- \( \hat{\theta}_{(i)} \) es la estadística de interés calculada al excluir la observación \( i \) del conjunto de datos original.
- \( \bar{\theta}_{\cdot} \) es la media de las estadísticas \( \hat{\theta}_{(i)} \) calculadas a partir de las muestras "Jackknife".

El parámetro de aceleración \( a \) describe cómo la varianza de las estimaciones bootstrap cambia en función de la estadística de interés. Es un valor clave para ajustar el intervalo BCa, ya que permite tener en cuenta las fluctuaciones en la dispersión de las estimaciones.

**Cálculo del Parámetro de Aceleración en R**

En **R**, podemos calcular el parámetro de aceleración \( a \) usando el siguiente código. Primero, calculamos las estadísticas de Jackknife y luego aplicamos la fórmula para \( a \). 


El cálculo del parámetro de aceleración \( a \) se realiza mediante la función `jackknife_function`, que genera las muestras jackknife eliminando, de manera secuencial, una observación de la muestra original. Para cada una de estas muestras, se calcula la estadística de interés, que en este caso es la media. Luego, se obtiene la media de todas las medias jackknife, la cual se utiliza para calcular el numerador y el denominador de la fórmula del parámetro de aceleración. Finalmente, al dividir estos valores, se determina el coeficiente de aceleración \( a \).

Los códigos en detalle son los siguientes:

<pre>
# Definir la función Jackknife para calcular la aceleración
jackknife_function <- function(data, stat_function) {
  n <- length(data)
  jackknife_values <- numeric(n)
  
  # Calcular las estadísticas Jackknife al excluir cada observación
  for (i in 1:n) {
    jackknife_values[i] <- stat_function(data[-i])
  }
  
  # Calcular la media Jackknife
  jackknife_mean <- mean(jackknife_values)
  
  # Calcular el parámetro de aceleración a
  numerador <- sum((jackknife_values - jackknife_mean)^3)
  denominador <- 6*sum((jackknife_values - jackknife_mean)^2)^(3/2)
  
  a <- numerador / denominador
  
  return(list(a,jackknife_values,jackknife_mean,numerador,denominador))
}

# Usar los datos originales para calcular la aceleración
resultados <- jackknife_function(X, mean)  # Aquí X es la muestra original

# Mostrar el valor de a
a_value<-resultados[[1]]
</pre>


```{r}
# Definir la función Jackknife para calcular la aceleración
jackknife_function <- function(data, stat_function) {
  n <- length(data)
  jackknife_values <- numeric(n)
  
  # Calcular las estadísticas Jackknife al excluir cada observación
  for (i in 1:n) {
    jackknife_values[i] <- stat_function(data[-i])
  }
  
  # Calcular la media Jackknife
  jackknife_mean <- mean(jackknife_values)
  
  # Calcular el parámetro de aceleración a
  numerador <- sum((jackknife_values - jackknife_mean)^3)
  denominador <- 6*sum((jackknife_values - jackknife_mean)^2)^(3/2)
  
  a <- numerador / denominador
  
  return(list(a,jackknife_values,jackknife_mean,numerador,denominador))
}

# Usar los datos originales para calcular la aceleración
resultados <- jackknife_function(X, mean)  # Aquí X es la muestra original

# Mostrar el valor de a
a_value<-resultados[[1]]
```


Las medias muestrales por cada una de las 20 muestras Jackknife son las siguientes:

<pre>
> resultados
[[2]]
 [1] 25.42105 25.31579 25.21053 25.10526 25.05263 24.94737 24.78947 24.63158 24.52632 24.42105 24.26316 24.10526 24.00000 23.84211 23.73684
[16] 23.63158 23.47368 23.36842 23.21053 22.94737

</pre>

El promedio de los promedios de las muestras Jackknife es el valor: 

<pre>

[[3]]
[1] 24.3

</pre>
 
El valor de $a$ y los valores calculados como numerador y denominador son: 


<pre>
[[1]]
[1] -0.005370197

[[4]]
[1] -1.149509

[[5]]
[1] 214.0533
</pre>



3. **Cálculo de los Percentiles Ajustados**

Una vez calculados el **sesgo** \( z_0 \) y el **parámetro de aceleración** \( a \), el siguiente paso es calcular los **percentiles ajustados** \( \alpha_1 \) y \( \alpha_2 \) que se utilizan para determinar el intervalo de confianza **BCa**.

Los percentiles ajustados se calculan utilizando las siguientes fórmulas:

\[
\alpha_1 = \Phi\left(z_0 + \frac{z_0 + z_{\alpha/2}}{1 - a(z_0 + z_{\alpha/2})}\right)
\]

\[
\alpha_2 = \Phi\left(z_0 + \frac{z_0 + z_{1-\alpha/2}}{1 - a(z_0 + z_{1-\alpha/2})}\right)
\]

Donde:

- \( \Phi \) es la **función de distribución acumulada** de la normal estándar.
- \( z_{\alpha/2} \) y \( z_{1-\alpha/2} \) son los valores críticos de la distribución normal estándar para los percentiles inferior y superior del intervalo de confianza deseado (por ejemplo, para un intervalo del 95%, \( \alpha = 0.05 \)).
- \( z_0 \) es el **sesgo** calculado previamente.
- \( a \) es el **parámetro de aceleración** calculado previamente.

Los percentiles ajustados \( \alpha_1 \) y \( \alpha_2 \) determinan los límites inferior y superior del intervalo de confianza ajustado. 


**Cálculo de los Percentiles Ajustados en R**

En **R**, los percentiles ajustados se pueden calcular utilizando las fórmulas anteriores. A continuación se muestra el código que realiza este cálculo:

<pre>
# Definir el nivel de significancia
alpha <- 0.05  # Nivel de significancia para el intervalo de confianza del 95%

# Calcular los percentiles ajustados alpha_1 y alpha_2
alpha_1 <- pnorm(z_0 + (z_0 + qnorm(alpha / 2)) / (1 - a_value * (z_0 + qnorm(alpha / 2))))
alpha_2 <- pnorm(z_0 + (z_0 + qnorm(1 - alpha / 2)) / (1 - a_value * (z_0 + qnorm(1 - alpha / 2))))

# Mostrar los percentiles ajustados
alpha_1
alpha_2
</pre>


```{r,echo=TRUE}
# Definir el nivel de significancia
alpha <- 0.05  # Nivel de significancia para el intervalo de confianza del 95%

# Calcular los percentiles ajustados alpha_1 y alpha_2
alpha_1 <- pnorm(z_0 + (z_0 + qnorm(alpha / 2)) / (1 - a_value * (z_0 + qnorm(alpha / 2))))
alpha_2 <- pnorm(z_0 + (z_0 + qnorm(1 - alpha / 2)) / (1 - a_value * (z_0 + qnorm(1 - alpha / 2))))

# Mostrar los percentiles ajustados
alpha_1
alpha_2
```

Los valores resultantes son:

<pre>

> # Mostrar los percentiles ajustados
> alpha_1
[1] 0.006328416
> alpha_2
[1] 0.9247505

</pre>


4. **Generación del Intervalo BCa**

Una vez que hemos calculado los **percentiles ajustados** \( \alpha_1 \) y \( \alpha_2 \), el siguiente paso es obtener el **intervalo de confianza BCa** para la estadística de interés (en este caso, la **media**).

El intervalo de confianza BCa se calcula utilizando los percentiles ajustados \( \alpha_1 \) y \( \alpha_2 \) en la distribución de las estadísticas bootstrap ordenadas.

La fórmula para el intervalo de confianza BCa es:

\[
\left[ \hat{\theta}^*_b \left( \alpha_1 \right), \hat{\theta}^*_b \left( \alpha_2 \right) \right]
\]

Donde:

- \( \hat{\theta}^*_b \) es la **media** por cada muestra bootstrap generada.
- \( \alpha_1 \) y \( \alpha_2 \) son los **percentiles ajustados** calculados previamente.

**Cálculo del Intervalo BCa en R**

Una vez que tenemos los percentiles ajustados, podemos usar estos valores para determinar los límites inferior y superior del intervalo de confianza BCa. A continuación se muestra el código en **R** para calcular el intervalo BCa:

<pre>
# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Obtener los valores correspondientes de los percentiles ajustados
IC_lower <- bootstrap_means_sorted[floor(B * alpha_1) + 1]
IC_upper <- bootstrap_means_sorted[floor(B * alpha_2)]

# Mostrar el intervalo BCa
IC <- c(IC_lower, IC_upper)
IC
</pre>


```{r,echo=TRUE}
# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Obtener los valores correspondientes de los percentiles ajustados
IC_lower <- bootstrap_means_sorted[floor(B * alpha_1) + 1]
IC_upper <- bootstrap_means_sorted[floor(B * alpha_2)]

# Mostrar el intervalo BCa
IC <- c(IC_lower, IC_upper)
IC
```

Un  **intervalo BCa** para la media usando $B$= 10 está determinado por los valores:


<pre>

> IC
[1] 21.05 26.50

</pre>


---

Ahora usando $B$=1000 para fectos inferenciales  se tiene los códigos siguientes:


<pre>

#---Paso 1

#---Paso 1

# Instalar y cargar el paquete 'boot' si es necesario
# install.packages("boot")
library(boot)

# Definir los datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Definir la función de estadística de interés (en este caso, la media)
stat_function <- function(X, indices) {
  return(mean(X[indices]))
}

# Fijar semilla para reproducibilidad
set.seed(123)

# Número de muestras bootstrap
B <- 1000 

# Realizar el bootstrap
bootstrap_results <- boot(X, stat_function, R = B)

# Calcular el sesgo z_0

# media bootstrap
bootstrap_mean <- mean(bootstrap_results$t)

# Estadística original calculada con los datos
original_stat <- mean(X)

# Calcular la proporción de estimaciones bootstrap menores que la estadística original
prop_less_than_original <- sum(bootstrap_results$t < original_stat) / length(bootstrap_results$t)

# Calcular el sesgo z_0 usando la función inversa de la normal estándar
z_0 <- qnorm(prop_less_than_original)

# Mostrar el valor de z_0
z_0


#---Paso 2

# Definir la función Jackknife para calcular la aceleración
jackknife_function <- function(data, stat_function) {
  n <- length(data)
  jackknife_values <- numeric(n)
  
  # Calcular las estadísticas Jackknife al excluir cada observación
  for (i in 1:n) {
    jackknife_values[i] <- stat_function(data[-i])
  }
  
  # Calcular la media Jackknife
  jackknife_mean <- mean(jackknife_values)
  
  # Calcular el parámetro de aceleración a
  numerador <- sum((jackknife_values - jackknife_mean)^3)
  denominador <- 6*sum((jackknife_values - jackknife_mean)^2)^(3/2)
  
  a <- numerador / denominador
  
  return(list(a,jackknife_values,jackknife_mean,numerador,denominador))
}

# Usar los datos originales para calcular la aceleración
resultados <- jackknife_function(X, mean)  # Aquí X es la muestra original

# Mostrar el valor de a
a_value<-resultados[[1]]


#---Paso 3

# Definir el nivel de significancia
alpha <- 0.05  # Nivel de significancia para el intervalo de confianza del 95%

# Calcular los percentiles ajustados alpha_1 y alpha_2
alpha_1 <- pnorm(z_0 + (z_0 + qnorm(alpha / 2)) / (1 - a_value * (z_0 + qnorm(alpha / 2))))
alpha_2 <- pnorm(z_0 + (z_0 + qnorm(1 - alpha / 2)) / (1 - a_value * (z_0 + qnorm(1 - alpha / 2))))

# Mostrar los percentiles ajustados
alpha_1
alpha_2

#---Paso 4

# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Obtener los valores correspondientes de los percentiles ajustados
IC_lower <- bootstrap_means_sorted[floor(B * alpha_1) + 1]
IC_upper <- bootstrap_means_sorted[floor(B * alpha_2)]

# Mostrar el intervalo BCa
IC <- c(IC_lower, IC_upper)
IC

</pre>


```{r,echo=TRUE}

#---Paso 1

# Instalar y cargar el paquete 'boot' si es necesario
# install.packages("boot")
library(boot)

# Definir los datos originales
X <- c(3, 5, 7, 9, 10, 12, 15, 18, 20, 22, 25, 28, 30, 33, 35, 37, 40, 42, 45, 50)

# Definir la función de estadística de interés (en este caso, la media)
stat_function <- function(X, indices) {
  return(mean(X[indices]))
}

# Fijar semilla para reproducibilidad
set.seed(123)

# Número de muestras bootstrap
B <- 1000 

# Realizar el bootstrap
bootstrap_results <- boot(X, stat_function, R = B)

# Calcular el sesgo z_0

# media bootstrap
bootstrap_mean <- mean(bootstrap_results$t)

# Estadística original calculada con los datos
original_stat <- mean(X)

# Calcular la proporción de estimaciones bootstrap menores que la estadística original
prop_less_than_original <- sum(bootstrap_results$t < original_stat) / length(bootstrap_results$t)

# Calcular el sesgo z_0 usando la función inversa de la normal estándar
z_0 <- qnorm(prop_less_than_original)

# Mostrar el valor de z_0
z_0


#---Paso 2

# Definir la función Jackknife para calcular la aceleración
jackknife_function <- function(data, stat_function) {
  n <- length(data)
  jackknife_values <- numeric(n)
  
  # Calcular las estadísticas Jackknife al excluir cada observación
  for (i in 1:n) {
    jackknife_values[i] <- stat_function(data[-i])
  }
  
  # Calcular la media Jackknife
  jackknife_mean <- mean(jackknife_values)
  
  # Calcular el parámetro de aceleración a
  numerador <- sum((jackknife_values - jackknife_mean)^3)
  denominador <- 6*sum((jackknife_values - jackknife_mean)^2)^(3/2)
  
  a <- numerador / denominador
  
  return(list(a,jackknife_values,jackknife_mean,numerador,denominador))
}

# Usar los datos originales para calcular la aceleración
resultados <- jackknife_function(X, mean)  # Aquí X es la muestra original

# Mostrar el valor de a
a_value<-resultados[[1]]


#---Paso 3

# Definir el nivel de significancia
alpha <- 0.05  # Nivel de significancia para el intervalo de confianza del 95%

# Calcular los percentiles ajustados alpha_1 y alpha_2
alpha_1 <- pnorm(z_0 + (z_0 + qnorm(alpha / 2)) / (1 - a_value * (z_0 + qnorm(alpha / 2))))
alpha_2 <- pnorm(z_0 + (z_0 + qnorm(1 - alpha / 2)) / (1 - a_value * (z_0 + qnorm(1 - alpha / 2))))

# Mostrar los percentiles ajustados
alpha_1
alpha_2

#---Paso 4

# Ordenar las medias bootstrap en orden ascendente
bootstrap_means_sorted <- sort(bootstrap_means)

# Obtener los valores correspondientes de los percentiles ajustados
IC_lower <- bootstrap_means_sorted[floor(B * alpha_1) + 1]
IC_upper <- bootstrap_means_sorted[floor(B * alpha_2)]

# Mostrar el intervalo BCa
IC <- c(IC_lower, IC_upper)
IC
```


Un **intervalo BCa para la media** usando $B$= 1000 está determinado por los valores:


<pre>

> IC
[1] 18.50 30.45

</pre>

</p>
</div>

---


</br></br></br>
<h4>Intervalo de Studentizado (t-bootstrap)</h4>

Este método se basa en la distribución t de Student en lugar de la normal.

\[
t_b = \frac{\hat{\theta}^*_b - \hat{\theta}}{s_b}
\]

y el intervalo se construye con los percentiles de la distribución de \( t_b \).




<div class="caja-actividad">
<h3>Actividad:</h3>
>
<p>
- Consulta cómo aplicar el método Intervalo de Studentizado (t-bootstrap) y aplica el método para determinar un intervalo Bootstrap para la media usando la misma muestra original de los ejemplos de esta sección.
</p>
>
</div>










