---
title : <span style="color:#034a94"> **Pruebas de hipótesis no paramétricas**</span>
author: "Métodos y Simulación Estadística"
output:
  html_document:
    toc: no
    toc_depth: 2
    toc_float: yes
    code_folding: hide
    css: style.css
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, comment = NA)
library(paqueteMETODOS)
data("CarreraLuz22")
CarreraLuz22M = subset(CarreraLuz22, CarreraLuz22$sex=="Hombre")
CarreraLuz22F = subset(CarreraLuz22, CarreraLuz22$sex=="Mujer")
CarreraLuz22F3 = subset(CarreraLuz22F, CarreraLuz22F$categoria=="3. Veteranos A")
w =c(58.36667,  65.25000,  75.95000,  81.15000,  55.28333,  60.51667, 65.66667,  83.05000,  91.98333,  78.11667,  57.80000,  55.35000, 64.28333,  83.01667,  63.90000,  50.16667,  70.90000,  87.15000, 62.36667,  73.30000,  62.98333,  62.46667,  56.73333,  76.48333, 78.78333,  87.95000,  60.91667,  74.13333,  71.11667,  65.55000, 52.20000,  60.61667,  78.76667,  70.83333,  79.16667,  68.50000, 64.93333,  84.76667,  82.86667,72.73333,  66.78333,  66.35000, 92.98333,  96.11667,  61.53333,  62.28333, 74.60000,  75.90000, 88.98333,  70.16667,  72.61667,  71.33333,  66.30000,  60.40000, 62.03333,  83.95000,  63.50000,  69.95000,  72.51667,  78.93333, 63.95000,  81.41667,  63.36667,  80.40000,  71.58333,  56.01667, 57.33333,  89.55000,  63.85000,  87.48333, 101.46667,  71.70000, 60.08333,  48.36667,  89.03333,  65.30000,  55.96667,  86.45000, 72.91667,  75.91667,  56.10000,  69.75000,  76.20000,  60.40000, 53.21667,  75.33333,  84.05000,  78.26667,  59.28333,  67.50000, 62.03333,  66.46667,  62.58333,  73.38333,  65.15000,  74.68333, 58.88333,  70.16667,55.05000,  68.46667)


xF1=c(52.20000, 78.93333, 65.48333, 73.26667, 63.93333, 70.10000, 55.66667, 84.10000, 73.28333, 71.71667, 58.38333, 73.38333, 56.06667, 70.16667, 66.40000, 65.05000, 68.50000, 77.46667, 72.18333, 78.15000, 67.50000, 93.48333, 59.28333, 59.05000, 79.05000, 63.01667, 74.16667, 55.05000, 75.26667, 77.53333, 73.86667, 63.70000, 69.75000, 70.83333, 70.28333, 56.48333, 53.65000, 80.78333, 93.71667,73.95000, 70.70000, 45.80000, 58.36667, 81.48333, 59.00000, 68.75000, 42.08333, 66.18333, 63.36667, 74.60000, 76.36667, 70.88333, 81.91667, 81.83333, 60.30000, 48.36667, 66.31667, 70.48333, 74.18333, 65.50000, 87.41667, 92.98333, 80.05000, 72.61667, 75.91667, 90.71667, 62.33333, 82.55000, 75.90000, 65.65000, 60.86667, 62.03333, 62.61667, 68.53333, 89.03333, 58.25000, 59.85000, 85.11667, 68.03333, 78.01667, 57.21667, 66.86667, 93.30000, 65.95000, 61.03333, 66.06667, 86.50000, 82.91667, 47.68333, 73.90000, 62.36667, 90.08333, 62.76667, 77.61667, 62.28333, 68.25000, 65.86667, 81.10000, 82.23333, 84.33333)

xM1=c(36.88333, 69.16667, 78.15000, 69.55000, 69.88333, 77.91667, 50.75000, 62.18333, 70.58333, 55.36667, 44.35000, 51.85000, 68.23333, 83.36667, 55.30000, 74.30000, 54.60000, 57.41667, 84.25000, 75.81667, 58.81667, 81.76667, 67.68333, 44.20000, 68.36667, 57.06667, 82.36667, 67.18333, 58.36667, 81.23333, 52.75000, 41.00000, 53.08333, 55.08333, 52.91667, 62.48333, 61.11667, 58.03333, 39.30000, 61.01667, 60.73333, 66.88333, 63.66667, 66.65000, 69.30000, 68.66667, 63.50000, 49.46667, 76.10000, 52.98333, 79.23333, 62.86667, 47.96667, 56.48333, 68.13333, 53.31667, 60.48333, 64.31667, 69.11667, 65.40000, 51.03333, 64.38333, 70.21667, 60.73333, 65.96667, 58.18333, 70.71667, 60.20000, 67.33333, 47.26667, 83.35000, 52.66667, 53.90000, 62.38333, 77.25000, 57.90000, 47.98333, 75.58333, 58.31667, 66.18333, 60.41667, 58.50000, 49.65000, 49.63333, 56.70000, 67.18333, 71.85000, 69.01667, 83.61667, 60.41667, 78.86667, 69.51667, 64.90000, 73.71667, 49.01667, 98.76667, 79.93333, 55.00000, 73.55000, 57.35000)


xMa =c(
86.13333,  71.50000,  55.60000,  80.51667,  55.83333, 103.03333,  48.88333,  72.68333,  57.66667,  52.40000, 71.18333,  79.40000,  72.76667,  56.43333,  60.78333,  49.70000,  51.30000,  61.90000,  39.10000,  48.21667, 57.33333,  57.20000,  44.13333,  53.15000,  68.80000,  61.26667,  50.30000,  51.46667,  59.58333,  61.83333, 72.63333,  81.91667,  66.56667,  47.96667,  48.65000,  55.71667,  34.71667,  61.05000,  53.78333,  84.25000, 53.68333,  77.31667,  59.76667,  75.58333,  50.35000,  64.66667,  79.86667,  85.78333,  68.36667,  75.10000, 42.76667,  82.83333,  58.18333,  89.81667,  66.23333,  59.33333,  64.63333,  69.01667,  69.86667,  64.60000, 61.01667,  43.21667,  41.86667,  54.50000,  67.70000,  68.83333,  62.38333,  66.13333,  79.80000,  59.55000, 44.28333,  61.40000,  86.18333,  53.78333,  62.48333,  59.85000,  89.58333,  62.30000,  77.15000,  57.03333, 76.98333,  56.10000,  57.88333,  77.40000,  66.48333,  53.70000,  47.96667,  55.21667,  62.01667,  46.78333, 58.16667,  62.88333,  48.00000,  39.38333,  51.00000,  69.05000,  61.13333,  60.63333,  58.26667,  63.05000)

xMd=c(
76.18333, 47.88333, 74.18333, 74.55000, 58.11667, 53.51667, 70.56667, 57.95000, 78.63333, 62.48333, 77.51667, 69.73333, 66.73333, 98.83333, 38.36667, 76.88333, 53.91667, 60.11667, 77.40000, 57.56667, 75.95000, 70.16667, 53.20000, 58.03333, 60.48333, 59.41667, 45.85000, 72.51667, 63.05000, 47.61667, 46.93333, 74.30000, 57.33333, 79.80000, 55.45000, 56.08333, 63.76667, 65.11667, 50.35000, 61.60000, 61.28333, 43.21667, 51.93333, 56.63333, 46.30000, 71.85000, 82.13333, 68.85000, 76.98333, 59.76667, 61.15000, 56.03333, 52.88333, 53.01667, 55.58333, 69.05000, 71.15000, 63.05000, 56.93333, 57.00000, 56.63333, 50.81667, 76.66667, 54.05000, 79.50000, 46.10000, 81.06667, 63.80000, 63.05000, 61.78333, 33.13333, 49.76667, 73.71667, 60.00000, 60.73333, 61.85000, 64.40000, 52.75000, 65.91667, 47.98333, 51.15000, 59.68333, 50.30000, 44.85000, 71.05000, 56.26667, 56.41667, 82.36667,71.53333, 65.05000, 48.00000, 62.88333, 56.03333, 51.81667, 53.16667, 45.25000, 42.16667, 53.76667, 61.01667, 52.26667)

```


<br/><br/>

# <span style="color:#034a94">**Pruebas no paramétricas**</span>



## <span style="color:#034a94">**Prueba de rachas**</span>

Se desea extraer una muestra aleatoria del grupo de participantes y probar que es aleatoria con respecto al sexo.

|                                       |
|:--------------------------------------|
|$Ho$: $X$ es aleatoria                 | 
|$Ha$: $X$ NO es aleatoria              |

```{r}
library(randtests)
x=sample(CarreraLuz22$sex, 100)
rachas<-as.numeric(x=="Hombre")
runs.test(rachas,alternative = "left.sided",threshold = 0.5,pvalue = "exact",plot=F)

```


<br/><br/><br/>

## <span style="color:#034a94">**Pruebas de normalidad**</span>

Existen varias pruebas de hipótesis para verificar si una variable tiene un comportamiento aproximadamente normal.En todos los casos las hipótesis planteadas son:

<br/>

|                                       |
|:--------------------------------------|
|$Ho$: $X$ tiene distribución Normal    | 
|$Ha$: $X$ no tiene distribución Normal |

<br/>

```{r}
plot(density(w))
```



### <span style="color:#034a94">**Prueba de Shapiro Wilk**</span>

La prueba de Shapiro-Wilk se utiliza para verificar si una muestra de datos sigue una distribución normal. Se puede utilizar antes de realizar pruebas paramétricas que asumen normalidad, como la prueba t de Student o el análisis de varianza (ANOVA). Se recomienda realizar la prueba de Shapiro-Wilk cuando se tienen dudas sobre la normalidad de los datos, especialmente si se trabaja con muestras pequeñas (menos de 50 observaciones), ya que en muestras grandes la prueba puede ser sensible y detectar pequeñas desviaciones de la normalidad que no son relevantes en la práctica.

```{r}
shapiro.test(w)
```
Esta prueba no requiere la instalación de paquetes adicionales, está disponible en la configuración básica de R


<br/><br/>

### <span style="color:#034a94">**Paquete normtest**</span>

Las siguientes pruebas requieren instalar y cargar el paquete: `normtest`

```{r}
# install.packages("normtets")
library(nortest)
```

<br/><br/>

### <span style="color:#034a94">**Prueba Jarque-Bera ajustada**

La prueba de Jarque-Bera ajustada se utiliza para verificar si una muestra de datos sigue una distribución normal. A diferencia de la prueba de Shapiro-Wilk, la prueba de Jarque-Bera es más adecuada para muestras grandes (más de 200 observaciones) debido a su mayor poder estadístico. Se recomienda utilizar la prueba de Jarque-Bera ajustada cuando se tiene una muestra grande y se quiere verificar la normalidad de los datos antes de realizar pruebas paramétricas que asumen normalidad.

```{r}
#ajb.norm.test(w)	

```

<br/><br/>

### <span style="color:#034a94">**Prueba de Frosini**</span>

La prueba de Frosini es una prueba estadística diseñada para verificar si una muestra de datos sigue una distribución normal. Esta prueba se basa en la comparación de la media y la varianza muestral con la media y la varianza de una distribución normal estándar. Sin embargo, la prueba de Frosini no es tan conocida ni ampliamente utilizada como otras pruebas de normalidad más comunes, como la prueba de Shapiro-Wilk o la prueba de Kolmogorov-Smirnov. 


```{r}
#frosini.norm.test(w)	
```

<br/><br/>

### <span style="color:#034a94">**Prueba de Geary**</span>

La prueba de Geary, también conocida como razón de Geary o estadístico de Geary, es una medida de auto-correlación espacial que se utiliza en análisis espaciales para evaluar si existe autocorrelación espacial en un conjunto de datos. La prueba se basa en la comparación de las diferencias entre valores observados y valores vecinos en una serie de datos espaciales. Una razón de Geary cercana a 1 indica ausencia de autocorrelación espacial, mientras que valores significativamente más bajos pueden indicar autocorrelación espacial. La prueba de Geary se utiliza principalmente en estudios de geografía, ecología y otras disciplinas relacionadas con datos espaciales.

```{r}
#geary.norm.test(w)	
```

<br/><br/>

### <span style="color:#034a94">**Prueba de Hagazy-Green 1**</span>

La prueba de Hegazy-Green se utiliza para verificar la normalidad de una muestra de datos. Se puede utilizar en diversos contextos, como en análisis de datos, estudios estadísticos y en la validación de modelos que asumen una distribución normal de los datos.

Se recomienda utilizar esta prueba cuando se desea verificar si una muestra de datos sigue una distribución normal y se quiere tener una alternativa a otras pruebas de normalidad más comunes, como la prueba de Shapiro-Wilk o la prueba de Kolmogorov-Smirnov. La prueba de Hegazy-Green puede ser útil cuando se desea explorar diferentes enfoques para verificar la normalidad de los datos, especialmente en investigaciones donde la normalidad es un supuesto importante.

```{r}
#hegazy1.norm.test(w)	
```

<br/>

### <span style="color:#034a94">**Prueba de Hagazy-Green 2**</span>

```{r}
#hegazy2.norm.test(w)
```

<br/><br/>

### <span style="color:#034a94">**Prueba de Jarque-Bera**</span>

La prueba de Jarque-Bera es una prueba de normalidad que se utiliza para verificar si una muestra de datos sigue una distribución normal. Esta prueba se basa en la asimetría y la curtosis de los datos. La asimetría mide la falta de simetría en la distribución de los datos, mientras que la curtosis mide la forma de la distribución en relación con una distribución normal.

En la prueba de Jarque-Bera, se calcula un estadístico de prueba que se distribuye asintóticamente como una distribución chi-cuadrado con 2 grados de libertad bajo la hipótesis nula de que los datos son normalmente distribuidos. Se compara este estadístico con un valor crítico de la distribución chi-cuadrado para determinar si se rechaza o no la hipótesis nula.


```{r}
#jb.norm.test(w)	
```

<br/><br/>

### <span style="color:#034a94">**Prueba de kurtosis**</span>

La kurtosis es una medida que describe la forma de la distribución de los datos en relación con una distribución normal. Indica qué tan puntiaguda o achatada es la distribución en comparación con una distribución normal. Una kurtosis alta indica una distribución más puntiaguda (colas más pesadas) que la distribución normal, mientras que una kurtosis baja indica una distribución más achatada (colas más ligeras) que la distribución normal.

La prueba de kurtosis se puede utilizar para verificar si la kurtosis de una muestra de datos es significativamente diferente de la kurtosis de una distribución normal. Sin embargo, es importante tener en cuenta que la kurtosis por sí sola no es una medida concluyente de la normalidad de los datos, ya que una distribución puede tener una kurtosis similar a la de una distribución normal y aún así no ser normal.


```{r}
#kurtosis.norm.test(w)
```

<br/><br/>

### <span style="color:#034a94">**Prueba de sesgo**</span>

La prueba de asimetría se utiliza para evaluar si la asimetría de una muestra de datos es significativamente diferente de la de una distribución normal. La asimetría mide la falta de simetría en la distribución de los datos, indicando si los datos están sesgados hacia la izquierda o hacia la derecha en comparación con una distribución normal, que tiene una asimetría de 0.

Hay varias pruebas estadísticas que se pueden utilizar para probar la asimetría, como la prueba omnibus de D'Agostino-Pearson, la prueba de Jarque-Bera y la prueba de Shapiro-Wilk. Estas pruebas examinan diferentes aspectos de la distribución de los datos para determinar si se desvía significativamente de la normalidad.

```{r}
#skewness.norm.test(w)	
```

<br/><br/>

### <span style="color:#034a94">**Prueba de Spiegelhalter**</span>

a prueba de Spiegelhalter es una prueba estadística utilizada para evaluar si una muestra de datos sigue una distribución normal. Esta prueba se basa en la comparación de la curtosis y la asimetría de los datos con los valores esperados bajo una distribución normal.

La prueba de Spiegelhalter es una de las pruebas de normalidad menos comunes y no es tan ampliamente utilizada como otras pruebas más establecidas, como la prueba de Shapiro-Wilk o la prueba de Kolmogorov-Smirnov. Por lo tanto, se recomienda utilizar las pruebas más comunes y ampliamente aceptadas para verificar la normalidad de los datos.


```{r}
#spiegelhalter.norm.test(w)	
```

<br/><br/>

### <span style="color:#034a94">**Prueba de Weisberg-Bingham**</span>

La prueba de Weisberg-Bingham es una prueba de normalidad que se utiliza para verificar si una muestra de datos sigue una distribución normal. Esta prueba se basa en la comparación de la curtosis y la asimetría de los datos con los valores esperados bajo una distribución normal.

Al igual que la prueba de Spiegelhalter, la prueba de Weisberg-Bingham no es tan común ni tan ampliamente utilizada como otras pruebas de normalidad más establecidas, como la prueba de Shapiro-Wilk o la prueba de Kolmogorov-Smirnov. Por lo tanto, se recomienda utilizar las pruebas más comunes y ampliamente aceptadas para verificar la normalidad de los datos.


```{r}
#wb.norm.test(w)	
```

<br/><br/><br/>

## <span style="color:#034a94">**Paquete nortest**</span>

Las siguientes pruebas requieren instalar y cargar el paquete: `nortest`

```{r}
# install.packages("nortets")
 #library(nortest)
```

<br/>

### <span style="color:#034a94">**Prueba de Anderson-Darling**</span>

La prueba de Anderson-Darling es una prueba de normalidad que se utiliza para verificar si una muestra de datos sigue una distribución normal. Esta prueba es una versión mejorada de la prueba de Kolmogorov-Smirnov, que es otra prueba comúnmente utilizada para verificar la normalidad de los datos.

La prueba de Anderson-Darling considera la diferencia entre los valores observados y los valores esperados bajo una distribución normal, dando más peso a las colas de la distribución que la prueba de Kolmogorov-Smirnov. Esto la hace más sensible a las desviaciones de la normalidad en las colas de la distribución.


```{r}
#ad.test(w)
```

<br/>

### <span style="color:#034a94">**Prueba de Cramer-von Mises**</span>

La prueba de Cramer-von Mises es una prueba de bondad de ajuste que se utiliza para verificar si una muestra de datos sigue una distribución teórica específica, como una distribución normal. Esta prueba es una alternativa a la prueba de Anderson-Darling y a la prueba de Kolmogorov-Smirnov, y se basa en la comparación de los valores acumulados observados y los valores acumulados esperados bajo la distribución teórica.

La prueba de Cramer-von Mises es especialmente útil cuando se desea evaluar si los datos siguen una distribución específica en lugar de simplemente evaluar si los datos son normales. Esta prueba es sensible a las desviaciones de la distribución en la cola, lo que la hace útil para detectar desviaciones no solo en la media y la varianza, sino también en la forma de la distribución.


```{r}
#cvm.test(w)
```


<br/>

### <span style="color:#034a94">**Prueba de Lilliefors (Kolmogorov-Smirnov)**</span>

La prueba de Lilliefors es una versión modificada de la prueba de Kolmogorov-Smirnov (KS) que se utiliza para verificar si una muestra de datos sigue una distribución normal. Mientras que la prueba de KS estándar asume que los parámetros de la distribución subyacente son conocidos, la prueba de Lilliefors estima estos parámetros a partir de los datos, lo que la hace más apropiada cuando no se conoce la verdadera distribución de los datos.

La prueba de Lilliefors es útil cuando se desea verificar si los datos siguen una distribución normal sin tener que asumir que los parámetros de la distribución son conocidos. Sin embargo, al igual que con la prueba de KS estándar, la interpretación de los resultados de la prueba de Lilliefors puede depender del tamaño de la muestra, por lo que es importante tener en cuenta este factor al interpretar los resultados.


```{r}
lillie.test(w)
```

<br/>

### <span style="color:#034a94">**Prueba chi-cuadrado de Pearson**</span>

La prueba chi-cuadrado de Pearson se utiliza para comparar la distribución observada de los datos con una distribución teórica, como una distribución normal. En el contexto de la normalidad, esta prueba compara la distribución de frecuencias observada en los datos con la distribución de frecuencias esperada bajo la hipótesis de que los datos siguen una distribución normal.

Para realizar la prueba chi-cuadrado de Pearson para la normalidad, se dividen los datos en intervalos y se cuenta el número de observaciones en cada intervalo. Luego, se calcula la frecuencia esperada para cada intervalo bajo la hipótesis de normalidad. La prueba compara las frecuencias observadas y esperadas utilizando la estadística de prueba chi-cuadrado.

Es importante tener en cuenta que, al igual que otras pruebas de normalidad, la interpretación de los resultados de la prueba chi-cuadrado de Pearson puede depender del tamaño de la muestra y de otros factores. Por lo tanto, es recomendable utilizar esta prueba en conjunto con otras pruebas de normalidad y métodos de diagnóstico.


```{r}
pearson.test(w)
```

<br/>

### <span style="color:#034a94">**Prueba de Shapiro-Francia**</span>

La prueba de Shapiro-Francia es una prueba de normalidad que se utiliza para verificar si una muestra de datos sigue una distribución normal. Es una versión modificada de la prueba de Shapiro-Wilk que utiliza un enfoque diferente para calcular el estadístico de prueba.

Al igual que la prueba de Shapiro-Wilk, la prueba de Shapiro-Francia evalúa la hipótesis nula de que los datos provienen de una distribución normal. Si el valor p asociado con la prueba es menor que un nivel de significancia dado (generalmente 0.05), se rechaza la hipótesis nula y se concluye que los datos no siguen una distribución normal.

La prueba de Shapiro-Francia se considera útil cuando se trabaja con muestras pequeñas o moderadamente grandes y se desea una prueba de normalidad que tenga un buen rendimiento en términos de poder estadístico. Sin embargo, al igual que con cualquier prueba de normalidad, es importante considerar otros factores y utilizar múltiples pruebas y métodos de diagnóstico para evaluar la normalidad de los datos.


```{r}
sf.test(w)
```

En todos los casos se presenta un valor-p grande por lo cual no se rechaza $Ho$, asumimos que $Ho$ es verdad. Asumimos que la distribución de la variable $X$ es normal

<div class="content-box-gray">
## <span style="color:#686868">**Resumen**</span>

|                   |                                                          |
|:------------------|:---------------------------------------------------------|
|                   |`chisq.test(x=obs,p=esp)`                                 |
|paquete: MASS      |`library(MASS)`                                           |
|                   |`chisq.test(M)`  # M: matriz                              |
|paquete: BSDA      |`library(BSDA)`                                           |
|                   |`SIGN.test(x,md=15,alternative = "greater")`              |
|                   |`wilcox.test(g1,g2,paired = FALSE,alternative = "less")`  |
|                   |**Pruebas de normalidad**                                 |
|                   |`shapiro.test(x)`                                         |
| paquete:normtest  |`library(normtest)`                                       |
|                   |`ajb.norm.test(x)`                                        |
|                   |`frosini.norm.test(x)`                                    |
|                   |`geary.norm.test(x)`                                      |
|                   |`hegazy1.norm.test(x)	`                                  |
|                   |`hegazy2.norm.test(x)`                                    |
|                   |`jb.norm.test(x)	`                                        |
|                   |`kurtosis.norm.test(x)`                                   |
|                   |`skewness.norm.test(x)	`                                  |
|                   |`spiegelhalter.norm.test(x)`                              |
|                   |`wb.norm.test(x)	`                                        |
|paquete: nortest   |`library(nortest)`                                        |
|                   |`ad.test(x)`                                              |
|                   |`cvm.test(x)`                                             |
|                   |`lillie.test(x)`                                          |
|                   |`pearson.test(x)`                                         |
|                   |`sf.test(x)`                                              |
</div>


<br/><br/>


### <span style="color:#686868">**Referencias**</span>

* https://rpubs.com/CJRR/PUJ_DECB_NP



